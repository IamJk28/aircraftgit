{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamJk28/aircraftgit/blob/main/Copy_of_Yet_another_copy_of_New_Aircraft_Model_Training_Detection_resnet_latest_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell allows the google colab session to access your drive contents where we have uploaded images and Annotations\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2_ZAKo0jn1kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0d2ca8-acaa-4f20-a46a-b3e444d6b4db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "# Adjust var names appropriately - using the TF2 Object detection zoo @ https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "# trying: ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8\n",
        "\n",
        "CUSTOM_MODEL_NAME = 'ssd_mobilenet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8'#Change this for different model\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'#Change for different model\n",
        "\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "folderpaths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\n",
        "    'TRAIN_PATH':os.path.join('Tensorflow','workspace','images','train'),\n",
        "    'TEST_PATH':os.path.join('Tensorflow','workspace','images','test'),\n",
        "    'COLLECT_PATH':os.path.join('Tensorflow','workspace','images','collectedimages')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(folderpaths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(folderpaths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in folderpaths.values():\n",
        "    if not os.path.exists(path):\n",
        "      !mkdir -p {path}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Untar Image and label Archive and move image and label folders to correct location"
      ],
      "metadata": {
        "id": "BbiJlptaaKYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replace source_folder0 with link to tar.gz file of images and label folders\n",
        "\n",
        "import shutil\n",
        "\n",
        "source_folder0 = \"drive/MyDrive/aircraftimage/processed_files.tar.gz\"\n",
        "destination_folder0 = \"Tensorflow/workspace/images\"\n",
        "\n",
        "if os.path.exists(source_folder0):\n",
        "   shutil.copy(source_folder0, destination_folder0)"
      ],
      "metadata": {
        "id": "XRTRKIYxHbNc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace source_folder0 with the same tar.gz link/path as above\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Path to the archive file\n",
        "source_folder0 = \"/content/Tensorflow/workspace/images/processed_files.tar.gz\"\n",
        "\n",
        "# Extract the contents of the archive\n",
        "with tarfile.open(source_folder0, 'r:gz') as tar:\n",
        "    tar.extractall(\"/content/Tensorflow/workspace/images\")\n"
      ],
      "metadata": {
        "id": "MgO5r1Gv3j-1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use the first two source_folder strings in future. upload the images and Annotations files from Microsoft teams INTO a new file (here we have called it \"aircraftimage\" ,change the path of source folders if you call it something else)\n",
        "\n",
        "#this code takes the \"images\" and \"Annotations\" files that you have uploaded into Google Drive and copies them in to the directory Tensorflow/workspace/collectedimages .from here using some later process/code we split the collected images(and xml files) into training and testing sets\n",
        "\n",
        "#again make sure that the source_folder 1 and 2 paths are relevant to the tar.gz file that was just untarred.\n",
        "\n",
        "source_folder1 = \"Tensorflow/workspace/images/processed_files/processed_images\"\n",
        "source_folder2 = \"Tensorflow/workspace/images/processed_files/processed_xml\"\n",
        "destination_folder = \"Tensorflow/workspace/images/collectedimages\"\n",
        "\n",
        "source_folders = [source_folder1, source_folder2]\n",
        "\n",
        "for source_folder in source_folders:\n",
        "    source_files = os.listdir(source_folder)\n",
        "    for file_name in source_files:\n",
        "        source_file = os.path.join(source_folder, file_name)\n",
        "        destination_file = os.path.join(destination_folder, file_name)\n",
        "        shutil.copy(source_file, destination_file)"
      ],
      "metadata": {
        "id": "l2CREW2Ugk1d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the number of images you are running this experiment with\n",
        "\n",
        "#define the directory you want to count images in\n",
        "directory_path1 = \"/content/Tensorflow/workspace/images/images\"\n",
        "directory_path2 = \"/content/Tensorflow/workspace/images/Annotations\"\n",
        "\n",
        "#list all images in the directory\n",
        "items = os.listdir(source_folder1)\n",
        "\n",
        "#count\n",
        "num_items = len(items)\n",
        "\n",
        "#print the number of images you are working with\n",
        "print(f\"Number of items in the directory: {num_items}\")\n",
        "\n",
        "#list all images in the directory\n",
        "items = os.listdir(source_folder2)\n",
        "\n",
        "#count\n",
        "num_items = len(items)\n",
        "\n",
        "#print the number of images you are working with\n",
        "print(f\"Number of items in the directory: {num_items}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrwuhdtD4Qim",
        "outputId": "3fa1bba4-a9f3-43c5-8ca0-f58b7f5ae4c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items in the directory: 1214\n",
            "Number of items in the directory: 1213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional resizing step -- We can resize images and labels to match the correct input size for the model (if the chosen model does not have an inbuilt image_resizer, and if this hasn't already been done locally)"
      ],
      "metadata": {
        "id": "-U543r8ulmRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def resize_images(input_folder, output_folder, new_width, new_height):\n",
        "    \"\"\"Iterates through all images in a given input folder (input_folder) and resizes them to a specified size.\n",
        "    run annotation_converter.py afterwards to convert any existing/outstanding xml files to the proper size.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "      if filename.endswith('JPG'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(input_path)\n",
        "        if image is not None:\n",
        "          # Resize the image\n",
        "          resized_image = cv2.resize(image, (new_width, new_height))\n",
        "\n",
        "          # Save the resized image to the output folder\n",
        "          output_path = os.path.join(output_folder, filename)\n",
        "          cv2.imwrite(output_path, resized_image)"
      ],
      "metadata": {
        "id": "oK-M172LCdlR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uncheck this if you want to resize images in the cloud\n",
        "#resize_images('Tensorflow/workspace/images/collectedimages', 'Tensorflow/workspace/images/resizedcollectedimages', 640, 640)"
      ],
      "metadata": {
        "id": "ftMPdr_YDIw1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def resize_xml_annotations(xml_folder, output_folder, new_size):\n",
        "    \"\"\" Iterates through all xml_files in a given input folder (xml_folder variable)\n",
        "    and resizes them to map to the same location on a resized image.\n",
        "    \"\"\"\n",
        "    new_width, new_height = new_size\n",
        "\n",
        "    for xml_file in os.listdir(xml_folder):\n",
        "        if xml_file.endswith('.xml'):\n",
        "            xml_path = os.path.join(xml_folder, xml_file)\n",
        "            tree = ET.parse(xml_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            image_size = root.find('size')\n",
        "            image_width = int(image_size.find('width').text)\n",
        "            image_height = int(image_size.find('height').text)\n",
        "\n",
        "            width_ratio = new_width / image_width\n",
        "            height_ratio = new_height / image_height\n",
        "\n",
        "            for object in root.findall('object'):\n",
        "                bndbox = object.find('bndbox')\n",
        "\n",
        "                xmin = int(bndbox.find('xmin').text)\n",
        "                ymin = int(bndbox.find('ymin').text)\n",
        "                xmax = int(bndbox.find('xmax').text)\n",
        "                ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "                xmin = int(xmin * width_ratio)\n",
        "                ymin = int(ymin * height_ratio)\n",
        "                xmax = int(xmax * width_ratio)\n",
        "                ymax = int(ymax * height_ratio)\n",
        "\n",
        "                bndbox.find('xmin').text = str(xmin)\n",
        "                bndbox.find('ymin').text = str(ymin)\n",
        "                bndbox.find('xmax').text = str(xmax)\n",
        "                bndbox.find('ymax').text = str(ymax)\n",
        "\n",
        "            # Update the image size in the XML file\n",
        "            image_size.find('width').text = str(new_width)\n",
        "            image_size.find('height').text = str(new_height)\n",
        "\n",
        "            # Save the updated XML file to the output folder\n",
        "            output_path = os.path.join(output_folder, xml_file)\n",
        "            tree.write(output_path)"
      ],
      "metadata": {
        "id": "fq1h73ZlCdp1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uncheck if you want to resize xml labels in the cloud\n",
        "#resize_xml_annotations('Tensorflow/workspace/images/collectedimages', 'Tensorflow/workspace/images/resizedcollectedimages', (640,640))"
      ],
      "metadata": {
        "id": "qDGTq_01DJdd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Train/Test Split"
      ],
      "metadata": {
        "id": "Htw5QYSPaiiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import copyfile"
      ],
      "metadata": {
        "id": "XfNFePlhTIT-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the paths to your image and XML directories #resized\n",
        "image_directory ='Tensorflow/workspace/images/collectedimages'\n",
        "xml_directory ='Tensorflow/workspace/images/collectedimages'\n",
        "\n",
        "# Create the train and test directories if they don't exist\n",
        "train_directory = 'Tensorflow/workspace/images/train'\n",
        "test_directory = 'Tensorflow/workspace/images/test'\n",
        "os.makedirs(train_directory, exist_ok=True)\n",
        "os.makedirs(test_directory, exist_ok=True)\n",
        "\n",
        "# List all image files in the image directory\n",
        "image_files = [file for file in os.listdir(image_directory) if file.endswith('.JPG')]\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "print(image_files)\n",
        "\n",
        "# Perform the train/test split\n",
        "train_files, test_files = train_test_split(image_files, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "\n",
        "# Move the selected images and their corresponding XML files to the train folder\n",
        "for file in train_files:\n",
        "    image_src = os.path.join(image_directory, file)\n",
        "    #print(image_src)\n",
        "    xml_src = os.path.join(xml_directory, file.replace('.JPG', '.xml'))\n",
        "    #print(xml_src)\n",
        "    image_dest = os.path.join(train_directory, file)\n",
        "    #print(image_dest)\n",
        "    xml_dest = os.path.join(train_directory, file.replace('.JPG', '.xml'))\n",
        "    #print(xml_dest)\n",
        "    if os.path.exists(xml_src):\n",
        "      copyfile(image_src, image_dest)\n",
        "      copyfile(xml_src, xml_dest)\n",
        "\n",
        "# Move the remaining images and their corresponding XML files to the test folder\n",
        "for file in test_files:\n",
        "    image_src = os.path.join(image_directory, file)\n",
        "    xml_src = os.path.join(xml_directory, file.replace('.JPG', '.xml'))\n",
        "    image_dest = os.path.join(test_directory, file)\n",
        "    xml_dest = os.path.join(test_directory, file.replace('.JPG', '.xml'))\n",
        "    if os.path.exists(xml_src):\n",
        "      copyfile(image_src, image_dest)\n",
        "      copyfile(xml_src, xml_dest)\n",
        "\n",
        "\n",
        "#examine train/test split by unchecking below\n",
        "print(\"size of training set\",len(train_files))\n",
        "print(\"size of testing set\",len(test_files))\n",
        "\n",
        "#Number of images being used in this dataset\n",
        "print(\"Overall Number of Images Input into Model: \" + str(len(train_files) + len(test_files)))"
      ],
      "metadata": {
        "id": "FsFIVF9CPHFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3319bc31-67e4-423f-c256-98b11e7badad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d5306168-AllSkyImage007071349.JPG', '2584746d-AllSkyImage007071119.JPG', '04f8c19a-AllSkyImage007072267.JPG', '682e1e58-AllSkyImage007040289.JPG', 'ce617c2b-AllSkyImage007071322.JPG', '599c00c2-AllSkyImage007072301.JPG', '248cf569-AllSkyImage007038024.JPG', 'dd0263b3-AllSkyImage007071302.JPG', '1853ac16-AllSkyImage007037670.JPG', 'ae552a1f-AllSkyImage007039249.JPG', 'd5f33b4e-AllSkyImage007070992.JPG', '6e133539-AllSkyImage007039306.JPG', 'b1af8457-AllSkyImage007071160.JPG', 'f272a3fb-AllSkyImage007072548.JPG', '0c6833cc-AllSkyImage007040253.JPG', 'febda06d-AllSkyImage007038170.JPG', '9de8126e-AllSkyImage007039187.JPG', '38251cb1-AllSkyImage007037470.JPG', 'bed0b164-AllSkyImage007072604.JPG', 'cb8d24d8-AllSkyImage007072669.JPG', '1ced42ac-AllSkyImage007072651.JPG', 'b1f50dac-AllSkyImage007039437.JPG', '8b7d1b39-AllSkyImage007039404.JPG', 'f633b741-AllSkyImage007072883.JPG', '7622ea96-AllSkyImage007037598.JPG', '9c24e2a5-AllSkyImage007127813.JPG', '9f7b7e96-AllSkyImage007127558.JPG', '2acb6834-AllSkyImage007039458.JPG', '5b071df3-AllSkyImage007072437.JPG', '500a7be5-AllSkyImage007039330.JPG', '16e35aa0-AllSkyImage007070986.JPG', '7e894a99-AllSkyImage007072503.JPG', '876c914f-AllSkyImage007072387.JPG', '33cdc66b-AllSkyImage007037520.JPG', 'bafff32c-AllSkyImage007037734.JPG', 'd5c511a4-AllSkyImage007071473.JPG', '3dad44b8-AllSkyImage007037502.JPG', '3e83cada-AllSkyImage007072730.JPG', 'ac8821a9-AllSkyImage007071162.JPG', '0734d49c-AllSkyImage007071146.JPG', 'cf2579d6-AllSkyImage007071443.JPG', '3c4dd40a-AllSkyImage007072633.JPG', '07660020-AllSkyImage007072285.JPG', 'db701af0-AllSkyImage007039241.JPG', '89a3e288-AllSkyImage007072380.JPG', 'af0ef007-AllSkyImage007039180.JPG', '3dbc8d7e-AllSkyImage007127750.JPG', '2284584c-AllSkyImage007039409.JPG', '4b78403f-AllSkyImage007037428.JPG', 'a2ca1933-AllSkyImage007037522.JPG', 'e19b4d73-AllSkyImage007072396.JPG', '00353503-AllSkyImage007072445.JPG', 'a3086a81-AllSkyImage007039214.JPG', '29e1a3e2-AllSkyImage007127525.JPG', 'd6533835-AllSkyImage007071194.JPG', 'f7fbfa6f-AllSkyImage007072537.JPG', '67853a6a-AllSkyImage007072655.JPG', '8af57df4-AllSkyImage007037740.JPG', '80a2de67-AllSkyImage007039394.JPG', '9a314922-AllSkyImage007071013.JPG', '062f4b1f-AllSkyImage007071077.JPG', 'b9bb3568-AllSkyImage007072392.JPG', 'b9be49ca-AllSkyImage007039726.JPG', '9b068e9a-AllSkyImage007071147.JPG', 'fde413b1-AllSkyImage007071100.JPG', 'a41c922a-AllSkyImage007072399.JPG', '99197ce6-AllSkyImage007072374.JPG', '3c5e0130-AllSkyImage007039264.JPG', '553c2925-AllSkyImage007037477.JPG', '0dc560c3-AllSkyImage007072774.JPG', '3e5beb16-AllSkyImage007038084.JPG', '4d7c8fff-AllSkyImage007037538.JPG', 'f9cc1bd7-AllSkyImage007039195.JPG', '73265ced-AllSkyImage007072677.JPG', 'c9a35522-AllSkyImage007071150.JPG', '8ba0e6f8-AllSkyImage007073577.JPG', '02fb9aa9-AllSkyImage007071376.JPG', '3d068ce0-AllSkyImage007039405.JPG', '6eae72a7-AllSkyImage007072438.JPG', 'b69461cd-AllSkyImage007039181.JPG', '12382eb5-AllSkyImage007071137.JPG', '6af61074-AllSkyImage007072367.JPG', 'a8da8261-AllSkyImage007072458.JPG', '471e8867-AllSkyImage007071090.JPG', 'c83e8cb9-AllSkyImage007072499.JPG', 'b1b0817b-AllSkyImage007039191.JPG', '9a210cb5-AllSkyImage007071024.JPG', '4be7fc25-AllSkyImage007038132.JPG', 'dbc2ba9d-AllSkyImage007073589.JPG', '73787e46-AllSkyImage007071469.JPG', 'cfb2f582-AllSkyImage007039254.JPG', '4edc130e-AllSkyImage007071033.JPG', '0945cdc1-AllSkyImage007072546.JPG', 'f87d1dff-AllSkyImage007071360.JPG', '80835e7a-AllSkyImage007071254.JPG', '9802ae87-AllSkyImage007072352.JPG', '15fd6d05-AllSkyImage007071479.JPG', '7af03ef1-AllSkyImage007071830.JPG', '15cecfca-AllSkyImage007037574.JPG', 'ff2e93c3-AllSkyImage007072674.JPG', '376a22f4-AllSkyImage007072603.JPG', '93c05dcf-AllSkyImage007039212.JPG', '8e03be82-AllSkyImage007072379.JPG', '36edacd5-AllSkyImage007072394.JPG', 'e07de6c1-AllSkyImage007040295.JPG', '7839a5be-AllSkyImage007071320.JPG', 'd93a8501-AllSkyImage007039397.JPG', '9e9d89a2-AllSkyImage007071272.JPG', '78ef8d98-AllSkyImage007072539.JPG', '8547025d-AllSkyImage007071325.JPG', 'aaba60fa-AllSkyImage007039401.JPG', 'a533cf9b-AllSkyImage007127551.JPG', '9f99f066-AllSkyImage007038708.JPG', '988bdc81-AllSkyImage007037558.JPG', '241346ab-AllSkyImage007037440.JPG', 'cecf4990-AllSkyImage007072424.JPG', 'e0fffb2b-AllSkyImage007037496.JPG', 'e74cbac8-AllSkyImage007071397.JPG', '593ca603-AllSkyImage007037469.JPG', '72120ac8-AllSkyImage007037699.JPG', '293ffca5-AllSkyImage007037542.JPG', 'e5e0b240-AllSkyImage007072551.JPG', '1269e1c2-AllSkyImage007040280.JPG', '3b31a7a9-AllSkyImage007071318.JPG', '5df92d6e-AllSkyImage007037557.JPG', '34f9edba-AllSkyImage007072585.JPG', 'eb5f2058-AllSkyImage007072660.JPG', '405a8e76-AllSkyImage007072390.JPG', '10ab9eea-AllSkyImage007072526.JPG', '7ff162e8-AllSkyImage007037539.JPG', '735ee491-AllSkyImage007072631.JPG', 'f6fadd92-AllSkyImage007070987.JPG', '7743d482-AllSkyImage007072333.JPG', 'ef25b2c8-AllSkyImage007071025.JPG', 'bd941218-AllSkyImage007127526.JPG', 'ac6e2906-AllSkyImage007072370.JPG', 'ad59ccef-AllSkyImage007072497.JPG', '5fdd17af-AllSkyImage007037723.JPG', '91d3b2e4-AllSkyImage007039219.JPG', '407f5386-AllSkyImage007072729.JPG', '0ba4a751-AllSkyImage007071340.JPG', 'bfa66e6c-AllSkyImage007071365.JPG', 'cde66efb-AllSkyImage007072296.JPG', '9fa9af2e-AllSkyImage007039224.JPG', 'e7696949-AllSkyImage007039139.JPG', 'b1b0cbc8-AllSkyImage007037738.JPG', '963ab627-AllSkyImage007072584.JPG', 'f85909eb-AllSkyImage007037559.JPG', '4d5f3666-AllSkyImage007038388.JPG', 'a660f74d-AllSkyImage007038220.JPG', '0004338d-AllSkyImage007038651.JPG', '71ea15b7-AllSkyImage007072618.JPG', 'b89f49ea-AllSkyImage007072547.JPG', '8d04a602-AllSkyImage007039322.JPG', '17bfa4b2-AllSkyImage007037731.JPG', '8c5d8a1b-AllSkyImage007039386.JPG', '34c8316a-AllSkyImage007072372.JPG', '887665a7-AllSkyImage007071462.JPG', '90e6d773-AllSkyImage007071251.JPG', 'a4fa52f1-AllSkyImage007039541.JPG', '592be5ea-AllSkyImage007039320.JPG', '7b971624-AllSkyImage007037746.JPG', '0d648e15-AllSkyImage007071219.JPG', '4c8c5198-AllSkyImage007038286.JPG', 'f6b816b4-AllSkyImage007038311.JPG', 'cc674f30-AllSkyImage007039413.JPG', '1768ec16-AllSkyImage007038123.JPG', 'b4ce5a5f-AllSkyImage007072691.JPG', '98f74fc2-AllSkyImage007038046.JPG', '19b00e1f-AllSkyImage007037442.JPG', '2d20836c-AllSkyImage007071129.JPG', 'a0fe409a-AllSkyImage007071039.JPG', '8aa6fb41-AllSkyImage007039284.JPG', '2ce167e6-AllSkyImage007071193.JPG', 'a4a8b8d0-AllSkyImage007071321.JPG', '8b310f5a-AllSkyImage007072779.JPG', '2ee8a32b-AllSkyImage007071181.JPG', '04b0736a-AllSkyImage007037489.JPG', '87256c9f-AllSkyImage007039339.JPG', '77620d64-AllSkyImage007071126.JPG', 'aa98035c-AllSkyImage007071196.JPG', 'da46903c-AllSkyImage007039276.JPG', '074338cb-AllSkyImage007071525.JPG', 'dbd04416-AllSkyImage007071192.JPG', 'b7f6fbf0-AllSkyImage007072291.JPG', '08e7ef36-AllSkyImage007037498.JPG', '720b0f43-AllSkyImage007071363.JPG', 'c2984b7f-AllSkyImage007127868.JPG', '78640aad-AllSkyImage007073207.JPG', '15ab5e99-AllSkyImage007039160.JPG', 'dfb2b6ca-AllSkyImage007072498.JPG', '4d6db5f7-AllSkyImage007037627.JPG', '6c07061e-AllSkyImage007039223.JPG', 'e41d3c19-AllSkyImage007038097.JPG', '2bfa1233-AllSkyImage007070998.JPG', '2f9fe332-AllSkyImage007071039_2.JPG', 'b2ecc883-AllSkyImage007039209.JPG', '76fa8c64-AllSkyImage007038253.JPG', 'b4688249-AllSkyImage007039133.JPG', '61e3f0ac-AllSkyImage007072781.JPG', '26ce4483-AllSkyImage007127552.JPG', '670c1257-AllSkyImage007037526.JPG', '70d693c2-AllSkyImage007072406.JPG', '8ffad400-AllSkyImage007127943.JPG', '917e99f4-AllSkyImage007071824.JPG', '654cfbb7-AllSkyImage007072449.JPG', '3b54a5aa-AllSkyImage007037745.JPG', 'fafe6f02-AllSkyImage007038493.JPG', '7d3cf33d-AllSkyImage007038122.JPG', '5ff532e3-AllSkyImage007072393.JPG', '4ddf2357-AllSkyImage007039183.JPG', 'ddb974c3-AllSkyImage007039210.JPG', '3721ee4f-AllSkyImage007071483.JPG', '8fdde588-AllSkyImage007071478.JPG', '7490ddd5-AllSkyImage007072752.JPG', 'c8229234-AllSkyImage007039260.JPG', '89e13cc3-AllSkyImage007072719.JPG', 'bfb1cca3-AllSkyImage007072266.JPG', '8ea8c755-AllSkyImage007037671.JPG', '22cc26f5-AllSkyImage007072672.JPG', '04cc5cb0-AllSkyImage007071229.JPG', '4274a972-AllSkyImage007039384.JPG', '297dcab1-AllSkyImage007071335.JPG', 'e334257c-AllSkyImage007071142.JPG', '9a3263d3-AllSkyImage007072386.JPG', 'f34e653c-AllSkyImage007072600.JPG', 'dc736764-AllSkyImage007038156.JPG', 'b6d68765-AllSkyImage007071393.JPG', '3a34799c-AllSkyImage007071342.JPG', '7ce24b3c-AllSkyImage007038045.JPG', '9031291e-AllSkyImage007071163.JPG', 'bd5fc4e0-AllSkyImage007071390.JPG', 'c1d19528-AllSkyImage007071148.JPG', '1c050fc9-AllSkyImage007039623.JPG', '74d3b2b4-AllSkyImage007071328.JPG', '3bbea5df-AllSkyImage007071405.JPG', 'afd16922-AllSkyImage007039697.JPG', 'c203eeb1-AllSkyImage007071216.JPG', 'd783d1a6-AllSkyImage007071878.JPG', '4ef47ae8-AllSkyImage007039354.JPG', '2f073843-AllSkyImage007072461.JPG', 'a039e420-AllSkyImage007038308.JPG', '0967d5e7-AllSkyImage007071104.JPG', 'cca11e4b-AllSkyImage007039539.JPG', '825ec8cb-AllSkyImage007039487.JPG', 'e1b15d8f-AllSkyImage007071252.JPG', 'e9eadae0-AllSkyImage007039251.JPG', 'a47c82f8-AllSkyImage007072357_2.JPG', '25904676-AllSkyImage007038354.JPG', '5b33a4c3-AllSkyImage007072303.JPG', '68cff54d-AllSkyImage007072828.JPG', '553876cc-AllSkyImage007039229.JPG', 'a8ee112a-AllSkyImage007072789.JPG', '063b7fdd-AllSkyImage007071308.JPG', 'fa4ac29e-AllSkyImage007072525.JPG', '200de3ca-AllSkyImage007039602.JPG', '1a36bd0e-AllSkyImage007072268.JPG', '6ae50c1a-AllSkyImage007038023.JPG', '1e9a8ac1-AllSkyImage007038085.JPG', 'f1815b26-AllSkyImage007039365.JPG', 'f7af227a-AllSkyImage007127781.JPG', '8a035914-AllSkyImage007039246.JPG', '4b88e8fb-AllSkyImage007072679.JPG', 'e25b4d36-AllSkyImage007071084.JPG', 'b033f699-AllSkyImage007071470.JPG', '2f386296-AllSkyImage007039407.JPG', '940ec049-AllSkyImage007071133.JPG', 'b32a0a98-AllSkyImage007039434.JPG', 'eca0150f-AllSkyImage007072717.JPG', 'e7bae278-AllSkyImage007038256.JPG', 'c95a0742-AllSkyImage007037491.JPG', '07d16220-AllSkyImage007072381.JPG', 'c07e2082-AllSkyImage007039192.JPG', '929fa1d0-AllSkyImage007038652.JPG', '168b647a-AllSkyImage007039182.JPG', '3acaa76c-AllSkyImage007039266.JPG', 'c91f92fa-AllSkyImage007038523.JPG', 'c57674ac-AllSkyImage007071173.JPG', '72511a80-AllSkyImage007127553.JPG', 'a6b48c1c-AllSkyImage007037441.JPG', 'b6b8f15a-AllSkyImage007072443.JPG', 'acd08c1b-AllSkyImage007127847.JPG', '150ee42c-AllSkyImage007072716.JPG', '7cc58cf8-AllSkyImage007070988.JPG', '4f30ae91-AllSkyImage007039374.JPG', '8853f110-AllSkyImage007071164.JPG', '1e4ed521-AllSkyImage007037463.JPG', 'b70c65de-AllSkyImage007071434.JPG', 'b15e7720-AllSkyImage007071409.JPG', '2b0fad25-AllSkyImage007072331.JPG', '3f3a3e41-AllSkyImage007039396.JPG', '504cded2-AllSkyImage007037587.JPG', '258b161b-AllSkyImage007038507.JPG', '45b7b4bb-AllSkyImage007038155.JPG', '736916e9-AllSkyImage007072532.JPG', '8c2466c4-AllSkyImage007072786.JPG', 'b367b190-AllSkyImage007071217.JPG', 'feecbf1b-AllSkyImage007072590.JPG', '65322ef6-AllSkyImage007037704.JPG', '5ce5485f-AllSkyImage007039653.JPG', '4cf00009-AllSkyImage007038281.JPG', '4fdbb7b3-AllSkyImage007038470.JPG', 'dd5066a4-AllSkyImage007039274.JPG', '7f837118-AllSkyImage007037610.JPG', '600a9a7d-AllSkyImage007039601.JPG', '81cdf43e-AllSkyImage007071083.JPG', '7868715c-AllSkyImage007072376.JPG', '3098d28f-AllSkyImage007037548.JPG', 'af9cef5e-AllSkyImage007072430.JPG', 'e1423736-AllSkyImage007071143.JPG', 'ffad556b-AllSkyImage007072700.JPG', '39df4052-AllSkyImage007037733.JPG', 'd506cb52-AllSkyImage007037705.JPG', '93d5cb18-AllSkyImage007072429.JPG', 'a1c66631-AllSkyImage007072636.JPG', 'ca2646cc-AllSkyImage007038109.JPG', 'd0fff539-AllSkyImage007073208.JPG', '61288f1d-AllSkyImage007040297.JPG', '1c0e1b0d-AllSkyImage007037499.JPG', '26bfbd73-AllSkyImage007072701.JPG', 'c6e54fa3-AllSkyImage007072658.JPG', '3e631eca-AllSkyImage007071007.JPG', '222a40ca-AllSkyImage007037730.JPG', 'e4ff06bb-AllSkyImage007039286.JPG', '83ea0bb6-AllSkyImage007039370.JPG', '7acdb5d1-AllSkyImage007039492.JPG', 'e638e833-AllSkyImage007038098.JPG', 'e7f63fc5-AllSkyImage007071446.JPG', '8f41ed60-AllSkyImage007127539.JPG', 'b834c7cf-AllSkyImage007037431.JPG', 'ac1c209b-AllSkyImage007071086.JPG', '0f5b3727-AllSkyImage007071343.JPG', 'a89a0855-AllSkyImage007072803.JPG', 'd47328a7-AllSkyImage007039250.JPG', '80bdeb76-AllSkyImage007039542.JPG', '884dc0a8-AllSkyImage007038489.JPG', 'fe41a1cf-AllSkyImage007037622.JPG', '32d5fc4b-AllSkyImage007038219.JPG', 'cb490589-AllSkyImage007071095.JPG', '5e337cea-AllSkyImage007072318.JPG', 'ce56e639-AllSkyImage007071021.JPG', 'cd2eeecf-AllSkyImage007072654.JPG', '5dee8c59-AllSkyImage007071085.JPG', '23fdc1dc-AllSkyImage007039459.JPG', '84fada3d-AllSkyImage007072705.JPG', 'a617a82f-AllSkyImage007127751.JPG', '1dd7ab04-AllSkyImage007071020.JPG', '69961f98-AllSkyImage007037698.JPG', '3bb5bc3f-AllSkyImage007037619.JPG', 'ca36bd4c-AllSkyImage007070981.JPG', 'a9a6bfeb-AllSkyImage007039265.JPG', '7c0a7775-AllSkyImage007072533.JPG', '2fe2a4c8-AllSkyImage007071172.JPG', '5affd5e4-AllSkyImage007071826.JPG', '5dcbc8fe-AllSkyImage007072534.JPG', '2e1c9ece-AllSkyImage007070990.JPG', 'e189f18c-AllSkyImage007072632.JPG', '246d129b-AllSkyImage007039325.JPG', 'a0f39392-AllSkyImage007072425.JPG', '47702c0b-AllSkyImage007071610.JPG', '54bf7873-AllSkyImage007072295.JPG', '226816b6-AllSkyImage007072383.JPG', '6934a2db-AllSkyImage007071357.JPG', '618e3797-AllSkyImage007071369.JPG', 'fba8ec2a-AllSkyImage007072541.JPG', 'a7b677d2-AllSkyImage007037573.JPG', '47c4d485-AllSkyImage007071471.JPG', '01b7c515-AllSkyImage007040296.JPG', '19d90605-AllSkyImage007039159.JPG', '26d14a6e-AllSkyImage007038487.JPG', '0fca120a-AllSkyImage007038488.JPG', 'ef084270-AllSkyImage007072530.JPG', 'd7cef651-AllSkyImage007037462.JPG', '486f72ab-AllSkyImage007039221.JPG', '2764823f-AllSkyImage007039240.JPG', 'e5ecd62c-AllSkyImage007072403.JPG', '6e79f757-AllSkyImage007039448.JPG', 'a52530f0-AllSkyImage007072628.JPG', 'ba69e4e2-AllSkyImage007039258.JPG', '8b218aa9-AllSkyImage007039625.JPG', 'c38eab33-AllSkyImage007039244.JPG', 'afe1da6a-AllSkyImage007071243.JPG', 'eb113dad-AllSkyImage007037490.JPG', '6ce73f55-AllSkyImage007071315.JPG', '153b395f-AllSkyImage007071123.JPG', '90a958d2-AllSkyImage007071435.JPG', 'd22ee7c5-AllSkyImage007071094.JPG', '0660ada8-AllSkyImage007038389.JPG', 'ae2ee5e2-AllSkyImage007071242.JPG', 'a23bb9a4-AllSkyImage007071681.JPG', '2229967e-AllSkyImage007072891.JPG', 'd7490f09-AllSkyImage007071249.JPG', '2a9cae76-AllSkyImage007071016.JPG', '9180c8ae-AllSkyImage007038106.JPG', '661b58a6-AllSkyImage007072785.JPG', '0a50933b-AllSkyImage007037510.JPG', 'fa5eadb4-AllSkyImage007071134.JPG', 'a11a6c14-AllSkyImage007039157.JPG', '09ad15b0-AllSkyImage007071481.JPG', 'c3e84619-AllSkyImage007071334.JPG', '49d43b16-AllSkyImage007039353.JPG', '908685ce-AllSkyImage007072704.JPG', 'c4681aa0-AllSkyImage007072549.JPG', '2de33c19-AllSkyImage007039373.JPG', '36794df2-AllSkyImage007072760.JPG', '80287077-AllSkyImage007039495.JPG', 'e6ff1793-AllSkyImage007072804.JPG', 'bf436e71-AllSkyImage007072444.JPG', '62442a64-AllSkyImage007071292.JPG', '926ab735-AllSkyImage007072611.JPG', '846d05d4-AllSkyImage007071290.JPG', '4f0ff6d8-AllSkyImage007040287.JPG', '024cad37-AllSkyImage007038393.JPG', '6053af01-AllSkyImage007072397.JPG', '402a5e02-AllSkyImage007072501.JPG', 'ad0bdc2f-AllSkyImage007037742.JPG', '67327add-AllSkyImage007037618.JPG', '9f4a0935-AllSkyImage007039257.JPG', 'b24aa7e5-AllSkyImage007071093.JPG', '71ee28db-AllSkyImage007071401.JPG', 'c09295b3-AllSkyImage007071014.JPG', '3dbc035a-AllSkyImage007072254.JPG', 'fe8267d6-AllSkyImage007038366.JPG', '612be1e3-AllSkyImage007071186.JPG', 'ae96ec1d-AllSkyImage007071105.JPG', '9469d23d-AllSkyImage007071106.JPG', '688ae6c2-AllSkyImage007127952.JPG', '15b3712f-AllSkyImage007127808.JPG', 'ae090320-AllSkyImage007071350.JPG', '87c60939-AllSkyImage007071792.JPG', 'c871a13e-AllSkyImage007039208.JPG', '6456f89f-AllSkyImage007071392.JPG', 'a58dd26b-AllSkyImage007071000.JPG', '8c82e48f-AllSkyImage007039540.JPG', 'e7708f7d-AllSkyImage007072375.JPG', '84b877b6-AllSkyImage007071361.JPG', '63c6de4a-AllSkyImage007039277.JPG', '24e7d6a4-AllSkyImage007039436.JPG', '0e86f4c7-AllSkyImage007071329.JPG', '01a19ecb-AllSkyImage007038089.JPG', 'd5040e13-AllSkyImage007071114.JPG', 'd0c955fb-AllSkyImage007127538.JPG', '323902ef-AllSkyImage007040288.JPG', '55446b72-AllSkyImage007127783.JPG', 'bfca9fdc-AllSkyImage007037728.JPG', 'd461f45b-AllSkyImage007071351.JPG', '186257fd-AllSkyImage007039345.JPG', 'd41e1254-AllSkyImage007039509.JPG', '7a7bb06e-AllSkyImage007072599.JPG', '9164e94a-AllSkyImage007071794.JPG', '922aac9a-AllSkyImage007072649.JPG', '9bc9462e-AllSkyImage007071080.JPG', 'cbfd7aca-AllSkyImage007071337.JPG', 'c21a06fa-AllSkyImage007037547.JPG', 'b0b20756-AllSkyImage007072715.JPG', '25b4ca8f-AllSkyImage007071037.JPG', '67f74171-AllSkyImage007072529.JPG', '8c094675-AllSkyImage007072673.JPG', 'cff65a8c-AllSkyImage007071327.JPG', 'e552454d-AllSkyImage007072552.JPG', '6739dad4-AllSkyImage007072670.JPG', 'dadd03e7-AllSkyImage007037666.JPG', 'aa78383d-AllSkyImage007039725.JPG', '55f4353d-AllSkyImage007072536.JPG', '1575179a-AllSkyImage007039695.JPG', 'fa3af730-AllSkyImage007039400.JPG', 'b1a76d23-AllSkyImage007071477.JPG', '1e16b17f-AllSkyImage007071187.JPG', '9506726b-AllSkyImage007071051.JPG', 'b46ecee5-AllSkyImage007037575.JPG', 'abf8f8d4-AllSkyImage007037700.JPG', '44412fe7-AllSkyImage007072316.JPG', '26e3b350-AllSkyImage007037512.JPG', '22a812ad-AllSkyImage007037540.JPG', '4c1e279c-AllSkyImage007072319.JPG', 'e3298c44-AllSkyImage007038144.JPG', '68f0816f-AllSkyImage007037482.JPG', 'd9745858-AllSkyImage007038285.JPG', '7a5ccd23-AllSkyImage007038634.JPG', '998f64a6-AllSkyImage007071092.JPG', '1ce99b0c-AllSkyImage007039486.JPG', 'db1a2c7a-AllSkyImage007037591.JPG', '66a2e42b-AllSkyImage007039217.JPG', 'd6cb0eba-AllSkyImage007072601.JPG', '9cae2620-AllSkyImage007071248.JPG', '498e4ac2-AllSkyImage007071223.JPG', '52ca510a-AllSkyImage007072426.JPG', '2d10326b-AllSkyImage007127870.JPG', '43a813be-AllSkyImage007039624.JPG', 'fb91e5b5-AllSkyImage007071008.JPG', 'a14bad0e-AllSkyImage007072538.JPG', 'af93c868-AllSkyImage007071348.JPG', '171c3a96-AllSkyImage007072793.JPG', '6daee53d-AllSkyImage007038218.JPG', '8535d9f6-AllSkyImage007071174.JPG', '39e62464-AllSkyImage007039185.JPG', '4f429fda-AllSkyImage007039252.JPG', '1c582dad-AllSkyImage007071463.JPG', '14b39a61-AllSkyImage007039510.JPG', '5608a7e5-AllSkyImage007039387.JPG', '929893d9-AllSkyImage007071034.JPG', '11ca6cff-AllSkyImage007038273.JPG', '27150339-AllSkyImage007071403.JPG', 'da565414-AllSkyImage007072586.JPG', '050f2876-AllSkyImage007072447.JPG', 'ee53d5f5-AllSkyImage007039140.JPG', '6499511d-AllSkyImage007039450.JPG', '9c9a682a-AllSkyImage007038271.JPG', 'eb53e3b3-AllSkyImage007040282.JPG', '9d99ef11-AllSkyImage007038225.JPG', '761bd128-AllSkyImage007071250.JPG', '89e245f2-AllSkyImage007039207.JPG', '983cc61e-AllSkyImage007071222.JPG', '40561636-AllSkyImage007038124.JPG', '82e32281-AllSkyImage007127782.JPG', 'b057e9ad-AllSkyImage007072535.JPG', '9575aac9-AllSkyImage007037585.JPG', '148444c1-AllSkyImage007039153.JPG', 'd258c2ac-AllSkyImage007038272.JPG', '3bf1a6fd-AllSkyImage007072714.JPG', '64a9d412-AllSkyImage007127839.JPG', '84618b2c-AllSkyImage007071317.JPG', '69486adc-AllSkyImage007072459.JPG', '5cd5a14b-AllSkyImage007039654.JPG', '7fedf901-AllSkyImage007072635.JPG', 'e7b96acd-AllSkyImage007073591.JPG', '37e1718a-AllSkyImage007072398.JPG', 'dc724e01-AllSkyImage007071359.JPG', '57b62ad1-AllSkyImage007037748.JPG', '315cd1c1-AllSkyImage007038242.JPG', '51ee97be-AllSkyImage007037747.JPG', 'aeb398b9-AllSkyImage007072500.JPG', '3dbb0626-AllSkyImage007127838.JPG', '4eb37b85-AllSkyImage007039369.JPG', '9728902f-AllSkyImage007071879.JPG', '4f527803-AllSkyImage007037609.JPG', 'b72c1470-AllSkyImage007037476.JPG', 'c6ecc733-AllSkyImage007039398.JPG', '70744601-AllSkyImage007072272.JPG', 'ebb3134f-AllSkyImage007072613.JPG', '52383760-AllSkyImage007037743.JPG', '50ac5c1b-AllSkyImage007037586.JPG', 'd229b429-AllSkyImage007039175.JPG', '73d0a210-AllSkyImage007038355.JPG', '17a537cf-AllSkyImage007127560_2.JPG', '15b18c28-AllSkyImage007072694.JPG', '02c098bb-AllSkyImage007039194.JPG', '0573b7cc-AllSkyImage007038033.JPG', '89ae78a1-AllSkyImage007072286.JPG', '0a457fc0-AllSkyImage007072818.JPG', 'b1d024fc-AllSkyImage007071326.JPG', 'b46cbbde-AllSkyImage007039338.JPG', '0074e073-AllSkyImage007071402.JPG', '329bfb0d-AllSkyImage007038632.JPG', '10e06c74-AllSkyImage007071171.JPG', '71474a07-AllSkyImage007039184.JPG', '46108379-AllSkyImage007072614.JPG', 'c381abb0-AllSkyImage007038409.JPG', 'c94901fb-AllSkyImage007073613.JPG', '5c1f71aa-AllSkyImage007039389.JPG', 'bc8e67c8-AllSkyImage007071468.JPG', 'a7637116-AllSkyImage007072589.JPG', '381d6531-AllSkyImage007071273.JPG', '7ed601fe-AllSkyImage007071149.JPG', '8a9586d5-AllSkyImage007071224.JPG', '8bcc7896-AllSkyImage007071170.JPG', '64bbb5af-AllSkyImage007038143.JPG', 'aa64576e-AllSkyImage007071188.JPG', '4df23a74-AllSkyImage007037483.JPG', '4461b77c-AllSkyImage007071010.JPG', '583ded47-AllSkyImage007037641.JPG', '70be1828-AllSkyImage007040259.JPG', 'ec45487f-AllSkyImage007127809.JPG', '9e3803c7-AllSkyImage007071524.JPG', 'a3cf883a-AllSkyImage007038255.JPG', 'f375bfdc-AllSkyImage007071384.JPG', '4cc3ba5d-AllSkyImage007071065.JPG', 'ce6cf17b-AllSkyImage007039367.JPG', '0eaf0436-AllSkyImage007039125.JPG', '1ffdd516-AllSkyImage007071611.JPG', 'a0c5879b-AllSkyImage007072427.JPG', '704eac63-AllSkyImage007039543.JPG', '77f8922a-AllSkyImage007071467.JPG', '8552bcf4-AllSkyImage007037735.JPG', '95925d60-AllSkyImage007127559.JPG', '92949009-AllSkyImage007071336.JPG', '240b2d5e-AllSkyImage007039248.JPG', '36d9f2bb-AllSkyImage007071038.JPG', '728b473d-AllSkyImage007039262.JPG', 'e3727963-AllSkyImage007071135.JPG', 'e908b769-AllSkyImage007072790.JPG', '18d22a1a-AllSkyImage007072843.JPG', '7ad337c6-AllSkyImage007071410.JPG', '4325e844-AllSkyImage007072351.JPG', '1f97b648-AllSkyImage007039132.JPG', '1f6ad1f4-AllSkyImage007127941.JPG', '59d98276-AllSkyImage007072678.JPG', '4b776c86-AllSkyImage007037626.JPG', '7897fd67-AllSkyImage007071391.JPG', 'c356139c-AllSkyImage007071161.JPG', '55b5fbc2-AllSkyImage007071023.JPG', 'f71644a6-AllSkyImage007037697.JPG', '39a1adb1-AllSkyImage007037707.JPG', '1cdfb1e7-AllSkyImage007038208.JPG', '0cb8a306-AllSkyImage007071895.JPG', '3daf5e4e-AllSkyImage007038707.JPG', '298fd424-AllSkyImage007072441.JPG', 'f4e11068-AllSkyImage007071036.JPG', 'b56b2376-AllSkyImage007071362.JPG', '081e6952-AllSkyImage007037503.JPG', 'dd75576d-AllSkyImage007039263.JPG', 'd86cc8a4-AllSkyImage007071027.JPG', '9caa602f-AllSkyImage007071293.JPG', '1277f52c-AllSkyImage007037623.JPG', '6972c4e0-AllSkyImage007127753.JPG', '6685dd3d-AllSkyImage007071877.JPG', '2c02f6d7-AllSkyImage007039307.JPG', 'c9422602-AllSkyImage007040260.JPG', '63cf31eb-AllSkyImage007071464.JPG', '24f896ac-AllSkyImage007037527.JPG', '9549cbea-AllSkyImage007073573.JPG', '449d4f45-AllSkyImage007039346.JPG', 'b021864c-AllSkyImage007127540.JPG', '30e9d499-AllSkyImage007072755.JPG', '9877b794-AllSkyImage007072792.JPG', 'def20531-AllSkyImage007039424.JPG', '629ed47c-AllSkyImage007037593.JPG', '732c4417-AllSkyImage007039232.JPG', 'c3278ac1-AllSkyImage007072775.JPG', 'd4a9c051-AllSkyImage007038129.JPG', 'ae51b25f-AllSkyImage007071063.JPG', '5a4491ca-AllSkyImage007071026.JPG', 'cfcc3bdf-AllSkyImage007072478.JPG', '3a90fe8b-AllSkyImage007072320.JPG', 'd8dd6983-AllSkyImage007037471.JPG', 'bda62e72-AllSkyImage007039126.JPG', '380f1c80-AllSkyImage007039154.JPG', 'b0bee7b1-AllSkyImage007037592.JPG', 'f9a52af1-AllSkyImage007039727.JPG', '058f9fe6-AllSkyImage007071366.JPG', '2a12c81a-AllSkyImage007072377.JPG', '00aa267e-AllSkyImage007039372.JPG', 'ac5d8157-AllSkyImage007071115.JPG', 'e68a539d-AllSkyImage007038257.JPG', 'f9087737-AllSkyImage007071339.JPG', '60563257-AllSkyImage007039412.JPG', '21b75e22-AllSkyImage007072630.JPG', '7b7e7e0f-AllSkyImage007071827.JPG', '0c5fb185-AllSkyImage007071612.JPG', '3cea9628-AllSkyImage007037439.JPG', '2246b164-AllSkyImage007071002.JPG', '43fe52c8-AllSkyImage007073612.JPG', '804fced7-AllSkyImage007071314.JPG', '984c00f9-AllSkyImage007127669.JPG', '9a8313eb-AllSkyImage007071382.JPG', '8c267634-AllSkyImage007071444.JPG', '2825ecf6-AllSkyImage007039158.JPG', '03a18f39-AllSkyImage007039134.JPG', 'bb664c61-AllSkyImage007039243.JPG', '7b922b06-AllSkyImage007039231.JPG', '16a41bc3-AllSkyImage007039406.JPG', '0258030e-AllSkyImage007072366.JPG', '23837a92-AllSkyImage007071289.JPG', 'e5005604-AllSkyImage007039347.JPG', 'ea434bbc-AllSkyImage007072602.JPG', 'f5fd061e-AllSkyImage007071324.JPG', 'd0d35741-AllSkyImage007071374.JPG', '7446e587-AllSkyImage007039371.JPG', '96e8462b-AllSkyImage007039128.JPG', '12d3ead4-AllSkyImage007039331.JPG', 'e86fb480-AllSkyImage007038263.JPG', 'c29064cb-AllSkyImage007037701.JPG', 'c4f44892-AllSkyImage007037709.JPG', '374b227e-AllSkyImage007071407.JPG', 'ba65a286-AllSkyImage007072496.JPG', '0920986e-AllSkyImage007072798.JPG', '6467bea9-AllSkyImage007040252.JPG', 'fe041f0c-AllSkyImage007071829.JPG', '53456f9b-AllSkyImage007038309.JPG', '4dafd6a0-AllSkyImage007038492.JPG', 'fa862128-AllSkyImage007037596.JPG', 'cc20fa01-AllSkyImage007071062.JPG', '889ce4e4-AllSkyImage007038282.JPG', 'bef9462b-AllSkyImage007039156.JPG', 'fb65c0c3-AllSkyImage007037599.JPG', 'c33e4c66-AllSkyImage007039508.JPG', '1f5229c4-AllSkyImage007072609.JPG', 'b02b4910-AllSkyImage007037725.JPG', '74e6cfa6-AllSkyImage007039213.JPG', '45f4e8ac-AllSkyImage007037488.JPG', 'd1dcf129-AllSkyImage007039304.JPG', 'd0a9804e-AllSkyImage007038075.JPG', 'f5decdcf-AllSkyImage007071176.JPG', '51f431fc-AllSkyImage007072371.JPG', 'ea562d0a-AllSkyImage007037427.JPG', '6a7c5b9d-AllSkyImage007037706.JPG', '39707942-AllSkyImage007038035.JPG', 'ca52622e-AllSkyImage007072255.JPG', '981942ca-AllSkyImage007071230.JPG', '7a135425-AllSkyImage007037667.JPG', '2c30388f-AllSkyImage007072666.JPG', 'db3cf19a-AllSkyImage007039127.JPG', 'a93fb9e1-AllSkyImage007072317.JPG', '750288d4-AllSkyImage007071215.JPG', '633e30db-AllSkyImage007072693.JPG', '7cfbc262-AllSkyImage007072439.JPG', '70b2f25a-AllSkyImage007072692.JPG', '66ce0f1e-AllSkyImage007071275.JPG', '12a2271d-AllSkyImage007072436.JPG', 'a1f92c2f-AllSkyImage007072302.JPG', '72641df6-AllSkyImage007127605.JPG', '09ff3530-AllSkyImage007127670_2.JPG', '44ffe989-AllSkyImage007072417.JPG', 'a61389ea-AllSkyImage007072627.JPG', 'fd74657f-AllSkyImage007038390.JPG', '1d515e32-AllSkyImage007072350.JPG', 'ce00e1d8-AllSkyImage007037466.JPG', 'f5c9d88b-AllSkyImage007127814.JPG', '773314ad-AllSkyImage007037595.JPG', '241706bc-AllSkyImage007038490.JPG', 'db0581bb-AllSkyImage007071116.JPG', '337ba48a-AllSkyImage007072829.JPG', 'c0259cb0-AllSkyImage007038365.JPG', 'ebfed955-AllSkyImage007038506.JPG', '9bb3298f-AllSkyImage007039225.JPG', 'e377c4d4-AllSkyImage007071466.JPG', '49215aa3-AllSkyImage007039305.JPG', '2b250481-AllSkyImage007072334.JPG', '5100e0b1-AllSkyImage007071144.JPG', '75bf3f77-AllSkyImage007071461.JPG', 'f62bcc29-AllSkyImage007072402.JPG', '9ebde4a6-AllSkyImage007040283.JPG', 'f41536c7-AllSkyImage007072389.JPG', 'dae80ea9-AllSkyImage007071122.JPG', '92ad9a6a-AllSkyImage007037465.JPG', 'd211f575-AllSkyImage007071001.JPG', 'f7cfb9c8-AllSkyImage007073090.JPG', '4d44fbb3-AllSkyImage007072442.JPG', 'c440791d-AllSkyImage007071323.JPG', 'cb333dfa-AllSkyImage007039245.JPG', 'e561bf06-AllSkyImage007040281.JPG', '6b978ea0-AllSkyImage007127810.JPG', '96259e67-AllSkyImage007037521.JPG', 'cab39b7d-AllSkyImage007039449.JPG', '52f93d86-AllSkyImage007071347.JPG', 'a1e2eddf-AllSkyImage007072629.JPG', 'd7ec43dc-AllSkyImage007072777.JPG', 'c8e15baf-AllSkyImage007072615.JPG', '758e2dff-AllSkyImage007072619.JPG', 'ef310a7f-AllSkyImage007071411.JPG', '5d05067e-AllSkyImage007038254.JPG', '00fd143a-AllSkyImage007072753.JPG', '30eed34f-AllSkyImage007072542.JPG', '9337f449-AllSkyImage007071052.JPG', '105112d1-AllSkyImage007037464.JPG', '2ff6e5c6-AllSkyImage007072494.JPG', 'c8646643-AllSkyImage007039218.JPG', '81bec065-AllSkyImage007071368.JPG', '5e202c41-AllSkyImage007038531.JPG', '094ed999-AllSkyImage007071003.JPG', '12ce1608-AllSkyImage007038074.JPG', 'e1dc18d5-AllSkyImage007071004.JPG', 'b13bb76f-AllSkyImage007037714.JPG', '26eadb12-AllSkyImage007037433.JPG', 'c3eecb2c-AllSkyImage007038090.JPG', 'ba7ac105-AllSkyImage007037694.JPG', '3fdef526-AllSkyImage007071375.JPG', '9f3abf06-AllSkyImage007039368.JPG', '0ccaf9fb-AllSkyImage007071319.JPG', '377fd867-AllSkyImage007127870_2.JPG', '1d630740-AllSkyImage007039433.JPG', '4b517621-AllSkyImage007072665.JPG', 'e8c6c9f1-AllSkyImage007038043.JPG', '52f76561-AllSkyImage007038188.JPG', 'a4fa6cec-AllSkyImage007071465.JPG', 'afe6791a-AllSkyImage007072830.JPG', '016659a8-AllSkyImage007037668.JPG', '7007762a-AllSkyImage007037665.JPG', '5fd2ef9d-AllSkyImage007072395.JPG', 'd70c0fe3-AllSkyImage007070991.JPG', '3ffcd506-AllSkyImage007127837.JPG', '699d08a8-AllSkyImage007071355.JPG', 'eaa96211-AllSkyImage007071386.JPG', '4cec7916-AllSkyImage007039186.JPG', '5d3f4a3b-AllSkyImage007072428.JPG', '1e12b132-AllSkyImage007071364.JPG', '28b84426-AllSkyImage007039327.JPG', 'd723cae1-AllSkyImage007071089.JPG', '3e2f2a06-AllSkyImage007038179.JPG', '6c0a7fc4-AllSkyImage007039308.JPG', 'c6c065ec-AllSkyImage007039408.JPG', 'f420b41e-AllSkyImage007037484.JPG', '16fe978e-AllSkyImage007038034.JPG', '82c94daf-AllSkyImage007038108.JPG', '027c61cd-AllSkyImage007071377.JPG', '51dfc927-AllSkyImage007037461.JPG', '9127f0eb-AllSkyImage007071353.JPG', 'd5666df7-AllSkyImage007039193.JPG', 'a3f02511-AllSkyImage007038159.JPG', 'fea88615-AllSkyImage007038088.JPG', '3bda4370-AllSkyImage007071378.JPG', '240aca7f-AllSkyImage007039493.JPG', 'f901bc26-AllSkyImage007127811.JPG', 'e5513640-AllSkyImage007071825.JPG', '6bb850ab-AllSkyImage007071316.JPG', '7d16172b-AllSkyImage007072543.JPG', '28f5a41c-AllSkyImage007072462.JPG', '4fe5a3f6-AllSkyImage007072713.JPG', '8f228b54-AllSkyImage007038025.JPG', '19c02eb3-AllSkyImage007071225.JPG', '775ffd46-AllSkyImage007072368.JPG', 'e26aba05-AllSkyImage007073590.JPG', '6ecfe521-AllSkyImage007039261.JPG', '0cb13c3a-AllSkyImage007039328.JPG', 'df94728b-AllSkyImage007072676.JPG', '02f93398-AllSkyImage007071354.JPG', '7f70aeb9-AllSkyImage007127752.JPG', '67d6c8aa-AllSkyImage007038410.JPG', '624a2974-AllSkyImage007072597.JPG', 'a0d3d8a3-AllSkyImage007037669.JPG', '7465014e-AllSkyImage007038491.JPG', '5875f47f-AllSkyImage007071309.JPG', 'abbf339f-AllSkyImage007071183.JPG', '09112591-AllSkyImage007072440.JPG', '26d88d3d-AllSkyImage007038224.JPG', '6067e34b-AllSkyImage007072448.JPG', 'ababd50f-AllSkyImage007072550.JPG', '59c04b51-AllSkyImage007037537.JPG', '12a9204d-AllSkyImage007037732.JPG', '5e361f3f-AllSkyImage007071247.JPG', '9e7ce10b-AllSkyImage007072617.JPG', '40911c14-AllSkyImage007039385.JPG', '4176439d-AllSkyImage007039323.JPG', 'c2ac2dff-AllSkyImage007071195.JPG', 'b6a1d94b-AllSkyImage007071064.JPG', '9cfe8761-AllSkyImage007037429.JPG', '5e0b5431-AllSkyImage007072502.JPG', 'dd8b6815-AllSkyImage007071011.JPG', 'b69f7430-AllSkyImage007039423.JPG', '0cfb9c70-AllSkyImage007072591.JPG', '90404149-AllSkyImage007127560.JPG', '166044a6-AllSkyImage007037541.JPG', 'b1bcf04f-AllSkyImage007072391.JPG', 'a1528a59-AllSkyImage007071078.JPG', 'cb23a984-AllSkyImage007037708.JPG', 'bf19fa91-AllSkyImage007071091.JPG', '05b76a6f-AllSkyImage007072610.JPG', '11bb5ff3-AllSkyImage007039253.JPG', '28434e2e-AllSkyImage007071338.JPG', '1c92c92f-AllSkyImage007037500.JPG', '32043bb6-AllSkyImage007037594.JPG', 'b5bd92ba-AllSkyImage007072495.JPG', '9d7c5177-AllSkyImage007072703.JPG', '7fa1b344-AllSkyImage007072283.JPG', '8136525a-AllSkyImage007127670.JPG', 'be4e2cce-AllSkyImage007072527.JPG', '7309edaa-AllSkyImage007071482.JPG', 'bbcc4db3-AllSkyImage007039234.JPG', 'e66c3619-AllSkyImage007071241.JPG', '459f02b8-AllSkyImage007039410.JPG', 'a58e6c86-AllSkyImage007038310.JPG', '8dc4788b-AllSkyImage007072712.JPG', 'd56f1460-AllSkyImage007038277.JPG', '38c9aaa6-AllSkyImage007038412.JPG', '5abf83a2-AllSkyImage007071218_2.JPG', '2f82b25e-AllSkyImage007038145.JPG', '37e8b353-AllSkyImage007071079.JPG', 'a7764670-AllSkyImage007037736.JPG', '22b2f566-AllSkyImage007071370.JPG', 'd93d763b-AllSkyImage007071371.JPG', '04215e70-AllSkyImage007071127.JPG', 'f1e30945-AllSkyImage007039422.JPG', 'f266baeb-AllSkyImage007071472.JPG', 'd2651614-AllSkyImage007072451.JPG', 'd14160c5-AllSkyImage007071291.JPG', 'e2fb126c-AllSkyImage007039310.JPG', '4f97b8f0-AllSkyImage007038394.JPG', '9cc90f31-AllSkyImage007039285.JPG', '67d4e840-AllSkyImage007072528.JPG', '13467202-AllSkyImage007038574.JPG', 'df26576f-AllSkyImage007039321.JPG', '741b5a7e-AllSkyImage007037624.JPG', 'e78c31de-AllSkyImage007037475.JPG', 'd8abf3f1-AllSkyImage007071383.JPG', '0f323c65-AllSkyImage007072587.JPG', 'c00afbab-AllSkyImage007071175.JPG', '3941ab5f-AllSkyImage007072330.JPG', 'bbb9b12c-AllSkyImage007071191.JPG', '115e4a95-AllSkyImage007071087.JPG', '2f4309be-AllSkyImage007038283.JPG', 'faba7bda-AllSkyImage007072540.JPG', '1270674a-AllSkyImage007072388.JPG', '4975efd4-AllSkyImage007037724.JPG', '00c814e6-AllSkyImage007072385.JPG', 'af189cda-AllSkyImage007039259.JPG', 'ce84eb36-AllSkyImage007127867.JPG', '54c9e711-AllSkyImage007072616.JPG', '9c51fd17-AllSkyImage007038142.JPG', 'c1f0957d-AllSkyImage007072321.JPG', '9af09379-AllSkyImage007071330.JPG', '74af7370-AllSkyImage007072446.JPG', '179a9ef3-AllSkyImage007072817.JPG', 'a64ec0d7-AllSkyImage007037546.JPG', '8ac0e34b-AllSkyImage007071678.JPG', 'f5129844-AllSkyImage007071218.JPG', 'fd4cc6c6-AllSkyImage007039146.JPG', 'd83efbe4-AllSkyImage007038171.JPG', '9accd5db-AllSkyImage007072453.JPG', '1cfb8b45-AllSkyImage007071053.JPG', 'f520aed3-AllSkyImage007127840.JPG', 'ebd7265a-AllSkyImage007037511.JPG', 'aa1eb090-AllSkyImage007037664.JPG', 'fb3da18b-AllSkyImage007072273.JPG', 'f99a15b4-AllSkyImage007071433.JPG', 'e162c877-AllSkyImage007071253.JPG', 'b193590d-AllSkyImage007071793.JPG', 'fc68423c-AllSkyImage007037729.JPG', '3e101cb3-AllSkyImage007039155.JPG', 'a7f0e64b-AllSkyImage007039190.JPG', 'd482e0c2-AllSkyImage007072675.JPG', '5c2d9f5c-AllSkyImage007071088.JPG', '8c8adb29-AllSkyImage007038284.JPG', '4ef5b260-AllSkyImage007039395.JPG', '9e81a76b-AllSkyImage007070982.JPG', '70d28252-AllSkyImage007038141.JPG', 'c63e391d-AllSkyImage007039432.JPG', '959ff3c2-AllSkyImage007071381.JPG', '34b2bd3f-AllSkyImage007039696.JPG', 'b837e639-AllSkyImage007071022.JPG', '3272a4f8-AllSkyImage007039494.JPG', '6e4d9ef0-AllSkyImage007072294.JPG', 'c47ed637-AllSkyImage007037607.JPG', '3ea96b89-AllSkyImage007071006.JPG', 'c3190b3f-AllSkyImage007071680.JPG', 'aefe426b-AllSkyImage007071117.JPG', 'dba88808-AllSkyImage007071288.JPG', 'acd152ea-AllSkyImage007071679.JPG', '8522daa8-AllSkyImage007071274.JPG', 'e7cd1e45-AllSkyImage007039220.JPG', '0ff2fd74-AllSkyImage007039233.JPG', '79fd9650-AllSkyImage007071136.JPG', 'e7d288f9-AllSkyImage007072454.JPG', '7c040416-AllSkyImage007039699.JPG', '0b50272c-AllSkyImage007127942.JPG', '6238beb6-AllSkyImage007072460.JPG', '57a04af9-AllSkyImage007071009.JPG', '379449b0-AllSkyImage007039309.JPG', 'ca0d0892-AllSkyImage007072382.JPG', '62e2e8ca-AllSkyImage007038307.JPG', 'e20e57e0-AllSkyImage007071356.JPG', 'c7c4a6a0-AllSkyImage007039324.JPG', '3ef1a7d2-AllSkyImage007072405.JPG', '43159753-AllSkyImage007072608.JPG', 'f4b2aef0-AllSkyImage007071125.JPG', 'f558666d-AllSkyImage007039256.JPG', 'ba93469b-AllSkyImage007039411.JPG', 'd1fb9ce8-AllSkyImage007072680.JPG', '45a789ff-AllSkyImage007071276.JPG', '3ae32525-AllSkyImage007038042.JPG', '42470dc8-AllSkyImage007072776.JPG', 'a6cf41d0-AllSkyImage007071358.JPG', '9630e5c6-AllSkyImage007071367.JPG', 'ddb6159f-AllSkyImage007070999.JPG', '751604ce-AllSkyImage007071312.JPG', 'ff599da1-AllSkyImage007039329.JPG', 'e047c0b4-AllSkyImage007073576.JPG', '776c8c4d-AllSkyImage007037602.JPG', '8fc19f7f-AllSkyImage007072754.JPG', '29ef31af-AllSkyImage007039336.JPG', '578fb374-AllSkyImage007072612.JPG', 'b4b5b4a6-AllSkyImage007127784.JPG', 'eeab4a5e-AllSkyImage007037737.JPG', '884aa9d5-AllSkyImage007037430.JPG', '49e6df9c-AllSkyImage007039698.JPG', '11500561-AllSkyImage007039399.JPG', '6ae11ba1-AllSkyImage007039273.JPG', '37cd0a3d-AllSkyImage007039388.JPG', '2124b020-AllSkyImage007037434.JPG', '9a4175fc-AllSkyImage007072455.JPG', '10a16234-AllSkyImage007072378.JPG', '4c659757-AllSkyImage007038392.JPG', 'b21ebbb7-AllSkyImage007037620.JPG', '61c145fc-AllSkyImage007039352.JPG', 'ef413deb-AllSkyImage007039188.JPG', 'abe7476d-AllSkyImage007072450.JPG', 'f96a786a-AllSkyImage007039655.JPG', '92137ccc-AllSkyImage007071301.JPG', '0aa0cd25-AllSkyImage007072799.JPG', 'e3cd4082-AllSkyImage007071141.JPG', '71bd7eab-AllSkyImage007037432.JPG', '870e2b01-AllSkyImage007073574.JPG', 'e1678f8b-AllSkyImage007037467.JPG', '7d549314-AllSkyImage007039435.JPG', '41b2c98a-AllSkyImage007071313.JPG', '34d9e21b-AllSkyImage007072650.JPG', '3f3bf93e-AllSkyImage007072373.JPG', 'dc124dd2-AllSkyImage007038635.JPG', '226d75b9-AllSkyImage007072284.JPG', '26fe9d25-AllSkyImage007037497.JPG', '7162f156-AllSkyImage007038178.JPG', 'c8354a31-AllSkyImage007038128.JPG', 'ef5fca2b-AllSkyImage007038262.JPG', 'e9503bbe-AllSkyImage007038241.JPG', '13705ce8-AllSkyImage007071445.JPG', '83bedf9d-AllSkyImage007072404.JPG', 'c87fb036-AllSkyImage007039222.JPG', '84f8247e-AllSkyImage007072384.JPG', 'c83dca40-AllSkyImage007039287.JPG', '7c9bf55a-AllSkyImage007038411.JPG', '96eda1a0-AllSkyImage007072332.JPG', 'b1ff2099-AllSkyImage007127869.JPG', '298e5100-AllSkyImage007071124.JPG', 'a911304e-AllSkyImage007039337.JPG', 'ce1e3cd6-AllSkyImage007039694.JPG', '8ea1a8bb-AllSkyImage007039326.JPG', '7a06a1f0-AllSkyImage007071484.JPG', '9f997ebc-AllSkyImage007071372.JPG', '78ccda87-AllSkyImage007072778.JPG', '65e46229-AllSkyImage007072531.JPG', '430d82ea-AllSkyImage007072626.JPG', 'cd2b9f09-AllSkyImage007127950.JPG', 'f750bf8e-AllSkyImage007037625.JPG', 'da677f0c-AllSkyImage007072805.JPG', '024861a4-AllSkyImage007127606.JPG', 'fb5f2296-AllSkyImage007070985.JPG']\n",
            "size of training set 820\n",
            "size of testing set 205\n",
            "Overall Number of Images Input into Model: 1025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "#3. Download Tensorflow Object Detection API and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7667b4c9-332e-44cd-d310-8e681fc758d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 89900, done.\u001b[K\n",
            "remote: Counting objects: 100% (3612/3612), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1929/1929), done.\u001b[K\n",
            "remote: Total 89900 (delta 1914), reused 3279 (delta 1645), pack-reused 86288\u001b[K\n",
            "Receiving objects: 100% (89900/89900), 606.56 MiB | 6.64 MiB/s, done.\n",
            "Resolving deltas: 100% (63812/63812), done.\n"
          ]
        }
      ],
      "source": [
        "#This downloads the object detection API\n",
        "if not os.path.exists(os.path.join(folderpaths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {folderpaths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb1d3b8-7246-4b1c-82c6-8268db701ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.5)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.14.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.1.78)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.15.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.15.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.59.2)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (23.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.0,!=4.24.1,!=4.24.2,<4.25.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.34.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras (from object-detection==0.1)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.41.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697354 sha256=6e204811fa903fbdd5ebcb2f70b73ec99fa1e8b9436ccaffa393fec1d4996fd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2o6l9an4/wheels/fb/c9/43/709f88e66b36649c7a29812ca4f6236f31caed949aabc3e335\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43993 sha256=a537f3246ec0606f0299f26e2b2e9e96f72c25c5836f0e544692ae09ada1b5cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=ff180e4b4074c35cfcc50acde4ff6b3785d7d1052ba45d6710f098655b986d01\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=b221c1faec93bb64a7ee76b8f1a28becd2dfc51a379fa5e6a694f35a85d15155\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=3870fef1fb3192c6e6193f0862101342c4d98213b971f97bf608083254c1be06\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=ff7a282002852f73462d9559c21fd321f3ae4a87db517dbb7451849ab9674843\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25985 sha256=7262a36ed3a71ecfcdc0b0f7d9621e51026fad7ecf948980072c3d916f5e73f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=00eb5b7244f7c015ed1c4d1f84a8ddb76cb89493dd4988559282e424eb42ee05\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n",
            "Installing collected packages: sentencepiece, pyjsparser, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyparsing, portalocker, orjson, objsize, keras, js2py, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed apache-beam-2.51.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.9.0 fasteners-0.19 hdfs-2.7.3 immutabledict-3.0.0 js2py-0.74 keras-2.15.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.10 portalocker-2.8.2 pyjsparser-2.7.1 pymongo-4.6.0 pyparsing-2.4.7 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tensorflow_io-0.34.0 tf-models-official-2.15.0 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "#Converts .protoc files into readable .py format\n",
        "!apt-get install protobuf-compiler\n",
        "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This seems to be the necessary version of tensorflow (doesn't seem to work with tensorflow==2.14.0)\n",
        "!pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "id": "dF5Ei6QzGGJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32528e8-998f-4b02-bf75-eadec181e76a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.59.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\n",
            "tf-models-official 2.15.0 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "scrolled": true,
        "id": "5kPfJLfRCydF",
        "outputId": "130578fc-ebab-49ac-83f0-45f73713ae98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-17 08:20:07.658537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-17 08:20:08.616457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-17 08:20:11.020505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:11.611761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:11.612030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-11-17 08:20:11.620157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:11.620456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:11.620621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:12.560670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:12.560971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:12.561146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 08:20:12.561277: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-17 08:20:12.561317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1117 08:20:12.742270 132814314062976 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1117 08:20:13.034600 132814314062976 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.72s\n",
            "I1117 08:20:13.338681 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.72s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "I1117 08:20:13.911790 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n",
            "I1117 08:20:14.222619 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.48s\n",
            "I1117 08:20:14.701252 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.28s\n",
            "I1117 08:20:16.977116 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1117 08:20:16.983990 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1117 08:20:17.013945 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1117 08:20:17.032321 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1117 08:20:17.051144 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "I1117 08:20:17.167190 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "I1117 08:20:17.305275 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I1117 08:20:17.442611 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "I1117 08:20:17.576644 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "I1117 08:20:17.696786 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I1117 08:20:17.733382 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1117 08:20:17.941640 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1117 08:20:17.941785 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1117 08:20:17.941835 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1117 08:20:17.944575 132814314062976 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1117 08:20:17.985893 132814314062976 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1117 08:20:17.986051 132814314062976 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1117 08:20:18.089274 132814314062976 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1117 08:20:18.089421 132814314062976 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1117 08:20:18.315203 132814314062976 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1117 08:20:18.315352 132814314062976 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1117 08:20:18.566854 132814314062976 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1117 08:20:18.567025 132814314062976 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1117 08:20:18.878866 132814314062976 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1117 08:20:18.879019 132814314062976 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1117 08:20:19.208268 132814314062976 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1117 08:20:19.208419 132814314062976 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1117 08:20:19.617195 132814314062976 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1117 08:20:19.617345 132814314062976 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1117 08:20:19.718336 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1117 08:20:19.779013 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:19.844849 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1117 08:20:19.845044 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1117 08:20:19.845135 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1117 08:20:19.848468 132814314062976 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1117 08:20:19.869983 132814314062976 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1117 08:20:19.870105 132814314062976 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1117 08:20:20.063630 132814314062976 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1117 08:20:20.063806 132814314062976 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1117 08:20:20.374575 132814314062976 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1117 08:20:20.374732 132814314062976 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1117 08:20:20.705130 132814314062976 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1117 08:20:20.705305 132814314062976 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1117 08:20:21.396531 132814314062976 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1117 08:20:21.396680 132814314062976 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1117 08:20:21.839827 132814314062976 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1117 08:20:21.839973 132814314062976 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1117 08:20:22.359682 132814314062976 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1117 08:20:22.359836 132814314062976 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1117 08:20:22.553816 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1117 08:20:22.588453 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:22.654870 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1117 08:20:22.655015 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1117 08:20:22.655071 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1117 08:20:22.657117 132814314062976 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1117 08:20:22.676143 132814314062976 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1117 08:20:22.676283 132814314062976 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1117 08:20:22.836322 132814314062976 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1117 08:20:22.836465 132814314062976 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1117 08:20:23.121003 132814314062976 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1117 08:20:23.121185 132814314062976 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1117 08:20:23.414439 132814314062976 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1117 08:20:23.414583 132814314062976 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1117 08:20:23.822348 132814314062976 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1117 08:20:23.822497 132814314062976 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1117 08:20:24.214491 132814314062976 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1117 08:20:24.214635 132814314062976 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1117 08:20:24.724009 132814314062976 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1117 08:20:24.724219 132814314062976 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1117 08:20:24.933288 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1117 08:20:24.975711 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:25.043437 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1117 08:20:25.043577 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1117 08:20:25.043630 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1117 08:20:25.045602 132814314062976 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1117 08:20:25.068247 132814314062976 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1117 08:20:25.068362 132814314062976 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1117 08:20:25.234317 132814314062976 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1117 08:20:25.234457 132814314062976 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1117 08:20:25.523902 132814314062976 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1117 08:20:25.524055 132814314062976 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1117 08:20:25.804038 132814314062976 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1117 08:20:25.804202 132814314062976 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1117 08:20:26.265579 132814314062976 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1117 08:20:26.265737 132814314062976 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1117 08:20:26.713315 132814314062976 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1117 08:20:26.713470 132814314062976 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1117 08:20:27.248887 132814314062976 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1117 08:20:27.249030 132814314062976 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1117 08:20:27.436700 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1117 08:20:27.475839 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:27.543158 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1117 08:20:27.543308 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1117 08:20:27.543358 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1117 08:20:27.545207 132814314062976 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1117 08:20:27.565108 132814314062976 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1117 08:20:27.565227 132814314062976 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1117 08:20:27.713908 132814314062976 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1117 08:20:27.714064 132814314062976 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1117 08:20:28.105599 132814314062976 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1117 08:20:28.105753 132814314062976 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1117 08:20:28.470959 132814314062976 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1117 08:20:28.471104 132814314062976 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1117 08:20:29.003643 132814314062976 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1117 08:20:29.003789 132814314062976 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1117 08:20:29.814915 132814314062976 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1117 08:20:29.815058 132814314062976 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1117 08:20:30.555930 132814314062976 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1117 08:20:30.556074 132814314062976 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1117 08:20:30.745715 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1117 08:20:30.783661 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:30.861728 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1117 08:20:30.861870 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1117 08:20:30.861944 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1117 08:20:30.863789 132814314062976 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1117 08:20:30.881541 132814314062976 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1117 08:20:30.881644 132814314062976 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1117 08:20:31.097128 132814314062976 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1117 08:20:31.097302 132814314062976 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1117 08:20:31.540025 132814314062976 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1117 08:20:31.540186 132814314062976 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1117 08:20:32.004031 132814314062976 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1117 08:20:32.004192 132814314062976 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1117 08:20:32.630443 132814314062976 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1117 08:20:32.630588 132814314062976 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1117 08:20:33.260078 132814314062976 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1117 08:20:33.260253 132814314062976 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1117 08:20:34.073365 132814314062976 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1117 08:20:34.073514 132814314062976 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1117 08:20:34.352540 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1117 08:20:34.389689 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:34.482216 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1117 08:20:34.482400 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1117 08:20:34.482468 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1117 08:20:34.484405 132814314062976 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1117 08:20:34.505962 132814314062976 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1117 08:20:34.506082 132814314062976 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1117 08:20:34.735567 132814314062976 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1117 08:20:34.735706 132814314062976 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1117 08:20:35.273823 132814314062976 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1117 08:20:35.273963 132814314062976 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1117 08:20:35.819013 132814314062976 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1117 08:20:35.819192 132814314062976 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1117 08:20:36.550059 132814314062976 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1117 08:20:36.550233 132814314062976 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1117 08:20:37.313737 132814314062976 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1117 08:20:37.313911 132814314062976 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1117 08:20:38.673878 132814314062976 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1117 08:20:38.674024 132814314062976 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1117 08:20:38.985037 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1117 08:20:39.027787 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1117 08:20:39.132538 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1117 08:20:39.132682 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1117 08:20:39.132731 132814314062976 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1117 08:20:39.134654 132814314062976 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1117 08:20:39.156851 132814314062976 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1117 08:20:39.156985 132814314062976 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1117 08:20:39.455170 132814314062976 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1117 08:20:39.455357 132814314062976 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1117 08:20:40.096966 132814314062976 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1117 08:20:40.097113 132814314062976 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1117 08:20:40.767514 132814314062976 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1117 08:20:40.767666 132814314062976 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1117 08:20:41.718024 132814314062976 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1117 08:20:41.718233 132814314062976 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1117 08:20:42.655435 132814314062976 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1117 08:20:42.655575 132814314062976 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1117 08:20:43.860855 132814314062976 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1117 08:20:43.861026 132814314062976 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1117 08:20:44.239378 132814314062976 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1117 08:20:44.278031 132814314062976 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.66s\n",
            "I1117 08:20:44.396450 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.66s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1117 08:20:44.424751 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1117 08:20:44.426354 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1117 08:20:44.426761 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1117 08:20:44.428066 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1117 08:20:44.429293 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1117 08:20:44.429653 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1117 08:20:44.430551 132814314062976 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 32.816s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(folderpaths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# verify if the installation has worked\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Wf1uctD4CydJ"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "660b301b-492b-4742-87c3-886fff53ef83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-17 08:20:46--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.79.207, 108.177.96.207, 108.177.126.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.79.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90453990 (86M) [application/x-tar]\n",
            "Saving to: ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "\n",
            "ssd_mobilenet_v1_fp 100%[===================>]  86.26M  32.4MB/s    in 2.7s    \n",
            "\n",
            "2023-11-17 08:20:49 (32.4 MB/s) - ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz saved [90453990/90453990]\n",
            "\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "#This downloads the actual model you plan to use from TF2 model zoo and moves it\n",
        "!wget {PRETRAINED_MODEL_URL}\n",
        "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {folderpaths['PRETRAINED_MODEL_PATH']}\n",
        "!cd {folderpaths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 4. Create Label Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "#The machine will class objects as numbers, so we introduce label mapping to map those numbers back to recognisable names of our distinct object groups\n",
        "labels = [{'name':'Aircraft', 'id':1},{'name':'Non-Aircraft', 'id':2}]\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "#5. Create TF records files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KWpb_BVUpfDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8b3f22-c6a9-4765-9fd1-deca4fd84b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {folderpaths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "5ec3a0e0-34d3-446c-8bf4-0eccf5b3a50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "#This code converts our xml annotations into a machine readable TFRecord file format\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(folderpaths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(folderpaths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(folderpaths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(folderpaths['ANNOTATION_PATH'], 'test.record')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 6. Copy Model Configuration File to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "!cp {os.path.join(folderpaths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(folderpaths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 7. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is where we adjust hyperparameters of our model either to configure the model to simply work on our input data, or to optimise it for best performance."
      ],
      "metadata": {
        "id": "6luxwrR0Fy43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.train_config.batch_size = 24\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(folderpaths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(folderpaths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(folderpaths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change {model_name} pipeline_config.model.{model_name}.num_classes to the name listed in the general config file\n",
        "pipeline_config.model.ssd.num_classes = len(labels)\n"
      ],
      "metadata": {
        "id": "Yw5J5ujVSoAL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "3ENVepLAJtgL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIlsg1T-q7_4",
        "outputId": "c28ca97a-e817-4ba5-b4d9-20a7f961a7d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 2\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v1_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 256\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 24\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.03999999910593033\n",
              "         total_steps: 25000\n",
              "         warmup_learning_rate: 0.013333000242710114\n",
              "         warmup_steps: 2000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              " num_steps: 25000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"detection\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false\n",
              " batch_size: 1,\n",
              " 'eval_input_configs': [label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "#8. Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We specify the number of training steps we want to have the model learn for"
      ],
      "metadata": {
        "id": "3wTKNyLHGARw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(folderpaths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=7500\".format(TRAINING_SCRIPT, folderpaths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "40fa4cb6-c1c4-41ab-dfc7-77e2420eb769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet/pipeline.config --num_train_steps=7500\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "0242acdc-8d2f-4508-e45b-753541bedd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-17 08:21:04.072768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-17 08:21:07.340595: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1117 08:21:07.341691 135342548780160 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 7500\n",
            "I1117 08:21:07.362831 135342548780160 config_util.py:552] Maybe overwriting train_steps: 7500\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1117 08:21:07.362987 135342548780160 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1117 08:21:07.387875 135342548780160 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1117 08:21:07.393946 135342548780160 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1117 08:21:07.394087 135342548780160 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1117 08:21:07.394141 135342548780160 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1117 08:21:07.394198 135342548780160 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1117 08:21:07.400129 135342548780160 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1117 08:21:07.417020 135342548780160 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1117 08:21:13.522624 135342548780160 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1117 08:21:15.940334 135342548780160 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1117 08:21:17.419015 135342548780160 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I1117 08:21:23.922287 135335308662336 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1117 08:21:35.120087 135335308662336 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.384236 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.386866 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.387871 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.388744 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.392073 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.392943 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.393860 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.394758 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.398905 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1117 08:21:52.399762 135342548780160 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1117 08:21:53.707038 135334813754944 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I1117 08:21:54.347608 135334813754944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1117 08:22:03.104818 135334813754944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1117 08:22:11.426335 135334813754944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1117 08:22:19.800306 135334813754944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Step 100 per-step time 1.752s\n",
            "I1117 08:24:48.270468 135342548780160 model_lib_v2.py:705] Step 100 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.479565,\n",
            " 'Loss/localization_loss': 0.24427535,\n",
            " 'Loss/regularization_loss': 0.781781,\n",
            " 'Loss/total_loss': 1.5056213,\n",
            " 'learning_rate': 0.014666351}\n",
            "I1117 08:24:48.270810 135342548780160 model_lib_v2.py:708] {'Loss/classification_loss': 0.479565,\n",
            " 'Loss/localization_loss': 0.24427535,\n",
            " 'Loss/regularization_loss': 0.781781,\n",
            " 'Loss/total_loss': 1.5056213,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.213s\n",
            "I1117 08:26:49.566474 135342548780160 model_lib_v2.py:705] Step 200 per-step time 1.213s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2908511,\n",
            " 'Loss/localization_loss': 0.15309636,\n",
            " 'Loss/regularization_loss': 0.78098845,\n",
            " 'Loss/total_loss': 1.2249359,\n",
            " 'learning_rate': 0.0159997}\n",
            "I1117 08:26:49.566761 135342548780160 model_lib_v2.py:708] {'Loss/classification_loss': 0.2908511,\n",
            " 'Loss/localization_loss': 0.15309636,\n",
            " 'Loss/regularization_loss': 0.78098845,\n",
            " 'Loss/total_loss': 1.2249359,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.212s\n",
            "I1117 08:28:50.763730 135342548780160 model_lib_v2.py:705] Step 300 per-step time 1.212s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25208622,\n",
            " 'Loss/localization_loss': 0.19030184,\n",
            " 'Loss/regularization_loss': 0.7800899,\n",
            " 'Loss/total_loss': 1.2224779,\n",
            " 'learning_rate': 0.01733305}\n",
            "I1117 08:28:50.764052 135342548780160 model_lib_v2.py:708] {'Loss/classification_loss': 0.25208622,\n",
            " 'Loss/localization_loss': 0.19030184,\n",
            " 'Loss/regularization_loss': 0.7800899,\n",
            " 'Loss/total_loss': 1.2224779,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.213s\n",
            "I1117 08:30:52.027025 135342548780160 model_lib_v2.py:705] Step 400 per-step time 1.213s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2565492,\n",
            " 'Loss/localization_loss': 0.19768299,\n",
            " 'Loss/regularization_loss': 0.77913034,\n",
            " 'Loss/total_loss': 1.2333626,\n",
            " 'learning_rate': 0.0186664}\n",
            "I1117 08:30:52.027324 135342548780160 model_lib_v2.py:708] {'Loss/classification_loss': 0.2565492,\n",
            " 'Loss/localization_loss': 0.19768299,\n",
            " 'Loss/regularization_loss': 0.77913034,\n",
            " 'Loss/total_loss': 1.2333626,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.211s\n",
            "I1117 08:32:53.158493 135342548780160 model_lib_v2.py:705] Step 500 per-step time 1.211s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24547829,\n",
            " 'Loss/localization_loss': 0.23696718,\n",
            " 'Loss/regularization_loss': 0.77809626,\n",
            " 'Loss/total_loss': 1.2605418,\n",
            " 'learning_rate': 0.01999975}\n",
            "I1117 08:32:53.158804 135342548780160 model_lib_v2.py:708] {'Loss/classification_loss': 0.24547829,\n",
            " 'Loss/localization_loss': 0.23696718,\n",
            " 'Loss/regularization_loss': 0.77809626,\n",
            " 'Loss/total_loss': 1.2605418,\n",
            " 'learning_rate': 0.01999975}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "#9. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, folderpaths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], folderpaths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsgEPx9pfDH"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqTV2jGBpfDH"
      },
      "outputs": [],
      "source": [
        "#exit after all printed out - runs perpetually\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dashboard to visualise Training and Testing results"
      ],
      "metadata": {
        "id": "Wr-Y2JdWm8l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "lnvTVz73h-9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=/content/Tensorflow/workspace/models/{CUSTOM_MODEL_NAME}/train\n"
      ],
      "metadata": {
        "id": "VVxp24GbnH41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=/content/Tensorflow/workspace/models/{CUSTOM_MODEL_NAME}/eval --port 6008\n",
        "#/content/Tensorflow/workspace/models/inception_resnet_v2_640x640/eval"
      ],
      "metadata": {
        "id": "Sdz_EEr5nIMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{CUSTOM_MODEL_NAME}"
      ],
      "metadata": {
        "id": "zEmQBqJunIj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "#10. Load Train Model From Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model - we can replace files['PIPELINE_CONFIG'] and folderpaths['CHECKPOINT_PATH'] and 'ckpt-3'\n",
        "\n",
        "checkpoint_number = 6  # Replace with the actual checkpoint number you want to restore\n",
        "\n",
        "checkpoint_path = os.path.join(folderpaths['CHECKPOINT_PATH'], f'ckpt-{checkpoint_number}')\n",
        "\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(checkpoint_path).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 11. Detect from an Image - Using the model we just loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "pQpgFDSUQ2il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell specifies the folder with ML predictions/results that you want to visualise - and collects the filenames of the images within.\n",
        "import os\n",
        "import random\n",
        "IMAGE_PATHS = []\n",
        "# Directory path\n",
        "directory_path = \"Tensorflow/workspace/images/test\"  # Replace with your directory path\n",
        "\n",
        "# List all files in the directory that end with \".jpg\"\n",
        "jpg_files = [f for f in os.listdir(directory_path) if f.endswith(\".JPG\")]\n",
        "\n",
        "# Get the full file paths\n",
        "file_paths = [os.path.join(directory_path, file) for file in jpg_files]\n",
        "\n",
        "# Print the selected file paths\n",
        "for file_path in file_paths:\n",
        "    IMAGE_PATHS.append(file_path)\n"
      ],
      "metadata": {
        "id": "bqxvIU_ptCRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# Create a directory to store annotated images\n",
        "output_dir = \"machine_annotated_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Counter for image file naming\n",
        "image_counter = 0\n",
        "\n",
        "# List to store annotated frames\n",
        "annotated_frames = []\n",
        "\n",
        "# Loop through the image paths\n",
        "for IMAGE_PATH in IMAGE_PATHS:\n",
        "    img = cv2.imread(IMAGE_PATH)\n",
        "    image_np = np.array(img)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'] + label_id_offset,\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=5,\n",
        "        min_score_thresh=0.3,  # Edit\n",
        "        agnostic_mode=False\n",
        "    )\n",
        "\n",
        "    # Append the annotated frame to the list\n",
        "    annotated_frames.append(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UOXi68mX2MB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to store annotated images\n",
        "output_dir = \"machine_annotated_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for index, annotated_frame in enumerate(annotated_frames):\n",
        "    # Save the machine annotated frame as a JPG file\n",
        "    output_image_path = os.path.join(output_dir, jpg_files[index])\n",
        "    cv2.imwrite(output_image_path, cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "id": "9aQyTdBzmVKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Store outputted data/configs/records in google drive or elsewhere\n"
      ],
      "metadata": {
        "id": "_vPUEQ9AbSg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adjust below version number to represent that this is the nth time you have built a trail detection model with this model's architecture type (specified in {CUSTOM_MODEL_NAME})\n",
        "version = 4\n",
        "\n",
        "# Convert CUSTOM_MODEL_NAME to lowercase\n",
        "custom_model_name = CUSTOM_MODEL_NAME.lower()\n",
        "\n",
        "# Replace {len(train_files) + len(test_files)} with the actual value\n",
        "total_images = len(train_files) + len(test_files)  # replace with your actual values\n",
        "\n",
        "\n",
        "# Set the source and destination folders\n",
        "source_folder = f'Tensorflow/workspace/models/{custom_model_name}'\n",
        "destination_folder = f'/content/drive/MyDrive/aircraftimage/output/{custom_model_name}_version_{version}_{total_images}_images'"
      ],
      "metadata": {
        "id": "tcGmDQ0O2MgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_video_path = f\"output_video_{custom_model_name}_version_{version}.mp4\"\n",
        "\n",
        "fps = 1\n",
        "\n",
        "image_files = [os.path.join(output_dir, jpg) for jpg in os.listdir(output_dir)]\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (annotated_frames[0].shape[1], annotated_frames[0].shape[0]))\n",
        "\n",
        "for image_file in image_files:\n",
        "    img = cv2.imread(image_file)\n",
        "    video_writer.write(img)\n",
        "\n",
        "video_writer.release()\n",
        "\n",
        "shutil.move(output_video_path,source_folder)"
      ],
      "metadata": {
        "id": "jKMf6Eho9LWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/machine_annotated_images',source_folder)"
      ],
      "metadata": {
        "id": "God0AmQqyvLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Copy individual files and folders from the source folder to the destination folder\n",
        "for item in os.listdir(source_folder):\n",
        "    src_item = os.path.join(source_folder, item)\n",
        "    dest_item = os.path.join(destination_folder, item)\n",
        "\n",
        "    if os.path.isdir(src_item):\n",
        "        shutil.copytree(src_item, dest_item)\n",
        "        print(f'Moved directory {src_item} to {dest_item}')\n",
        "    else:\n",
        "        shutil.copy(src_item, dest_item)\n",
        "        print(f'Moved file {src_item} to {dest_item}')\n"
      ],
      "metadata": {
        "id": "k1qc6yjv21dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unmount Google Drive\n",
        "#drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "KL5lbpyiHv5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#shutil.copytree('machine_annotated_images_30%', destination_folder + '/machine_annotated_images_30%')\n"
      ],
      "metadata": {
        "id": "jJf5E20P-01O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWZnJeRXClnE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}