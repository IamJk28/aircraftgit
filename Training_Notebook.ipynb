{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamJk28/aircraftgit/blob/main/Training_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Notebook\n"
      ],
      "metadata": {
        "id": "u5vAdnVYjGdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will train a model from TF2 Object Detection zoo/API on our aircraft images/Annotations"
      ],
      "metadata": {
        "id": "1LXMdQjVjJML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give the model you are making a name:"
      ],
      "metadata": {
        "id": "5GtwZ2f2jSi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_MODEL_NAME = 'ssd_mobilenet'\n"
      ],
      "metadata": {
        "id": "sD9ACQ0-jVMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ZAKo0jn1kh",
        "outputId": "e3808f68-dc1f-4048-ae6b-22552a4a584f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# this cell allows the google colab session to access your drive contents where we have uploaded images and Annotations\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go to https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "The models listed there can be plugged into our notebook, by copying a given model's link and pasting it into the PRETRAINED_MODEL_URL variable below"
      ],
      "metadata": {
        "id": "xcx-mqVudOfw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hJEdo_pfDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edea6296-3e22-4e85-f634-77402e4064df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Adjust variable names appropriately - using the TF2 Object detection zoo @ https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "#paste the model link from tf2 zoo\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'#Change for different model, get from tf2 zoo\n",
        "\n",
        "# Extract the filename from the URL\n",
        "filename = os.path.basename(PRETRAINED_MODEL_URL)\n",
        "\n",
        "# Remove the file extension (.tar.gz) from the filename\n",
        "model_name = os.path.splitext(filename)[0] #if this extraction of filename doesnt work just paste it in (e.g for PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz' , PRETRAINED_MODEL_NAME = ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8)\n",
        "\n",
        "PRETRAINED_MODEL_NAME = model_name.split('.tar')[0]\n",
        "\n",
        "PRETRAINED_MODEL_NAME"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#choose the name of the image dataset you want to use  currently using 'final_dataset.tar.gz', a tar.gz file containing images/annotations\n",
        "image_dataset = 'final_dataset.tar.gz'"
      ],
      "metadata": {
        "id": "HLQKuucblE_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#don't edit\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "metadata": {
        "id": "ranhJduBkLCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "image resizing:\n",
        "images should be resized so that they are the right input size for the model used. for example, for the model 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8' , the input model size is 640x640 , so below, you would set new_width = 640 etc etc.\n",
        "\n",
        "in the following cells the images and annotations will be automatically resized accordingly.\n"
      ],
      "metadata": {
        "id": "kFtAHoZ5Wh3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_width = 640\n",
        "new_height = 640"
      ],
      "metadata": {
        "id": "1AlyxRCSWtMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Hyperparameters:\n",
        "\n",
        "here we can edit the value of any variables/hyperparameters for our training run:\n",
        "\n",
        "-training_steps: how long the model trains for\n",
        "\n",
        "-batch_size: how many images the model stores in the GPU Ram at any given time whilst training. more = smoother training, but requires more gpu ram - too many = crash/error!\n",
        "\n",
        "\n",
        "you can edit the value of any other hyperparameters by opening the config file in section 7 of this notebook"
      ],
      "metadata": {
        "id": "-l-WfHeWOVYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_steps = 20000\n",
        "batch_size = 40"
      ],
      "metadata": {
        "id": "Mr1_xCT9OQKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "folderpaths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\n",
        "    'TRAIN_PATH':os.path.join('Tensorflow','workspace','images','train'),\n",
        "    'TEST_PATH':os.path.join('Tensorflow','workspace','images','test'),\n",
        "    'COLLECT_PATH':os.path.join('Tensorflow','workspace','images','collectedimages')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(folderpaths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(folderpaths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in folderpaths.values():\n",
        "    if not os.path.exists(path):\n",
        "      !mkdir -p {path}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbiJlptaaKYF"
      },
      "source": [
        "#1. Untar Image and label Archive and move image and label folders to correct location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRTRKIYxHbNc"
      },
      "outputs": [],
      "source": [
        "#replace source_folder0 with link to tar.gz file of images and label folders\n",
        "\n",
        "import shutil\n",
        "\n",
        "source_folder0 = \"drive/MyDrive/aircraftimage/final_dataset.tar.gz\"\n",
        "destination_folder0 = \"Tensorflow/workspace/images\"\n",
        "\n",
        "if os.path.exists(source_folder0):\n",
        "   shutil.copy(source_folder0, destination_folder0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgO5r1Gv3j-1"
      },
      "outputs": [],
      "source": [
        "#replace source_folder0 with the same tar.gz link/path as above\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Path to the archive file\n",
        "source_folder0 = f\"/content/Tensorflow/workspace/images/{image_dataset}\"\n",
        "\n",
        "# Extract the contents of the archive\n",
        "with tarfile.open(source_folder0, 'r:gz') as tar:\n",
        "    tar.extractall(\"/content/Tensorflow/workspace/images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2CREW2Ugk1d"
      },
      "outputs": [],
      "source": [
        "#use the first two source_folder strings in future. upload the images and Annotations files from Microsoft teams INTO a new file (here we have called it \"aircraftimage\" ,change the path of source folders if you call it something else)\n",
        "\n",
        "#this code takes the \"images\" and \"Annotations\" files that you have uploaded into Google Drive and copies them in to the directory Tensorflow/workspace/collectedimages .from here using some later process/code we split the collected images(and xml files) into training and testing sets\n",
        "\n",
        "#again make sure that the source_folder 1 and 2 paths are relevant to the tar.gz file that was just untarred.\n",
        "\n",
        "source_folder1 = \"Tensorflow/workspace/images/images\"\n",
        "source_folder2 = \"Tensorflow/workspace/images/Annotations\"\n",
        "destination_folder = \"Tensorflow/workspace/images/collectedimages\"\n",
        "\n",
        "source_folders = [source_folder1, source_folder2]\n",
        "\n",
        "for source_folder in source_folders:\n",
        "    source_files = os.listdir(source_folder)\n",
        "    for file_name in source_files:\n",
        "        source_file = os.path.join(source_folder, file_name)\n",
        "        destination_file = os.path.join(destination_folder, file_name)\n",
        "        shutil.copy(source_file, destination_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrwuhdtD4Qim",
        "outputId": "cc7d9709-bd00-4834-9b95-00aa7717c27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items in the directory: 2279\n",
            "Number of items in the directory: 2314\n"
          ]
        }
      ],
      "source": [
        "#check the number of images you are running this experiment with\n",
        "\n",
        "#define the directory you want to count images in\n",
        "directory_path1 = \"/content/Tensorflow/workspace/images/images\"\n",
        "directory_path2 = \"/content/Tensorflow/workspace/images/Annotations\"\n",
        "\n",
        "#list all images in the directory\n",
        "items = os.listdir(source_folder1)\n",
        "\n",
        "#count\n",
        "num_items = len(items)\n",
        "\n",
        "#print the number of images you are working with\n",
        "print(f\"Number of items in the directory: {num_items}\")\n",
        "\n",
        "#list all images in the directory\n",
        "items = os.listdir(source_folder2)\n",
        "\n",
        "#count\n",
        "num_items = len(items)\n",
        "\n",
        "#print the number of images you are working with\n",
        "print(f\"Number of items in the directory: {num_items}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U543r8ulmRy"
      },
      "source": [
        "# Optional resizing step -- We can resize images and labels to match the correct input size for the model (if the chosen model does not have an inbuilt image_resizer, and if this hasn't already been done locally)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK-M172LCdlR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def resize_images(input_folder, output_folder, new_width, new_height):\n",
        "    \"\"\"Iterates through all images in a given input folder (input_folder) and resizes them to a specified size.\n",
        "    run annotation_converter.py afterwards to convert any existing/outstanding xml files to the proper size.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "      if filename.endswith('JPG'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(input_path)\n",
        "        if image is not None:\n",
        "          # Resize the image\n",
        "          resized_image = cv2.resize(image, (new_width, new_height))\n",
        "\n",
        "          # Save the resized image to the output folder\n",
        "          output_path = os.path.join(output_folder, filename)\n",
        "          cv2.imwrite(output_path, resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftMPdr_YDIw1"
      },
      "outputs": [],
      "source": [
        "#uncheck this if you want to resize images in the cloud\n",
        "resize_images('Tensorflow/workspace/images/collectedimages', 'Tensorflow/workspace/images/resizedcollectedimages', new_width, new_height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq1h73ZlCdp1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def resize_xml_annotations(xml_folder, output_folder, new_size):\n",
        "    \"\"\" Iterates through all xml_files in a given input folder (xml_folder variable)\n",
        "    and resizes them to map to the same location on a resized image.\n",
        "    \"\"\"\n",
        "    new_width, new_height = new_size\n",
        "\n",
        "    for xml_file in os.listdir(xml_folder):\n",
        "        if xml_file.endswith('.xml'):\n",
        "            xml_path = os.path.join(xml_folder, xml_file)\n",
        "            tree = ET.parse(xml_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            image_size = root.find('size')\n",
        "            image_width = int(image_size.find('width').text)\n",
        "            image_height = int(image_size.find('height').text)\n",
        "\n",
        "            width_ratio = new_width / image_width\n",
        "            height_ratio = new_height / image_height\n",
        "\n",
        "            for object in root.findall('object'):\n",
        "                bndbox = object.find('bndbox')\n",
        "\n",
        "                xmin = int(bndbox.find('xmin').text)\n",
        "                ymin = int(bndbox.find('ymin').text)\n",
        "                xmax = int(bndbox.find('xmax').text)\n",
        "                ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "                xmin = int(xmin * width_ratio)\n",
        "                ymin = int(ymin * height_ratio)\n",
        "                xmax = int(xmax * width_ratio)\n",
        "                ymax = int(ymax * height_ratio)\n",
        "\n",
        "                bndbox.find('xmin').text = str(xmin)\n",
        "                bndbox.find('ymin').text = str(ymin)\n",
        "                bndbox.find('xmax').text = str(xmax)\n",
        "                bndbox.find('ymax').text = str(ymax)\n",
        "\n",
        "            # Update the image size in the XML file\n",
        "            image_size.find('width').text = str(new_width)\n",
        "            image_size.find('height').text = str(new_height)\n",
        "\n",
        "            # Save the updated XML file to the output folder\n",
        "            output_path = os.path.join(output_folder, xml_file)\n",
        "            tree.write(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDGTq_01DJdd"
      },
      "outputs": [],
      "source": [
        "#uncheck if you want to resize xml labels in the cloud\n",
        "resize_xml_annotations('Tensorflow/workspace/images/collectedimages', 'Tensorflow/workspace/images/resizedcollectedimages', (new_width,new_height))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htw5QYSPaiiS"
      },
      "source": [
        "#2. Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfNFePlhTIT-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsFIVF9CPHFx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the paths to your image and XML directories #resized\n",
        "image_directory ='Tensorflow/workspace/images/resizedcollectedimages'\n",
        "xml_directory ='Tensorflow/workspace/images/resizedcollectedimages'\n",
        "\n",
        "# Create the train and test directories if they don't exist\n",
        "train_directory = 'Tensorflow/workspace/images/train'\n",
        "test_directory = 'Tensorflow/workspace/images/test'\n",
        "os.makedirs(train_directory, exist_ok=True)\n",
        "os.makedirs(test_directory, exist_ok=True)\n",
        "\n",
        "# List all image files in the image directory\n",
        "image_files = [file for file in os.listdir(image_directory) if file.endswith('.JPG')]\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "# Perform the train/test split\n",
        "train_files, test_files = train_test_split(image_files, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "\n",
        "# Move the selected images and their corresponding XML files to the train folder\n",
        "for file in train_files:\n",
        "    image_src = os.path.join(image_directory, file)\n",
        "    #print(image_src)\n",
        "    xml_src = os.path.join(xml_directory, file.replace('.JPG', '.xml'))\n",
        "    #print(xml_src)\n",
        "    image_dest = os.path.join(train_directory, file)\n",
        "    #print(image_dest)\n",
        "    xml_dest = os.path.join(train_directory, file.replace('.JPG', '.xml'))\n",
        "    #print(xml_dest)\n",
        "    if os.path.exists(xml_src):\n",
        "      copyfile(image_src, image_dest)\n",
        "      copyfile(xml_src, xml_dest)\n",
        "\n",
        "# Move the remaining images and their corresponding XML files to the test folder\n",
        "for file in test_files:\n",
        "    image_src = os.path.join(image_directory, file)\n",
        "    xml_src = os.path.join(xml_directory, file.replace('.JPG', '.xml'))\n",
        "    image_dest = os.path.join(test_directory, file)\n",
        "    xml_dest = os.path.join(test_directory, file.replace('.JPG', '.xml'))\n",
        "    if os.path.exists(xml_src):\n",
        "      copyfile(image_src, image_dest)\n",
        "      copyfile(xml_src, xml_dest)\n",
        "\n",
        "\n",
        "#examine train/test split by unchecking below\n",
        "print(\"size of training set\",len(train_files))\n",
        "print(\"size of testing set\",len(test_files))\n",
        "\n",
        "#Number of images being used in this dataset\n",
        "print(\"Overall Number of Images Input into Model: \" + str(len(train_files) + len(test_files)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "#3. Download Tensorflow Object Detection API and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA1DIq5OpfDE",
        "outputId": "018d589b-4178-4295-b1e5-37a896af1595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 89900, done.\u001b[K\n",
            "remote: Counting objects: 100% (3612/3612), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1929/1929), done.\u001b[K\n",
            "remote: Total 89900 (delta 1914), reused 3279 (delta 1645), pack-reused 86288\u001b[K\n",
            "Receiving objects: 100% (89900/89900), 606.56 MiB | 16.22 MiB/s, done.\n",
            "Resolving deltas: 100% (63812/63812), done.\n"
          ]
        }
      ],
      "source": [
        "#This downloads the object detection API\n",
        "if not os.path.exists(os.path.join(folderpaths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {folderpaths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJjMHbnDs3Tv",
        "outputId": "dbc7b51a-4dbe-41c9-bfdb-51e9e2087f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.52.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.5)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.14.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.1.78)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.15.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.15.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.59.2)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.19.2)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (23.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.44.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.34.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras (from object-detection==0.1)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.41.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697354 sha256=ac8f4590709c044d167c3ff83ecf549d28661d3cb2ab88f2f167744694e7956c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xctulvey/wheels/fb/c9/43/709f88e66b36649c7a29812ca4f6236f31caed949aabc3e335\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43993 sha256=e4b696b650d4965b6b59c568443db43f97995cfc538cf8cf24268a22d05c99de\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=381aaa4d18bc8abbb172c495cfb2239d3f70e784b21bfec747bc77810916a666\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=5595544ca018462c66fbdf1572c221f96fc3018e1ebca8865d6ec4be71f04eed\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=a5879965d30039ba0ca1a06bd5702cc20cdcb56da965f4d80b660c155161c2db\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=29099c07a6b799c9ce16d3c76c7f261d2b73fa2fe2032beb76b24b70073dfc04\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25985 sha256=ba78b39578694e73399e4c796f293c47b8e9fffe9a31caafefd45d72b90fb181\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=dec7879da3fac486c13483a63a9bb8d7b1a7e60be828070724e3967e0b24bd51\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n",
            "Installing collected packages: sentencepiece, pyjsparser, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyparsing, pyarrow-hotfix, portalocker, orjson, objsize, keras, js2py, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, tensorboard, apache-beam, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed apache-beam-2.52.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.9.0 fasteners-0.19 hdfs-2.7.3 immutabledict-3.0.0 js2py-0.74 keras-2.15.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.10 portalocker-2.8.2 pyarrow-hotfix-0.5 pyjsparser-2.7.1 pymongo-4.6.0 pyparsing-2.4.7 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tensorflow_io-0.34.0 tf-models-official-2.15.0 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "#Converts .protoc files into readable .py format\n",
        "!apt-get install protobuf-compiler\n",
        "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF5Ei6QzGGJl",
        "outputId": "0ca39aba-a3a2-4bda-bee3-83cf971b39d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.59.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\n",
            "tf-models-official 2.15.0 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0\n"
          ]
        }
      ],
      "source": [
        "#This seems to be the necessary version of tensorflow (doesn't seem to work with tensorflow==2.14.0)\n",
        "!pip install tensorflow==2.13.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the output of the following cell has OK at the very bottom (in some fashion) then you have successfully installed TF2 Object Detection API"
      ],
      "metadata": {
        "id": "lMeIMZ5hbu3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kPfJLfRCydF",
        "outputId": "157f4181-2f95-4d93-a5b6-197da3bf8e0f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-18 17:37:20.951814: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-18 17:37:21.005320: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-18 17:37:22.025000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-11-18 17:37:25.849406: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-18 17:37:25.849482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38352 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1118 17:37:26.030207 140229924824192 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1118 17:37:26.318997 140229924824192 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.71s\n",
            "I1118 17:37:26.649768 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.71s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.63s\n",
            "I1118 17:37:27.281143 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.63s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.38s\n",
            "I1118 17:37:27.662217 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.38s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.51s\n",
            "I1118 17:37:28.174128 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.51s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n",
            "I1118 17:37:30.645816 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1118 17:37:30.653190 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1118 17:37:30.686173 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1118 17:37:30.708561 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1118 17:37:30.731483 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "I1118 17:37:30.869613 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "I1118 17:37:30.985853 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I1118 17:37:31.125320 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I1118 17:37:31.261960 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "I1118 17:37:31.382947 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I1118 17:37:31.417720 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1118 17:37:31.645156 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1118 17:37:31.645309 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1118 17:37:31.645365 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1118 17:37:31.648543 140229924824192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 17:37:31.682038 140229924824192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 17:37:31.682191 140229924824192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 17:37:31.776252 140229924824192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 17:37:31.776426 140229924824192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 17:37:32.021666 140229924824192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 17:37:32.021862 140229924824192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 17:37:32.239476 140229924824192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 17:37:32.239635 140229924824192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 17:37:32.600874 140229924824192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 17:37:32.601086 140229924824192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 17:37:32.963507 140229924824192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 17:37:32.963659 140229924824192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 17:37:33.401605 140229924824192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 17:37:33.401757 140229924824192 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1118 17:37:33.521090 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1118 17:37:33.573971 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:33.637731 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1118 17:37:33.637879 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1118 17:37:33.637937 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1118 17:37:33.639932 140229924824192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 17:37:33.659890 140229924824192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 17:37:33.660006 140229924824192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 17:37:33.815486 140229924824192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 17:37:33.815651 140229924824192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 17:37:34.104732 140229924824192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 17:37:34.104887 140229924824192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 17:37:34.424318 140229924824192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 17:37:34.424490 140229924824192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 17:37:35.041019 140229924824192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 17:37:35.041172 140229924824192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 17:37:35.422867 140229924824192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 17:37:35.423022 140229924824192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 17:37:35.908655 140229924824192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 17:37:35.908825 140229924824192 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1118 17:37:36.103283 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1118 17:37:36.138368 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:36.204980 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1118 17:37:36.205121 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1118 17:37:36.205194 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1118 17:37:36.207159 140229924824192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 17:37:36.225958 140229924824192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 17:37:36.226069 140229924824192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 17:37:36.379173 140229924824192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 17:37:36.379339 140229924824192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 17:37:36.662689 140229924824192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 17:37:36.662850 140229924824192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 17:37:36.974005 140229924824192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 17:37:36.974155 140229924824192 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1118 17:37:37.368064 140229924824192 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1118 17:37:37.368214 140229924824192 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1118 17:37:37.760150 140229924824192 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1118 17:37:37.760300 140229924824192 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1118 17:37:38.241132 140229924824192 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1118 17:37:38.241287 140229924824192 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1118 17:37:38.437692 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1118 17:37:38.477319 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:38.544815 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1118 17:37:38.544940 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1118 17:37:38.544996 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1118 17:37:38.546919 140229924824192 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1118 17:37:38.567733 140229924824192 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1118 17:37:38.567856 140229924824192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 17:37:38.725712 140229924824192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 17:37:38.725849 140229924824192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 17:37:39.016029 140229924824192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 17:37:39.016181 140229924824192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 17:37:39.297996 140229924824192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 17:37:39.298141 140229924824192 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1118 17:37:39.767554 140229924824192 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1118 17:37:39.767698 140229924824192 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1118 17:37:40.244197 140229924824192 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1118 17:37:40.244351 140229924824192 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1118 17:37:40.819588 140229924824192 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1118 17:37:40.819734 140229924824192 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1118 17:37:41.015507 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1118 17:37:41.057494 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:41.131109 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1118 17:37:41.131261 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1118 17:37:41.131315 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1118 17:37:41.133297 140229924824192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 17:37:41.155007 140229924824192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 17:37:41.155127 140229924824192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 17:37:41.308362 140229924824192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 17:37:41.308529 140229924824192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 17:37:41.684158 140229924824192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 17:37:41.684309 140229924824192 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1118 17:37:42.069223 140229924824192 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1118 17:37:42.069373 140229924824192 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1118 17:37:42.638008 140229924824192 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1118 17:37:42.638157 140229924824192 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1118 17:37:43.481598 140229924824192 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1118 17:37:43.481755 140229924824192 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1118 17:37:44.268652 140229924824192 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1118 17:37:44.268818 140229924824192 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1118 17:37:44.469025 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1118 17:37:44.509206 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:44.592506 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1118 17:37:44.592655 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1118 17:37:44.592712 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1118 17:37:44.594677 140229924824192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 17:37:44.613870 140229924824192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 17:37:44.613989 140229924824192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 17:37:44.836411 140229924824192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 17:37:44.836559 140229924824192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 17:37:45.296252 140229924824192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 17:37:45.296416 140229924824192 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1118 17:37:45.760795 140229924824192 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1118 17:37:45.760943 140229924824192 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1118 17:37:46.426118 140229924824192 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1118 17:37:46.426275 140229924824192 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1118 17:37:47.078150 140229924824192 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1118 17:37:47.078304 140229924824192 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1118 17:37:47.908997 140229924824192 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1118 17:37:47.909147 140229924824192 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1118 17:37:48.231071 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1118 17:37:48.271288 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:48.367252 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1118 17:37:48.367413 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1118 17:37:48.367471 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1118 17:37:48.369479 140229924824192 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1118 17:37:48.390541 140229924824192 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1118 17:37:48.390684 140229924824192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 17:37:48.619900 140229924824192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 17:37:48.620051 140229924824192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 17:37:49.178028 140229924824192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 17:37:49.178185 140229924824192 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1118 17:37:49.757831 140229924824192 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1118 17:37:49.757982 140229924824192 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1118 17:37:50.504476 140229924824192 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1118 17:37:50.504628 140229924824192 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1118 17:37:51.280699 140229924824192 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1118 17:37:51.280862 140229924824192 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1118 17:37:52.631794 140229924824192 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1118 17:37:52.631942 140229924824192 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1118 17:37:52.925655 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1118 17:37:52.967641 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 17:37:53.077412 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1118 17:37:53.077557 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1118 17:37:53.077611 140229924824192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1118 17:37:53.079561 140229924824192 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1118 17:37:53.109564 140229924824192 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1118 17:37:53.109693 140229924824192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 17:37:53.435313 140229924824192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 17:37:53.435471 140229924824192 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1118 17:37:54.084933 140229924824192 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1118 17:37:54.085084 140229924824192 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1118 17:37:54.771604 140229924824192 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1118 17:37:54.771757 140229924824192 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1118 17:37:55.711426 140229924824192 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1118 17:37:55.711577 140229924824192 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1118 17:37:56.658551 140229924824192 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1118 17:37:56.658704 140229924824192 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1118 17:37:57.874787 140229924824192 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1118 17:37:57.874947 140229924824192 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1118 17:37:58.288150 140229924824192 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1118 17:37:58.332033 140229924824192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.05s\n",
            "I1118 17:37:58.463957 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1118 17:37:58.492225 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1118 17:37:58.493996 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1118 17:37:58.494468 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1118 17:37:58.495911 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1118 17:37:58.497168 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1118 17:37:58.497543 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1118 17:37:58.498469 140229924824192 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 33.555s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(folderpaths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# verify if the installation has worked\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5I498ch6JqN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf1uctD4CydJ"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "574fca09-593f-43a2-c67e-a4502dcdee50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-18 17:38:00--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.130.207, 74.125.68.207, 64.233.170.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.130.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90453990 (86M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v1_fp 100%[===================>]  86.26M  14.6MB/s    in 7.0s    \n",
            "\n",
            "2023-11-18 17:38:08 (12.4 MB/s) - ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [90453990/90453990]\n",
            "\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "#This downloads the actual model you plan to use from TF2 model zoo and moves it\n",
        "!wget {PRETRAINED_MODEL_URL}\n",
        "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {folderpaths['PRETRAINED_MODEL_PATH']}\n",
        "!cd {folderpaths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 4. Create Label Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "#The machine will class objects as numbers, so we introduce label mapping to map those numbers back to recognisable names of our distinct object groups\n",
        "labels = [{'name':'Aircraft', 'id':1},{'name':'Non-Aircraft', 'id':2}]\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "#5. Create TF records files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpb_BVUpfDD",
        "outputId": "978e2ba8-0a50-4b78-8210-2a4c9e3ffa8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {folderpaths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "e93f7b76-18e8-4f93-daad-d0697d978db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "#This code converts our xml annotations into a machine readable TFRecord file format\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(folderpaths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(folderpaths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(folderpaths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(folderpaths['ANNOTATION_PATH'], 'test.record')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 6. Copy Model Configuration File to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "!cp {os.path.join(folderpaths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(folderpaths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 7. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6luxwrR0Fy43"
      },
      "source": [
        "This section is where we adjust hyperparameters of our model either to configure the model to simply work on our input data, or to optimise it for best performance.\n",
        "\n",
        "It is important to read the config file carefully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.train_config.batch_size = batch_size\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(folderpaths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(folderpaths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(folderpaths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important: Change the below {model_name} pipeline_config.model.{model_name}.num_classes to the name listed in the general config file (e.g for an ssd, we write\n",
        "\n",
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "\n",
        "- to explain, this sets the number of classes that the model will study to the size of the labels variable that we wrote in section 4\n"
      ],
      "metadata": {
        "id": "sxQg0tlGcXRW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw5J5ujVSoAL"
      },
      "outputs": [],
      "source": [
        "#change {model_name} pipeline_config.model.{model_name}.num_classes to the name listed in the general config file\n",
        "pipeline_config.model.ssd.num_classes = len(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ENVepLAJtgL"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIlsg1T-q7_4",
        "outputId": "e6af144a-fcd9-4136-88a6-9f7ce719afb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 2\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v1_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 256\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 40\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.03999999910593033\n",
              "         total_steps: 25000\n",
              "         warmup_learning_rate: 0.013333000242710114\n",
              "         warmup_steps: 2000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              " num_steps: 25000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"detection\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false\n",
              " batch_size: 1,\n",
              " 'eval_input_configs': [label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              " }}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "#8. Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wTKNyLHGARw"
      },
      "source": [
        "We specify the number of training steps we want to have the model learn for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(folderpaths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT, folderpaths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'],training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "37e8f471-8c1f-4b5a-bde8-3c83182c41de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet/pipeline.config --num_train_steps=20000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "a9a24092-6bbe-47bc-e65b-9d47a8b7add6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-18 17:38:24.081316: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-18 17:38:27.427972: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1118 17:38:27.429616 136149638571136 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
            "I1118 17:38:27.452880 136149638571136 config_util.py:552] Maybe overwriting train_steps: 20000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1118 17:38:27.453038 136149638571136 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1118 17:38:27.479532 136149638571136 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1118 17:38:27.492044 136149638571136 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1118 17:38:27.492214 136149638571136 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1118 17:38:27.492281 136149638571136 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1118 17:38:27.492333 136149638571136 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1118 17:38:27.500882 136149638571136 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1118 17:38:27.520440 136149638571136 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1118 17:38:34.155238 136149638571136 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1118 17:38:36.923379 136149638571136 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1118 17:38:38.595418 136149638571136 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I1118 17:38:46.721549 136140782818880 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1118 17:39:02.096822 136140782818880 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.120439 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.123401 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.124455 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.125339 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.129431 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.130326 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.131290 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.132152 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.136630 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1118 17:39:28.137514 136149638571136 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1118 17:39:29.256797 136140262733376 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I1118 17:39:29.965536 136140262733376 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1118 17:39:43.027226 136140262733376 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1118 17:39:55.599149 136140262733376 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1118 17:40:08.077260 136140262733376 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Step 100 per-step time 1.859s\n",
            "I1118 17:42:34.908554 136149638571136 model_lib_v2.py:705] Step 100 per-step time 1.859s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.40014088,\n",
            " 'Loss/localization_loss': 0.28643444,\n",
            " 'Loss/regularization_loss': 0.7795934,\n",
            " 'Loss/total_loss': 1.4661686,\n",
            " 'learning_rate': 0.014666351}\n",
            "I1118 17:42:34.908865 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.40014088,\n",
            " 'Loss/localization_loss': 0.28643444,\n",
            " 'Loss/regularization_loss': 0.7795934,\n",
            " 'Loss/total_loss': 1.4661686,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.084s\n",
            "I1118 17:44:23.180689 136149638571136 model_lib_v2.py:705] Step 200 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30596325,\n",
            " 'Loss/localization_loss': 0.22338188,\n",
            " 'Loss/regularization_loss': 0.7788138,\n",
            " 'Loss/total_loss': 1.3081589,\n",
            " 'learning_rate': 0.0159997}\n",
            "I1118 17:44:23.180961 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.30596325,\n",
            " 'Loss/localization_loss': 0.22338188,\n",
            " 'Loss/regularization_loss': 0.7788138,\n",
            " 'Loss/total_loss': 1.3081589,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.084s\n",
            "I1118 17:46:11.589251 136149638571136 model_lib_v2.py:705] Step 300 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31649017,\n",
            " 'Loss/localization_loss': 0.2092122,\n",
            " 'Loss/regularization_loss': 0.7779215,\n",
            " 'Loss/total_loss': 1.3036238,\n",
            " 'learning_rate': 0.01733305}\n",
            "I1118 17:46:11.589539 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.31649017,\n",
            " 'Loss/localization_loss': 0.2092122,\n",
            " 'Loss/regularization_loss': 0.7779215,\n",
            " 'Loss/total_loss': 1.3036238,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.083s\n",
            "I1118 17:47:59.850402 136149638571136 model_lib_v2.py:705] Step 400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23736846,\n",
            " 'Loss/localization_loss': 0.18629466,\n",
            " 'Loss/regularization_loss': 0.7769567,\n",
            " 'Loss/total_loss': 1.2006198,\n",
            " 'learning_rate': 0.0186664}\n",
            "I1118 17:47:59.850678 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.23736846,\n",
            " 'Loss/localization_loss': 0.18629466,\n",
            " 'Loss/regularization_loss': 0.7769567,\n",
            " 'Loss/total_loss': 1.2006198,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.083s\n",
            "I1118 17:49:48.195479 136149638571136 model_lib_v2.py:705] Step 500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24919465,\n",
            " 'Loss/localization_loss': 0.23172136,\n",
            " 'Loss/regularization_loss': 0.7759191,\n",
            " 'Loss/total_loss': 1.2568351,\n",
            " 'learning_rate': 0.01999975}\n",
            "I1118 17:49:48.195751 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.24919465,\n",
            " 'Loss/localization_loss': 0.23172136,\n",
            " 'Loss/regularization_loss': 0.7759191,\n",
            " 'Loss/total_loss': 1.2568351,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.083s\n",
            "I1118 17:51:36.527128 136149638571136 model_lib_v2.py:705] Step 600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22410735,\n",
            " 'Loss/localization_loss': 0.17709357,\n",
            " 'Loss/regularization_loss': 0.7748264,\n",
            " 'Loss/total_loss': 1.1760273,\n",
            " 'learning_rate': 0.0213331}\n",
            "I1118 17:51:36.527413 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.22410735,\n",
            " 'Loss/localization_loss': 0.17709357,\n",
            " 'Loss/regularization_loss': 0.7748264,\n",
            " 'Loss/total_loss': 1.1760273,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.083s\n",
            "I1118 17:53:24.856682 136149638571136 model_lib_v2.py:705] Step 700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20080145,\n",
            " 'Loss/localization_loss': 0.14281602,\n",
            " 'Loss/regularization_loss': 0.7736508,\n",
            " 'Loss/total_loss': 1.1172683,\n",
            " 'learning_rate': 0.02266645}\n",
            "I1118 17:53:24.856952 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.20080145,\n",
            " 'Loss/localization_loss': 0.14281602,\n",
            " 'Loss/regularization_loss': 0.7736508,\n",
            " 'Loss/total_loss': 1.1172683,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.083s\n",
            "I1118 17:55:13.185541 136149638571136 model_lib_v2.py:705] Step 800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19664256,\n",
            " 'Loss/localization_loss': 0.16952765,\n",
            " 'Loss/regularization_loss': 0.7724162,\n",
            " 'Loss/total_loss': 1.1385864,\n",
            " 'learning_rate': 0.023999799}\n",
            "I1118 17:55:13.185808 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.19664256,\n",
            " 'Loss/localization_loss': 0.16952765,\n",
            " 'Loss/regularization_loss': 0.7724162,\n",
            " 'Loss/total_loss': 1.1385864,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.083s\n",
            "I1118 17:57:01.519334 136149638571136 model_lib_v2.py:705] Step 900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18027072,\n",
            " 'Loss/localization_loss': 0.11104654,\n",
            " 'Loss/regularization_loss': 0.7711184,\n",
            " 'Loss/total_loss': 1.0624356,\n",
            " 'learning_rate': 0.025333151}\n",
            "I1118 17:57:01.519617 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.18027072,\n",
            " 'Loss/localization_loss': 0.11104654,\n",
            " 'Loss/regularization_loss': 0.7711184,\n",
            " 'Loss/total_loss': 1.0624356,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.083s\n",
            "I1118 17:58:49.852531 136149638571136 model_lib_v2.py:705] Step 1000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20285119,\n",
            " 'Loss/localization_loss': 0.14932214,\n",
            " 'Loss/regularization_loss': 0.7697657,\n",
            " 'Loss/total_loss': 1.121939,\n",
            " 'learning_rate': 0.0266665}\n",
            "I1118 17:58:49.852803 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.20285119,\n",
            " 'Loss/localization_loss': 0.14932214,\n",
            " 'Loss/regularization_loss': 0.7697657,\n",
            " 'Loss/total_loss': 1.121939,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.094s\n",
            "I1118 18:00:39.231679 136149638571136 model_lib_v2.py:705] Step 1100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1961142,\n",
            " 'Loss/localization_loss': 0.13545579,\n",
            " 'Loss/regularization_loss': 0.7683586,\n",
            " 'Loss/total_loss': 1.0999286,\n",
            " 'learning_rate': 0.02799985}\n",
            "I1118 18:00:39.231964 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.1961142,\n",
            " 'Loss/localization_loss': 0.13545579,\n",
            " 'Loss/regularization_loss': 0.7683586,\n",
            " 'Loss/total_loss': 1.0999286,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.083s\n",
            "I1118 18:02:27.563829 136149638571136 model_lib_v2.py:705] Step 1200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18248753,\n",
            " 'Loss/localization_loss': 0.106876075,\n",
            " 'Loss/regularization_loss': 0.7668739,\n",
            " 'Loss/total_loss': 1.0562375,\n",
            " 'learning_rate': 0.0293332}\n",
            "I1118 18:02:27.564105 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.18248753,\n",
            " 'Loss/localization_loss': 0.106876075,\n",
            " 'Loss/regularization_loss': 0.7668739,\n",
            " 'Loss/total_loss': 1.0562375,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.083s\n",
            "I1118 18:04:15.909915 136149638571136 model_lib_v2.py:705] Step 1300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14531188,\n",
            " 'Loss/localization_loss': 0.07473587,\n",
            " 'Loss/regularization_loss': 0.7653368,\n",
            " 'Loss/total_loss': 0.9853846,\n",
            " 'learning_rate': 0.03066655}\n",
            "I1118 18:04:15.910189 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.14531188,\n",
            " 'Loss/localization_loss': 0.07473587,\n",
            " 'Loss/regularization_loss': 0.7653368,\n",
            " 'Loss/total_loss': 0.9853846,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.083s\n",
            "I1118 18:06:04.252488 136149638571136 model_lib_v2.py:705] Step 1400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18450712,\n",
            " 'Loss/localization_loss': 0.11843959,\n",
            " 'Loss/regularization_loss': 0.7637411,\n",
            " 'Loss/total_loss': 1.0666878,\n",
            " 'learning_rate': 0.0319999}\n",
            "I1118 18:06:04.252768 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.18450712,\n",
            " 'Loss/localization_loss': 0.11843959,\n",
            " 'Loss/regularization_loss': 0.7637411,\n",
            " 'Loss/total_loss': 1.0666878,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.083s\n",
            "I1118 18:07:52.585969 136149638571136 model_lib_v2.py:705] Step 1500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15295938,\n",
            " 'Loss/localization_loss': 0.08358958,\n",
            " 'Loss/regularization_loss': 0.76209027,\n",
            " 'Loss/total_loss': 0.9986392,\n",
            " 'learning_rate': 0.03333325}\n",
            "I1118 18:07:52.586246 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.15295938,\n",
            " 'Loss/localization_loss': 0.08358958,\n",
            " 'Loss/regularization_loss': 0.76209027,\n",
            " 'Loss/total_loss': 0.9986392,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.083s\n",
            "I1118 18:09:40.898997 136149638571136 model_lib_v2.py:705] Step 1600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.143716,\n",
            " 'Loss/localization_loss': 0.10740181,\n",
            " 'Loss/regularization_loss': 0.7603788,\n",
            " 'Loss/total_loss': 1.0114965,\n",
            " 'learning_rate': 0.034666598}\n",
            "I1118 18:09:40.899272 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.143716,\n",
            " 'Loss/localization_loss': 0.10740181,\n",
            " 'Loss/regularization_loss': 0.7603788,\n",
            " 'Loss/total_loss': 1.0114965,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.083s\n",
            "I1118 18:11:29.224555 136149638571136 model_lib_v2.py:705] Step 1700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14244916,\n",
            " 'Loss/localization_loss': 0.07531991,\n",
            " 'Loss/regularization_loss': 0.7586138,\n",
            " 'Loss/total_loss': 0.97638285,\n",
            " 'learning_rate': 0.03599995}\n",
            "I1118 18:11:29.224829 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.14244916,\n",
            " 'Loss/localization_loss': 0.07531991,\n",
            " 'Loss/regularization_loss': 0.7586138,\n",
            " 'Loss/total_loss': 0.97638285,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.083s\n",
            "I1118 18:13:17.545673 136149638571136 model_lib_v2.py:705] Step 1800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14150025,\n",
            " 'Loss/localization_loss': 0.09201269,\n",
            " 'Loss/regularization_loss': 0.7567672,\n",
            " 'Loss/total_loss': 0.99028015,\n",
            " 'learning_rate': 0.037333302}\n",
            "I1118 18:13:17.545962 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.14150025,\n",
            " 'Loss/localization_loss': 0.09201269,\n",
            " 'Loss/regularization_loss': 0.7567672,\n",
            " 'Loss/total_loss': 0.99028015,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.083s\n",
            "I1118 18:15:05.862557 136149638571136 model_lib_v2.py:705] Step 1900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12358044,\n",
            " 'Loss/localization_loss': 0.08333205,\n",
            " 'Loss/regularization_loss': 0.754869,\n",
            " 'Loss/total_loss': 0.9617815,\n",
            " 'learning_rate': 0.03866665}\n",
            "I1118 18:15:05.862830 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.12358044,\n",
            " 'Loss/localization_loss': 0.08333205,\n",
            " 'Loss/regularization_loss': 0.754869,\n",
            " 'Loss/total_loss': 0.9617815,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.083s\n",
            "I1118 18:16:54.190639 136149638571136 model_lib_v2.py:705] Step 2000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14900796,\n",
            " 'Loss/localization_loss': 0.11953422,\n",
            " 'Loss/regularization_loss': 0.7529082,\n",
            " 'Loss/total_loss': 1.0214504,\n",
            " 'learning_rate': 0.04}\n",
            "I1118 18:16:54.190909 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.14900796,\n",
            " 'Loss/localization_loss': 0.11953422,\n",
            " 'Loss/regularization_loss': 0.7529082,\n",
            " 'Loss/total_loss': 1.0214504,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.094s\n",
            "I1118 18:18:43.540567 136149638571136 model_lib_v2.py:705] Step 2100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.111755796,\n",
            " 'Loss/localization_loss': 0.07389756,\n",
            " 'Loss/regularization_loss': 0.7508993,\n",
            " 'Loss/total_loss': 0.93655264,\n",
            " 'learning_rate': 0.039998136}\n",
            "I1118 18:18:43.540852 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.111755796,\n",
            " 'Loss/localization_loss': 0.07389756,\n",
            " 'Loss/regularization_loss': 0.7508993,\n",
            " 'Loss/total_loss': 0.93655264,\n",
            " 'learning_rate': 0.039998136}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.083s\n",
            "I1118 18:20:31.871038 136149638571136 model_lib_v2.py:705] Step 2200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12536918,\n",
            " 'Loss/localization_loss': 0.08955398,\n",
            " 'Loss/regularization_loss': 0.7488911,\n",
            " 'Loss/total_loss': 0.96381426,\n",
            " 'learning_rate': 0.039992537}\n",
            "I1118 18:20:31.871302 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.12536918,\n",
            " 'Loss/localization_loss': 0.08955398,\n",
            " 'Loss/regularization_loss': 0.7488911,\n",
            " 'Loss/total_loss': 0.96381426,\n",
            " 'learning_rate': 0.039992537}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.083s\n",
            "I1118 18:22:20.188912 136149638571136 model_lib_v2.py:705] Step 2300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13469352,\n",
            " 'Loss/localization_loss': 0.06616821,\n",
            " 'Loss/regularization_loss': 0.7468693,\n",
            " 'Loss/total_loss': 0.947731,\n",
            " 'learning_rate': 0.03998321}\n",
            "I1118 18:22:20.189212 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.13469352,\n",
            " 'Loss/localization_loss': 0.06616821,\n",
            " 'Loss/regularization_loss': 0.7468693,\n",
            " 'Loss/total_loss': 0.947731,\n",
            " 'learning_rate': 0.03998321}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.083s\n",
            "I1118 18:24:08.506007 136149638571136 model_lib_v2.py:705] Step 2400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1460907,\n",
            " 'Loss/localization_loss': 0.08838989,\n",
            " 'Loss/regularization_loss': 0.7448439,\n",
            " 'Loss/total_loss': 0.97932446,\n",
            " 'learning_rate': 0.039970152}\n",
            "I1118 18:24:08.506274 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.1460907,\n",
            " 'Loss/localization_loss': 0.08838989,\n",
            " 'Loss/regularization_loss': 0.7448439,\n",
            " 'Loss/total_loss': 0.97932446,\n",
            " 'learning_rate': 0.039970152}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.083s\n",
            "I1118 18:25:56.851909 136149638571136 model_lib_v2.py:705] Step 2500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.111571565,\n",
            " 'Loss/localization_loss': 0.07126374,\n",
            " 'Loss/regularization_loss': 0.74282455,\n",
            " 'Loss/total_loss': 0.92565984,\n",
            " 'learning_rate': 0.039953373}\n",
            "I1118 18:25:56.852179 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.111571565,\n",
            " 'Loss/localization_loss': 0.07126374,\n",
            " 'Loss/regularization_loss': 0.74282455,\n",
            " 'Loss/total_loss': 0.92565984,\n",
            " 'learning_rate': 0.039953373}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.083s\n",
            "I1118 18:27:45.173434 136149638571136 model_lib_v2.py:705] Step 2600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09805252,\n",
            " 'Loss/localization_loss': 0.071892254,\n",
            " 'Loss/regularization_loss': 0.7407783,\n",
            " 'Loss/total_loss': 0.9107231,\n",
            " 'learning_rate': 0.03993287}\n",
            "I1118 18:27:45.173699 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09805252,\n",
            " 'Loss/localization_loss': 0.071892254,\n",
            " 'Loss/regularization_loss': 0.7407783,\n",
            " 'Loss/total_loss': 0.9107231,\n",
            " 'learning_rate': 0.03993287}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.083s\n",
            "I1118 18:29:33.505793 136149638571136 model_lib_v2.py:705] Step 2700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10999948,\n",
            " 'Loss/localization_loss': 0.042400345,\n",
            " 'Loss/regularization_loss': 0.73873544,\n",
            " 'Loss/total_loss': 0.8911353,\n",
            " 'learning_rate': 0.039908648}\n",
            "I1118 18:29:33.506060 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.10999948,\n",
            " 'Loss/localization_loss': 0.042400345,\n",
            " 'Loss/regularization_loss': 0.73873544,\n",
            " 'Loss/total_loss': 0.8911353,\n",
            " 'learning_rate': 0.039908648}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.083s\n",
            "I1118 18:31:21.818784 136149638571136 model_lib_v2.py:705] Step 2800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11808287,\n",
            " 'Loss/localization_loss': 0.074360766,\n",
            " 'Loss/regularization_loss': 0.736682,\n",
            " 'Loss/total_loss': 0.92912567,\n",
            " 'learning_rate': 0.039880715}\n",
            "I1118 18:31:21.819055 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.11808287,\n",
            " 'Loss/localization_loss': 0.074360766,\n",
            " 'Loss/regularization_loss': 0.736682,\n",
            " 'Loss/total_loss': 0.92912567,\n",
            " 'learning_rate': 0.039880715}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.083s\n",
            "I1118 18:33:10.143944 136149638571136 model_lib_v2.py:705] Step 2900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11727318,\n",
            " 'Loss/localization_loss': 0.04466285,\n",
            " 'Loss/regularization_loss': 0.73463464,\n",
            " 'Loss/total_loss': 0.8965707,\n",
            " 'learning_rate': 0.039849065}\n",
            "I1118 18:33:10.144212 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.11727318,\n",
            " 'Loss/localization_loss': 0.04466285,\n",
            " 'Loss/regularization_loss': 0.73463464,\n",
            " 'Loss/total_loss': 0.8965707,\n",
            " 'learning_rate': 0.039849065}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.083s\n",
            "I1118 18:34:58.469290 136149638571136 model_lib_v2.py:705] Step 3000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09599663,\n",
            " 'Loss/localization_loss': 0.04702189,\n",
            " 'Loss/regularization_loss': 0.73259133,\n",
            " 'Loss/total_loss': 0.8756098,\n",
            " 'learning_rate': 0.03981372}\n",
            "I1118 18:34:58.469604 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09599663,\n",
            " 'Loss/localization_loss': 0.04702189,\n",
            " 'Loss/regularization_loss': 0.73259133,\n",
            " 'Loss/total_loss': 0.8756098,\n",
            " 'learning_rate': 0.03981372}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.093s\n",
            "I1118 18:36:47.793983 136149638571136 model_lib_v2.py:705] Step 3100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.120265625,\n",
            " 'Loss/localization_loss': 0.067736045,\n",
            " 'Loss/regularization_loss': 0.7305787,\n",
            " 'Loss/total_loss': 0.91858035,\n",
            " 'learning_rate': 0.03977467}\n",
            "I1118 18:36:47.794265 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.120265625,\n",
            " 'Loss/localization_loss': 0.067736045,\n",
            " 'Loss/regularization_loss': 0.7305787,\n",
            " 'Loss/total_loss': 0.91858035,\n",
            " 'learning_rate': 0.03977467}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.083s\n",
            "I1118 18:38:36.134260 136149638571136 model_lib_v2.py:705] Step 3200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.119358554,\n",
            " 'Loss/localization_loss': 0.07101131,\n",
            " 'Loss/regularization_loss': 0.72856545,\n",
            " 'Loss/total_loss': 0.9189353,\n",
            " 'learning_rate': 0.03973194}\n",
            "I1118 18:38:36.134549 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.119358554,\n",
            " 'Loss/localization_loss': 0.07101131,\n",
            " 'Loss/regularization_loss': 0.72856545,\n",
            " 'Loss/total_loss': 0.9189353,\n",
            " 'learning_rate': 0.03973194}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.083s\n",
            "I1118 18:40:24.468744 136149638571136 model_lib_v2.py:705] Step 3300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.097008355,\n",
            " 'Loss/localization_loss': 0.051054075,\n",
            " 'Loss/regularization_loss': 0.72652245,\n",
            " 'Loss/total_loss': 0.87458485,\n",
            " 'learning_rate': 0.03968552}\n",
            "I1118 18:40:24.469016 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.097008355,\n",
            " 'Loss/localization_loss': 0.051054075,\n",
            " 'Loss/regularization_loss': 0.72652245,\n",
            " 'Loss/total_loss': 0.87458485,\n",
            " 'learning_rate': 0.03968552}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.083s\n",
            "I1118 18:42:12.781724 136149638571136 model_lib_v2.py:705] Step 3400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09391105,\n",
            " 'Loss/localization_loss': 0.04705239,\n",
            " 'Loss/regularization_loss': 0.72447485,\n",
            " 'Loss/total_loss': 0.8654383,\n",
            " 'learning_rate': 0.039635435}\n",
            "I1118 18:42:12.781990 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09391105,\n",
            " 'Loss/localization_loss': 0.04705239,\n",
            " 'Loss/regularization_loss': 0.72447485,\n",
            " 'Loss/total_loss': 0.8654383,\n",
            " 'learning_rate': 0.039635435}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.083s\n",
            "I1118 18:44:01.114332 136149638571136 model_lib_v2.py:705] Step 3500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.109844506,\n",
            " 'Loss/localization_loss': 0.057908356,\n",
            " 'Loss/regularization_loss': 0.7224599,\n",
            " 'Loss/total_loss': 0.8902128,\n",
            " 'learning_rate': 0.03958168}\n",
            "I1118 18:44:01.114629 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.109844506,\n",
            " 'Loss/localization_loss': 0.057908356,\n",
            " 'Loss/regularization_loss': 0.7224599,\n",
            " 'Loss/total_loss': 0.8902128,\n",
            " 'learning_rate': 0.03958168}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.083s\n",
            "I1118 18:45:49.442376 136149638571136 model_lib_v2.py:705] Step 3600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102966085,\n",
            " 'Loss/localization_loss': 0.068267144,\n",
            " 'Loss/regularization_loss': 0.72042817,\n",
            " 'Loss/total_loss': 0.8916614,\n",
            " 'learning_rate': 0.039524276}\n",
            "I1118 18:45:49.442690 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.102966085,\n",
            " 'Loss/localization_loss': 0.068267144,\n",
            " 'Loss/regularization_loss': 0.72042817,\n",
            " 'Loss/total_loss': 0.8916614,\n",
            " 'learning_rate': 0.039524276}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.083s\n",
            "I1118 18:47:37.782572 136149638571136 model_lib_v2.py:705] Step 3700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.100101545,\n",
            " 'Loss/localization_loss': 0.0834445,\n",
            " 'Loss/regularization_loss': 0.71842134,\n",
            " 'Loss/total_loss': 0.90196735,\n",
            " 'learning_rate': 0.03946323}\n",
            "I1118 18:47:37.782857 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.100101545,\n",
            " 'Loss/localization_loss': 0.0834445,\n",
            " 'Loss/regularization_loss': 0.71842134,\n",
            " 'Loss/total_loss': 0.90196735,\n",
            " 'learning_rate': 0.03946323}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.083s\n",
            "I1118 18:49:26.110414 136149638571136 model_lib_v2.py:705] Step 3800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09443792,\n",
            " 'Loss/localization_loss': 0.05410985,\n",
            " 'Loss/regularization_loss': 0.7164064,\n",
            " 'Loss/total_loss': 0.8649542,\n",
            " 'learning_rate': 0.039398547}\n",
            "I1118 18:49:26.110702 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09443792,\n",
            " 'Loss/localization_loss': 0.05410985,\n",
            " 'Loss/regularization_loss': 0.7164064,\n",
            " 'Loss/total_loss': 0.8649542,\n",
            " 'learning_rate': 0.039398547}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.083s\n",
            "I1118 18:51:14.453630 136149638571136 model_lib_v2.py:705] Step 3900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09966024,\n",
            " 'Loss/localization_loss': 0.055140845,\n",
            " 'Loss/regularization_loss': 0.71440506,\n",
            " 'Loss/total_loss': 0.86920613,\n",
            " 'learning_rate': 0.039330248}\n",
            "I1118 18:51:14.453892 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09966024,\n",
            " 'Loss/localization_loss': 0.055140845,\n",
            " 'Loss/regularization_loss': 0.71440506,\n",
            " 'Loss/total_loss': 0.86920613,\n",
            " 'learning_rate': 0.039330248}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.084s\n",
            "I1118 18:53:02.805421 136149638571136 model_lib_v2.py:705] Step 4000 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.077647194,\n",
            " 'Loss/localization_loss': 0.04256133,\n",
            " 'Loss/regularization_loss': 0.71239245,\n",
            " 'Loss/total_loss': 0.832601,\n",
            " 'learning_rate': 0.039258346}\n",
            "I1118 18:53:02.805692 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.077647194,\n",
            " 'Loss/localization_loss': 0.04256133,\n",
            " 'Loss/regularization_loss': 0.71239245,\n",
            " 'Loss/total_loss': 0.832601,\n",
            " 'learning_rate': 0.039258346}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.094s\n",
            "I1118 18:54:52.228366 136149638571136 model_lib_v2.py:705] Step 4100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09245012,\n",
            " 'Loss/localization_loss': 0.045454327,\n",
            " 'Loss/regularization_loss': 0.7103769,\n",
            " 'Loss/total_loss': 0.8482814,\n",
            " 'learning_rate': 0.03918285}\n",
            "I1118 18:54:52.228679 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09245012,\n",
            " 'Loss/localization_loss': 0.045454327,\n",
            " 'Loss/regularization_loss': 0.7103769,\n",
            " 'Loss/total_loss': 0.8482814,\n",
            " 'learning_rate': 0.03918285}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.084s\n",
            "I1118 18:56:40.583913 136149638571136 model_lib_v2.py:705] Step 4200 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07610043,\n",
            " 'Loss/localization_loss': 0.03318782,\n",
            " 'Loss/regularization_loss': 0.7083827,\n",
            " 'Loss/total_loss': 0.81767094,\n",
            " 'learning_rate': 0.03910377}\n",
            "I1118 18:56:40.584261 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07610043,\n",
            " 'Loss/localization_loss': 0.03318782,\n",
            " 'Loss/regularization_loss': 0.7083827,\n",
            " 'Loss/total_loss': 0.81767094,\n",
            " 'learning_rate': 0.03910377}\n",
            "INFO:tensorflow:Step 4300 per-step time 1.083s\n",
            "I1118 18:58:28.919405 136149638571136 model_lib_v2.py:705] Step 4300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11427683,\n",
            " 'Loss/localization_loss': 0.04405654,\n",
            " 'Loss/regularization_loss': 0.70638746,\n",
            " 'Loss/total_loss': 0.8647208,\n",
            " 'learning_rate': 0.039021127}\n",
            "I1118 18:58:28.919675 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.11427683,\n",
            " 'Loss/localization_loss': 0.04405654,\n",
            " 'Loss/regularization_loss': 0.70638746,\n",
            " 'Loss/total_loss': 0.8647208,\n",
            " 'learning_rate': 0.039021127}\n",
            "INFO:tensorflow:Step 4400 per-step time 1.083s\n",
            "I1118 19:00:17.250266 136149638571136 model_lib_v2.py:705] Step 4400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.092594124,\n",
            " 'Loss/localization_loss': 0.030985208,\n",
            " 'Loss/regularization_loss': 0.7044304,\n",
            " 'Loss/total_loss': 0.8280098,\n",
            " 'learning_rate': 0.03893494}\n",
            "I1118 19:00:17.250591 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.092594124,\n",
            " 'Loss/localization_loss': 0.030985208,\n",
            " 'Loss/regularization_loss': 0.7044304,\n",
            " 'Loss/total_loss': 0.8280098,\n",
            " 'learning_rate': 0.03893494}\n",
            "INFO:tensorflow:Step 4500 per-step time 1.083s\n",
            "I1118 19:02:05.593809 136149638571136 model_lib_v2.py:705] Step 4500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07215718,\n",
            " 'Loss/localization_loss': 0.035324514,\n",
            " 'Loss/regularization_loss': 0.70244974,\n",
            " 'Loss/total_loss': 0.80993146,\n",
            " 'learning_rate': 0.03884522}\n",
            "I1118 19:02:05.594073 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07215718,\n",
            " 'Loss/localization_loss': 0.035324514,\n",
            " 'Loss/regularization_loss': 0.70244974,\n",
            " 'Loss/total_loss': 0.80993146,\n",
            " 'learning_rate': 0.03884522}\n",
            "INFO:tensorflow:Step 4600 per-step time 1.084s\n",
            "I1118 19:03:53.953176 136149638571136 model_lib_v2.py:705] Step 4600 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08897792,\n",
            " 'Loss/localization_loss': 0.050933227,\n",
            " 'Loss/regularization_loss': 0.7004949,\n",
            " 'Loss/total_loss': 0.84040606,\n",
            " 'learning_rate': 0.03875198}\n",
            "I1118 19:03:53.953469 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.08897792,\n",
            " 'Loss/localization_loss': 0.050933227,\n",
            " 'Loss/regularization_loss': 0.7004949,\n",
            " 'Loss/total_loss': 0.84040606,\n",
            " 'learning_rate': 0.03875198}\n",
            "INFO:tensorflow:Step 4700 per-step time 1.083s\n",
            "I1118 19:05:42.300082 136149638571136 model_lib_v2.py:705] Step 4700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06398538,\n",
            " 'Loss/localization_loss': 0.03756807,\n",
            " 'Loss/regularization_loss': 0.6985569,\n",
            " 'Loss/total_loss': 0.80011034,\n",
            " 'learning_rate': 0.038655244}\n",
            "I1118 19:05:42.300350 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06398538,\n",
            " 'Loss/localization_loss': 0.03756807,\n",
            " 'Loss/regularization_loss': 0.6985569,\n",
            " 'Loss/total_loss': 0.80011034,\n",
            " 'learning_rate': 0.038655244}\n",
            "INFO:tensorflow:Step 4800 per-step time 1.083s\n",
            "I1118 19:07:30.635982 136149638571136 model_lib_v2.py:705] Step 4800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06950346,\n",
            " 'Loss/localization_loss': 0.028298171,\n",
            " 'Loss/regularization_loss': 0.6966007,\n",
            " 'Loss/total_loss': 0.7944023,\n",
            " 'learning_rate': 0.038555026}\n",
            "I1118 19:07:30.636258 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06950346,\n",
            " 'Loss/localization_loss': 0.028298171,\n",
            " 'Loss/regularization_loss': 0.6966007,\n",
            " 'Loss/total_loss': 0.7944023,\n",
            " 'learning_rate': 0.038555026}\n",
            "INFO:tensorflow:Step 4900 per-step time 1.083s\n",
            "I1118 19:09:18.965569 136149638571136 model_lib_v2.py:705] Step 4900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09222074,\n",
            " 'Loss/localization_loss': 0.03583355,\n",
            " 'Loss/regularization_loss': 0.694655,\n",
            " 'Loss/total_loss': 0.82270926,\n",
            " 'learning_rate': 0.038451348}\n",
            "I1118 19:09:18.965846 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09222074,\n",
            " 'Loss/localization_loss': 0.03583355,\n",
            " 'Loss/regularization_loss': 0.694655,\n",
            " 'Loss/total_loss': 0.82270926,\n",
            " 'learning_rate': 0.038451348}\n",
            "INFO:tensorflow:Step 5000 per-step time 1.083s\n",
            "I1118 19:11:07.307239 136149638571136 model_lib_v2.py:705] Step 5000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07743194,\n",
            " 'Loss/localization_loss': 0.04093303,\n",
            " 'Loss/regularization_loss': 0.6926992,\n",
            " 'Loss/total_loss': 0.8110641,\n",
            " 'learning_rate': 0.038344227}\n",
            "I1118 19:11:07.307540 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07743194,\n",
            " 'Loss/localization_loss': 0.04093303,\n",
            " 'Loss/regularization_loss': 0.6926992,\n",
            " 'Loss/total_loss': 0.8110641,\n",
            " 'learning_rate': 0.038344227}\n",
            "INFO:tensorflow:Step 5100 per-step time 1.094s\n",
            "I1118 19:12:56.712626 136149638571136 model_lib_v2.py:705] Step 5100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08322213,\n",
            " 'Loss/localization_loss': 0.035861753,\n",
            " 'Loss/regularization_loss': 0.69076574,\n",
            " 'Loss/total_loss': 0.8098496,\n",
            " 'learning_rate': 0.03823368}\n",
            "I1118 19:12:56.712910 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.08322213,\n",
            " 'Loss/localization_loss': 0.035861753,\n",
            " 'Loss/regularization_loss': 0.69076574,\n",
            " 'Loss/total_loss': 0.8098496,\n",
            " 'learning_rate': 0.03823368}\n",
            "INFO:tensorflow:Step 5200 per-step time 1.083s\n",
            "I1118 19:14:45.045596 136149638571136 model_lib_v2.py:705] Step 5200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.077477045,\n",
            " 'Loss/localization_loss': 0.036169685,\n",
            " 'Loss/regularization_loss': 0.68884254,\n",
            " 'Loss/total_loss': 0.8024893,\n",
            " 'learning_rate': 0.038119733}\n",
            "I1118 19:14:45.045873 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.077477045,\n",
            " 'Loss/localization_loss': 0.036169685,\n",
            " 'Loss/regularization_loss': 0.68884254,\n",
            " 'Loss/total_loss': 0.8024893,\n",
            " 'learning_rate': 0.038119733}\n",
            "INFO:tensorflow:Step 5300 per-step time 1.083s\n",
            "I1118 19:16:33.366234 136149638571136 model_lib_v2.py:705] Step 5300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08441435,\n",
            " 'Loss/localization_loss': 0.034555994,\n",
            " 'Loss/regularization_loss': 0.6869161,\n",
            " 'Loss/total_loss': 0.80588645,\n",
            " 'learning_rate': 0.03800241}\n",
            "I1118 19:16:33.366509 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.08441435,\n",
            " 'Loss/localization_loss': 0.034555994,\n",
            " 'Loss/regularization_loss': 0.6869161,\n",
            " 'Loss/total_loss': 0.80588645,\n",
            " 'learning_rate': 0.03800241}\n",
            "INFO:tensorflow:Step 5400 per-step time 1.083s\n",
            "I1118 19:18:21.686246 136149638571136 model_lib_v2.py:705] Step 5400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07243285,\n",
            " 'Loss/localization_loss': 0.02704338,\n",
            " 'Loss/regularization_loss': 0.6850145,\n",
            " 'Loss/total_loss': 0.78449076,\n",
            " 'learning_rate': 0.037881725}\n",
            "I1118 19:18:21.686568 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07243285,\n",
            " 'Loss/localization_loss': 0.02704338,\n",
            " 'Loss/regularization_loss': 0.6850145,\n",
            " 'Loss/total_loss': 0.78449076,\n",
            " 'learning_rate': 0.037881725}\n",
            "INFO:tensorflow:Step 5500 per-step time 1.083s\n",
            "I1118 19:20:10.032341 136149638571136 model_lib_v2.py:705] Step 5500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08521651,\n",
            " 'Loss/localization_loss': 0.035942227,\n",
            " 'Loss/regularization_loss': 0.68311524,\n",
            " 'Loss/total_loss': 0.80427396,\n",
            " 'learning_rate': 0.037757702}\n",
            "I1118 19:20:10.032617 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.08521651,\n",
            " 'Loss/localization_loss': 0.035942227,\n",
            " 'Loss/regularization_loss': 0.68311524,\n",
            " 'Loss/total_loss': 0.80427396,\n",
            " 'learning_rate': 0.037757702}\n",
            "INFO:tensorflow:Step 5600 per-step time 1.083s\n",
            "I1118 19:21:58.353089 136149638571136 model_lib_v2.py:705] Step 5600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0886117,\n",
            " 'Loss/localization_loss': 0.040658668,\n",
            " 'Loss/regularization_loss': 0.68123573,\n",
            " 'Loss/total_loss': 0.8105061,\n",
            " 'learning_rate': 0.03763037}\n",
            "I1118 19:21:58.353356 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0886117,\n",
            " 'Loss/localization_loss': 0.040658668,\n",
            " 'Loss/regularization_loss': 0.68123573,\n",
            " 'Loss/total_loss': 0.8105061,\n",
            " 'learning_rate': 0.03763037}\n",
            "INFO:tensorflow:Step 5700 per-step time 1.083s\n",
            "I1118 19:23:46.694633 136149638571136 model_lib_v2.py:705] Step 5700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09157081,\n",
            " 'Loss/localization_loss': 0.048880603,\n",
            " 'Loss/regularization_loss': 0.6793599,\n",
            " 'Loss/total_loss': 0.8198113,\n",
            " 'learning_rate': 0.03749975}\n",
            "I1118 19:23:46.694935 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.09157081,\n",
            " 'Loss/localization_loss': 0.048880603,\n",
            " 'Loss/regularization_loss': 0.6793599,\n",
            " 'Loss/total_loss': 0.8198113,\n",
            " 'learning_rate': 0.03749975}\n",
            "INFO:tensorflow:Step 5800 per-step time 1.083s\n",
            "I1118 19:25:35.018282 136149638571136 model_lib_v2.py:705] Step 5800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07055979,\n",
            " 'Loss/localization_loss': 0.02600214,\n",
            " 'Loss/regularization_loss': 0.677499,\n",
            " 'Loss/total_loss': 0.77406096,\n",
            " 'learning_rate': 0.037365858}\n",
            "I1118 19:25:35.018597 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07055979,\n",
            " 'Loss/localization_loss': 0.02600214,\n",
            " 'Loss/regularization_loss': 0.677499,\n",
            " 'Loss/total_loss': 0.77406096,\n",
            " 'learning_rate': 0.037365858}\n",
            "INFO:tensorflow:Step 5900 per-step time 1.083s\n",
            "I1118 19:27:23.350362 136149638571136 model_lib_v2.py:705] Step 5900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.088435665,\n",
            " 'Loss/localization_loss': 0.042301707,\n",
            " 'Loss/regularization_loss': 0.67563057,\n",
            " 'Loss/total_loss': 0.80636793,\n",
            " 'learning_rate': 0.03722873}\n",
            "I1118 19:27:23.350658 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.088435665,\n",
            " 'Loss/localization_loss': 0.042301707,\n",
            " 'Loss/regularization_loss': 0.67563057,\n",
            " 'Loss/total_loss': 0.80636793,\n",
            " 'learning_rate': 0.03722873}\n",
            "INFO:tensorflow:Step 6000 per-step time 1.083s\n",
            "I1118 19:29:11.678067 136149638571136 model_lib_v2.py:705] Step 6000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07294961,\n",
            " 'Loss/localization_loss': 0.03854446,\n",
            " 'Loss/regularization_loss': 0.673793,\n",
            " 'Loss/total_loss': 0.7852871,\n",
            " 'learning_rate': 0.037088387}\n",
            "I1118 19:29:11.678338 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07294961,\n",
            " 'Loss/localization_loss': 0.03854446,\n",
            " 'Loss/regularization_loss': 0.673793,\n",
            " 'Loss/total_loss': 0.7852871,\n",
            " 'learning_rate': 0.037088387}\n",
            "INFO:tensorflow:Step 6100 per-step time 1.094s\n",
            "I1118 19:31:01.048224 136149638571136 model_lib_v2.py:705] Step 6100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06754003,\n",
            " 'Loss/localization_loss': 0.027743189,\n",
            " 'Loss/regularization_loss': 0.671945,\n",
            " 'Loss/total_loss': 0.7672282,\n",
            " 'learning_rate': 0.036944855}\n",
            "I1118 19:31:01.048540 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06754003,\n",
            " 'Loss/localization_loss': 0.027743189,\n",
            " 'Loss/regularization_loss': 0.671945,\n",
            " 'Loss/total_loss': 0.7672282,\n",
            " 'learning_rate': 0.036944855}\n",
            "INFO:tensorflow:Step 6200 per-step time 1.083s\n",
            "I1118 19:32:49.373646 136149638571136 model_lib_v2.py:705] Step 6200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08728723,\n",
            " 'Loss/localization_loss': 0.05459981,\n",
            " 'Loss/regularization_loss': 0.6701217,\n",
            " 'Loss/total_loss': 0.8120088,\n",
            " 'learning_rate': 0.036798168}\n",
            "I1118 19:32:49.373929 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.08728723,\n",
            " 'Loss/localization_loss': 0.05459981,\n",
            " 'Loss/regularization_loss': 0.6701217,\n",
            " 'Loss/total_loss': 0.8120088,\n",
            " 'learning_rate': 0.036798168}\n",
            "INFO:tensorflow:Step 6300 per-step time 1.083s\n",
            "I1118 19:34:37.714005 136149638571136 model_lib_v2.py:705] Step 6300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07820178,\n",
            " 'Loss/localization_loss': 0.03453163,\n",
            " 'Loss/regularization_loss': 0.66830313,\n",
            " 'Loss/total_loss': 0.78103656,\n",
            " 'learning_rate': 0.03664834}\n",
            "I1118 19:34:37.714271 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07820178,\n",
            " 'Loss/localization_loss': 0.03453163,\n",
            " 'Loss/regularization_loss': 0.66830313,\n",
            " 'Loss/total_loss': 0.78103656,\n",
            " 'learning_rate': 0.03664834}\n",
            "INFO:tensorflow:Step 6400 per-step time 1.083s\n",
            "I1118 19:36:26.063151 136149638571136 model_lib_v2.py:705] Step 6400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08133213,\n",
            " 'Loss/localization_loss': 0.02738255,\n",
            " 'Loss/regularization_loss': 0.6664985,\n",
            " 'Loss/total_loss': 0.7752132,\n",
            " 'learning_rate': 0.03649541}\n",
            "I1118 19:36:26.063431 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.08133213,\n",
            " 'Loss/localization_loss': 0.02738255,\n",
            " 'Loss/regularization_loss': 0.6664985,\n",
            " 'Loss/total_loss': 0.7752132,\n",
            " 'learning_rate': 0.03649541}\n",
            "INFO:tensorflow:Step 6500 per-step time 1.083s\n",
            "I1118 19:38:14.389763 136149638571136 model_lib_v2.py:705] Step 6500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.070085905,\n",
            " 'Loss/localization_loss': 0.031252194,\n",
            " 'Loss/regularization_loss': 0.66471237,\n",
            " 'Loss/total_loss': 0.76605046,\n",
            " 'learning_rate': 0.0363394}\n",
            "I1118 19:38:14.390050 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.070085905,\n",
            " 'Loss/localization_loss': 0.031252194,\n",
            " 'Loss/regularization_loss': 0.66471237,\n",
            " 'Loss/total_loss': 0.76605046,\n",
            " 'learning_rate': 0.0363394}\n",
            "INFO:tensorflow:Step 6600 per-step time 1.083s\n",
            "I1118 19:40:02.720149 136149638571136 model_lib_v2.py:705] Step 6600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05645034,\n",
            " 'Loss/localization_loss': 0.025921129,\n",
            " 'Loss/regularization_loss': 0.6629235,\n",
            " 'Loss/total_loss': 0.745295,\n",
            " 'learning_rate': 0.03618034}\n",
            "I1118 19:40:02.720443 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05645034,\n",
            " 'Loss/localization_loss': 0.025921129,\n",
            " 'Loss/regularization_loss': 0.6629235,\n",
            " 'Loss/total_loss': 0.745295,\n",
            " 'learning_rate': 0.03618034}\n",
            "INFO:tensorflow:Step 6700 per-step time 1.083s\n",
            "I1118 19:41:51.050634 136149638571136 model_lib_v2.py:705] Step 6700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06573406,\n",
            " 'Loss/localization_loss': 0.01668494,\n",
            " 'Loss/regularization_loss': 0.6611508,\n",
            " 'Loss/total_loss': 0.7435698,\n",
            " 'learning_rate': 0.03601826}\n",
            "I1118 19:41:51.050895 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06573406,\n",
            " 'Loss/localization_loss': 0.01668494,\n",
            " 'Loss/regularization_loss': 0.6611508,\n",
            " 'Loss/total_loss': 0.7435698,\n",
            " 'learning_rate': 0.03601826}\n",
            "INFO:tensorflow:Step 6800 per-step time 1.083s\n",
            "I1118 19:43:39.376325 136149638571136 model_lib_v2.py:705] Step 6800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06947035,\n",
            " 'Loss/localization_loss': 0.026795045,\n",
            " 'Loss/regularization_loss': 0.65940094,\n",
            " 'Loss/total_loss': 0.7556663,\n",
            " 'learning_rate': 0.035853196}\n",
            "I1118 19:43:39.376607 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06947035,\n",
            " 'Loss/localization_loss': 0.026795045,\n",
            " 'Loss/regularization_loss': 0.65940094,\n",
            " 'Loss/total_loss': 0.7556663,\n",
            " 'learning_rate': 0.035853196}\n",
            "INFO:tensorflow:Step 6900 per-step time 1.083s\n",
            "I1118 19:45:27.710459 136149638571136 model_lib_v2.py:705] Step 6900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07538694,\n",
            " 'Loss/localization_loss': 0.03153732,\n",
            " 'Loss/regularization_loss': 0.6576776,\n",
            " 'Loss/total_loss': 0.7646018,\n",
            " 'learning_rate': 0.035685178}\n",
            "I1118 19:45:27.710763 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07538694,\n",
            " 'Loss/localization_loss': 0.03153732,\n",
            " 'Loss/regularization_loss': 0.6576776,\n",
            " 'Loss/total_loss': 0.7646018,\n",
            " 'learning_rate': 0.035685178}\n",
            "INFO:tensorflow:Step 7000 per-step time 1.084s\n",
            "I1118 19:47:16.064097 136149638571136 model_lib_v2.py:705] Step 7000 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07364089,\n",
            " 'Loss/localization_loss': 0.021151284,\n",
            " 'Loss/regularization_loss': 0.6559838,\n",
            " 'Loss/total_loss': 0.750776,\n",
            " 'learning_rate': 0.035514224}\n",
            "I1118 19:47:16.064394 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07364089,\n",
            " 'Loss/localization_loss': 0.021151284,\n",
            " 'Loss/regularization_loss': 0.6559838,\n",
            " 'Loss/total_loss': 0.750776,\n",
            " 'learning_rate': 0.035514224}\n",
            "INFO:tensorflow:Step 7100 per-step time 1.094s\n",
            "I1118 19:49:05.492922 136149638571136 model_lib_v2.py:705] Step 7100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06191181,\n",
            " 'Loss/localization_loss': 0.016614567,\n",
            " 'Loss/regularization_loss': 0.65426475,\n",
            " 'Loss/total_loss': 0.7327911,\n",
            " 'learning_rate': 0.035340384}\n",
            "I1118 19:49:05.493210 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06191181,\n",
            " 'Loss/localization_loss': 0.016614567,\n",
            " 'Loss/regularization_loss': 0.65426475,\n",
            " 'Loss/total_loss': 0.7327911,\n",
            " 'learning_rate': 0.035340384}\n",
            "INFO:tensorflow:Step 7200 per-step time 1.083s\n",
            "I1118 19:50:53.819172 136149638571136 model_lib_v2.py:705] Step 7200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07299195,\n",
            " 'Loss/localization_loss': 0.03214347,\n",
            " 'Loss/regularization_loss': 0.65255,\n",
            " 'Loss/total_loss': 0.7576854,\n",
            " 'learning_rate': 0.035163675}\n",
            "I1118 19:50:53.819460 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07299195,\n",
            " 'Loss/localization_loss': 0.03214347,\n",
            " 'Loss/regularization_loss': 0.65255,\n",
            " 'Loss/total_loss': 0.7576854,\n",
            " 'learning_rate': 0.035163675}\n",
            "INFO:tensorflow:Step 7300 per-step time 1.083s\n",
            "I1118 19:52:42.160499 136149638571136 model_lib_v2.py:705] Step 7300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05916843,\n",
            " 'Loss/localization_loss': 0.02177108,\n",
            " 'Loss/regularization_loss': 0.65085036,\n",
            " 'Loss/total_loss': 0.7317898,\n",
            " 'learning_rate': 0.034984138}\n",
            "I1118 19:52:42.160770 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05916843,\n",
            " 'Loss/localization_loss': 0.02177108,\n",
            " 'Loss/regularization_loss': 0.65085036,\n",
            " 'Loss/total_loss': 0.7317898,\n",
            " 'learning_rate': 0.034984138}\n",
            "INFO:tensorflow:Step 7400 per-step time 1.083s\n",
            "I1118 19:54:30.499965 136149638571136 model_lib_v2.py:705] Step 7400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0775299,\n",
            " 'Loss/localization_loss': 0.0340861,\n",
            " 'Loss/regularization_loss': 0.6491537,\n",
            " 'Loss/total_loss': 0.7607697,\n",
            " 'learning_rate': 0.03480181}\n",
            "I1118 19:54:30.500232 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0775299,\n",
            " 'Loss/localization_loss': 0.0340861,\n",
            " 'Loss/regularization_loss': 0.6491537,\n",
            " 'Loss/total_loss': 0.7607697,\n",
            " 'learning_rate': 0.03480181}\n",
            "INFO:tensorflow:Step 7500 per-step time 1.083s\n",
            "I1118 19:56:18.843206 136149638571136 model_lib_v2.py:705] Step 7500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059828684,\n",
            " 'Loss/localization_loss': 0.02434814,\n",
            " 'Loss/regularization_loss': 0.6474701,\n",
            " 'Loss/total_loss': 0.73164696,\n",
            " 'learning_rate': 0.034616716}\n",
            "I1118 19:56:18.843487 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.059828684,\n",
            " 'Loss/localization_loss': 0.02434814,\n",
            " 'Loss/regularization_loss': 0.6474701,\n",
            " 'Loss/total_loss': 0.73164696,\n",
            " 'learning_rate': 0.034616716}\n",
            "INFO:tensorflow:Step 7600 per-step time 1.083s\n",
            "I1118 19:58:07.189923 136149638571136 model_lib_v2.py:705] Step 7600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07181966,\n",
            " 'Loss/localization_loss': 0.021631496,\n",
            " 'Loss/regularization_loss': 0.64579666,\n",
            " 'Loss/total_loss': 0.7392478,\n",
            " 'learning_rate': 0.0344289}\n",
            "I1118 19:58:07.190185 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07181966,\n",
            " 'Loss/localization_loss': 0.021631496,\n",
            " 'Loss/regularization_loss': 0.64579666,\n",
            " 'Loss/total_loss': 0.7392478,\n",
            " 'learning_rate': 0.0344289}\n",
            "INFO:tensorflow:Step 7700 per-step time 1.083s\n",
            "I1118 19:59:55.532432 136149638571136 model_lib_v2.py:705] Step 7700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.056698266,\n",
            " 'Loss/localization_loss': 0.02203989,\n",
            " 'Loss/regularization_loss': 0.6441465,\n",
            " 'Loss/total_loss': 0.72288465,\n",
            " 'learning_rate': 0.03423839}\n",
            "I1118 19:59:55.532703 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.056698266,\n",
            " 'Loss/localization_loss': 0.02203989,\n",
            " 'Loss/regularization_loss': 0.6441465,\n",
            " 'Loss/total_loss': 0.72288465,\n",
            " 'learning_rate': 0.03423839}\n",
            "INFO:tensorflow:Step 7800 per-step time 1.084s\n",
            "I1118 20:01:43.883679 136149638571136 model_lib_v2.py:705] Step 7800 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053601246,\n",
            " 'Loss/localization_loss': 0.016064435,\n",
            " 'Loss/regularization_loss': 0.64249855,\n",
            " 'Loss/total_loss': 0.7121643,\n",
            " 'learning_rate': 0.03404522}\n",
            "I1118 20:01:43.883951 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.053601246,\n",
            " 'Loss/localization_loss': 0.016064435,\n",
            " 'Loss/regularization_loss': 0.64249855,\n",
            " 'Loss/total_loss': 0.7121643,\n",
            " 'learning_rate': 0.03404522}\n",
            "INFO:tensorflow:Step 7900 per-step time 1.083s\n",
            "I1118 20:03:32.210868 136149638571136 model_lib_v2.py:705] Step 7900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059304215,\n",
            " 'Loss/localization_loss': 0.02241241,\n",
            " 'Loss/regularization_loss': 0.64086753,\n",
            " 'Loss/total_loss': 0.7225842,\n",
            " 'learning_rate': 0.033849433}\n",
            "I1118 20:03:32.211145 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.059304215,\n",
            " 'Loss/localization_loss': 0.02241241,\n",
            " 'Loss/regularization_loss': 0.64086753,\n",
            " 'Loss/total_loss': 0.7225842,\n",
            " 'learning_rate': 0.033849433}\n",
            "INFO:tensorflow:Step 8000 per-step time 1.083s\n",
            "I1118 20:05:20.541584 136149638571136 model_lib_v2.py:705] Step 8000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05395137,\n",
            " 'Loss/localization_loss': 0.025939405,\n",
            " 'Loss/regularization_loss': 0.6392414,\n",
            " 'Loss/total_loss': 0.7191322,\n",
            " 'learning_rate': 0.03365106}\n",
            "I1118 20:05:20.541869 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05395137,\n",
            " 'Loss/localization_loss': 0.025939405,\n",
            " 'Loss/regularization_loss': 0.6392414,\n",
            " 'Loss/total_loss': 0.7191322,\n",
            " 'learning_rate': 0.03365106}\n",
            "INFO:tensorflow:Step 8100 per-step time 1.094s\n",
            "I1118 20:07:09.898602 136149638571136 model_lib_v2.py:705] Step 8100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055597685,\n",
            " 'Loss/localization_loss': 0.020079253,\n",
            " 'Loss/regularization_loss': 0.63764334,\n",
            " 'Loss/total_loss': 0.71332026,\n",
            " 'learning_rate': 0.033450145}\n",
            "I1118 20:07:09.898887 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.055597685,\n",
            " 'Loss/localization_loss': 0.020079253,\n",
            " 'Loss/regularization_loss': 0.63764334,\n",
            " 'Loss/total_loss': 0.71332026,\n",
            " 'learning_rate': 0.033450145}\n",
            "INFO:tensorflow:Step 8200 per-step time 1.083s\n",
            "I1118 20:08:58.231502 136149638571136 model_lib_v2.py:705] Step 8200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054048244,\n",
            " 'Loss/localization_loss': 0.018426022,\n",
            " 'Loss/regularization_loss': 0.63604766,\n",
            " 'Loss/total_loss': 0.7085219,\n",
            " 'learning_rate': 0.03324672}\n",
            "I1118 20:08:58.231765 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.054048244,\n",
            " 'Loss/localization_loss': 0.018426022,\n",
            " 'Loss/regularization_loss': 0.63604766,\n",
            " 'Loss/total_loss': 0.7085219,\n",
            " 'learning_rate': 0.03324672}\n",
            "INFO:tensorflow:Step 8300 per-step time 1.083s\n",
            "I1118 20:10:46.578591 136149638571136 model_lib_v2.py:705] Step 8300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068608604,\n",
            " 'Loss/localization_loss': 0.028950684,\n",
            " 'Loss/regularization_loss': 0.63445884,\n",
            " 'Loss/total_loss': 0.7320181,\n",
            " 'learning_rate': 0.033040818}\n",
            "I1118 20:10:46.578889 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.068608604,\n",
            " 'Loss/localization_loss': 0.028950684,\n",
            " 'Loss/regularization_loss': 0.63445884,\n",
            " 'Loss/total_loss': 0.7320181,\n",
            " 'learning_rate': 0.033040818}\n",
            "INFO:tensorflow:Step 8400 per-step time 1.083s\n",
            "I1118 20:12:34.913158 136149638571136 model_lib_v2.py:705] Step 8400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.057680674,\n",
            " 'Loss/localization_loss': 0.019778162,\n",
            " 'Loss/regularization_loss': 0.6328896,\n",
            " 'Loss/total_loss': 0.7103485,\n",
            " 'learning_rate': 0.032832485}\n",
            "I1118 20:12:34.913460 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.057680674,\n",
            " 'Loss/localization_loss': 0.019778162,\n",
            " 'Loss/regularization_loss': 0.6328896,\n",
            " 'Loss/total_loss': 0.7103485,\n",
            " 'learning_rate': 0.032832485}\n",
            "INFO:tensorflow:Step 8500 per-step time 1.083s\n",
            "I1118 20:14:23.245454 136149638571136 model_lib_v2.py:705] Step 8500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054016657,\n",
            " 'Loss/localization_loss': 0.017533615,\n",
            " 'Loss/regularization_loss': 0.6313529,\n",
            " 'Loss/total_loss': 0.70290315,\n",
            " 'learning_rate': 0.032621756}\n",
            "I1118 20:14:23.245725 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.054016657,\n",
            " 'Loss/localization_loss': 0.017533615,\n",
            " 'Loss/regularization_loss': 0.6313529,\n",
            " 'Loss/total_loss': 0.70290315,\n",
            " 'learning_rate': 0.032621756}\n",
            "INFO:tensorflow:Step 8600 per-step time 1.083s\n",
            "I1118 20:16:11.589412 136149638571136 model_lib_v2.py:705] Step 8600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060223825,\n",
            " 'Loss/localization_loss': 0.024278428,\n",
            " 'Loss/regularization_loss': 0.62981045,\n",
            " 'Loss/total_loss': 0.7143127,\n",
            " 'learning_rate': 0.032408677}\n",
            "I1118 20:16:11.589681 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.060223825,\n",
            " 'Loss/localization_loss': 0.024278428,\n",
            " 'Loss/regularization_loss': 0.62981045,\n",
            " 'Loss/total_loss': 0.7143127,\n",
            " 'learning_rate': 0.032408677}\n",
            "INFO:tensorflow:Step 8700 per-step time 1.083s\n",
            "I1118 20:17:59.925082 136149638571136 model_lib_v2.py:705] Step 8700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05003534,\n",
            " 'Loss/localization_loss': 0.018595383,\n",
            " 'Loss/regularization_loss': 0.6282973,\n",
            " 'Loss/total_loss': 0.6969281,\n",
            " 'learning_rate': 0.032193277}\n",
            "I1118 20:17:59.925352 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05003534,\n",
            " 'Loss/localization_loss': 0.018595383,\n",
            " 'Loss/regularization_loss': 0.6282973,\n",
            " 'Loss/total_loss': 0.6969281,\n",
            " 'learning_rate': 0.032193277}\n",
            "INFO:tensorflow:Step 8800 per-step time 1.084s\n",
            "I1118 20:19:48.278696 136149638571136 model_lib_v2.py:705] Step 8800 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05540996,\n",
            " 'Loss/localization_loss': 0.021549873,\n",
            " 'Loss/regularization_loss': 0.6267966,\n",
            " 'Loss/total_loss': 0.70375645,\n",
            " 'learning_rate': 0.03197561}\n",
            "I1118 20:19:48.278990 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05540996,\n",
            " 'Loss/localization_loss': 0.021549873,\n",
            " 'Loss/regularization_loss': 0.6267966,\n",
            " 'Loss/total_loss': 0.70375645,\n",
            " 'learning_rate': 0.03197561}\n",
            "INFO:tensorflow:Step 8900 per-step time 1.083s\n",
            "I1118 20:21:36.608599 136149638571136 model_lib_v2.py:705] Step 8900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050819296,\n",
            " 'Loss/localization_loss': 0.020687284,\n",
            " 'Loss/regularization_loss': 0.62529594,\n",
            " 'Loss/total_loss': 0.6968025,\n",
            " 'learning_rate': 0.031755704}\n",
            "I1118 20:21:36.608919 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.050819296,\n",
            " 'Loss/localization_loss': 0.020687284,\n",
            " 'Loss/regularization_loss': 0.62529594,\n",
            " 'Loss/total_loss': 0.6968025,\n",
            " 'learning_rate': 0.031755704}\n",
            "INFO:tensorflow:Step 9000 per-step time 1.083s\n",
            "I1118 20:23:24.950459 136149638571136 model_lib_v2.py:705] Step 9000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.065551564,\n",
            " 'Loss/localization_loss': 0.03086848,\n",
            " 'Loss/regularization_loss': 0.62379533,\n",
            " 'Loss/total_loss': 0.7202154,\n",
            " 'learning_rate': 0.031533606}\n",
            "I1118 20:23:24.950777 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.065551564,\n",
            " 'Loss/localization_loss': 0.03086848,\n",
            " 'Loss/regularization_loss': 0.62379533,\n",
            " 'Loss/total_loss': 0.7202154,\n",
            " 'learning_rate': 0.031533606}\n",
            "INFO:tensorflow:Step 9100 per-step time 1.094s\n",
            "I1118 20:25:14.311519 136149638571136 model_lib_v2.py:705] Step 9100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058300488,\n",
            " 'Loss/localization_loss': 0.017548006,\n",
            " 'Loss/regularization_loss': 0.6223202,\n",
            " 'Loss/total_loss': 0.6981687,\n",
            " 'learning_rate': 0.031309355}\n",
            "I1118 20:25:14.311818 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.058300488,\n",
            " 'Loss/localization_loss': 0.017548006,\n",
            " 'Loss/regularization_loss': 0.6223202,\n",
            " 'Loss/total_loss': 0.6981687,\n",
            " 'learning_rate': 0.031309355}\n",
            "INFO:tensorflow:Step 9200 per-step time 1.083s\n",
            "I1118 20:27:02.655007 136149638571136 model_lib_v2.py:705] Step 9200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04966746,\n",
            " 'Loss/localization_loss': 0.020255812,\n",
            " 'Loss/regularization_loss': 0.6208516,\n",
            " 'Loss/total_loss': 0.69077486,\n",
            " 'learning_rate': 0.031082997}\n",
            "I1118 20:27:02.655275 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04966746,\n",
            " 'Loss/localization_loss': 0.020255812,\n",
            " 'Loss/regularization_loss': 0.6208516,\n",
            " 'Loss/total_loss': 0.69077486,\n",
            " 'learning_rate': 0.031082997}\n",
            "INFO:tensorflow:Step 9300 per-step time 1.083s\n",
            "I1118 20:28:50.991366 136149638571136 model_lib_v2.py:705] Step 9300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05682545,\n",
            " 'Loss/localization_loss': 0.014698212,\n",
            " 'Loss/regularization_loss': 0.61940926,\n",
            " 'Loss/total_loss': 0.6909329,\n",
            " 'learning_rate': 0.030854566}\n",
            "I1118 20:28:50.991653 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05682545,\n",
            " 'Loss/localization_loss': 0.014698212,\n",
            " 'Loss/regularization_loss': 0.61940926,\n",
            " 'Loss/total_loss': 0.6909329,\n",
            " 'learning_rate': 0.030854566}\n",
            "INFO:tensorflow:Step 9400 per-step time 1.083s\n",
            "I1118 20:30:39.326756 136149638571136 model_lib_v2.py:705] Step 9400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059731472,\n",
            " 'Loss/localization_loss': 0.018514076,\n",
            " 'Loss/regularization_loss': 0.6179695,\n",
            " 'Loss/total_loss': 0.6962151,\n",
            " 'learning_rate': 0.030624112}\n",
            "I1118 20:30:39.327026 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.059731472,\n",
            " 'Loss/localization_loss': 0.018514076,\n",
            " 'Loss/regularization_loss': 0.6179695,\n",
            " 'Loss/total_loss': 0.6962151,\n",
            " 'learning_rate': 0.030624112}\n",
            "INFO:tensorflow:Step 9500 per-step time 1.083s\n",
            "I1118 20:32:27.652199 136149638571136 model_lib_v2.py:705] Step 9500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06575026,\n",
            " 'Loss/localization_loss': 0.026891157,\n",
            " 'Loss/regularization_loss': 0.6165421,\n",
            " 'Loss/total_loss': 0.7091835,\n",
            " 'learning_rate': 0.030391678}\n",
            "I1118 20:32:27.652476 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06575026,\n",
            " 'Loss/localization_loss': 0.026891157,\n",
            " 'Loss/regularization_loss': 0.6165421,\n",
            " 'Loss/total_loss': 0.7091835,\n",
            " 'learning_rate': 0.030391678}\n",
            "INFO:tensorflow:Step 9600 per-step time 1.083s\n",
            "I1118 20:34:15.976646 136149638571136 model_lib_v2.py:705] Step 9600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05164772,\n",
            " 'Loss/localization_loss': 0.016312417,\n",
            " 'Loss/regularization_loss': 0.61513513,\n",
            " 'Loss/total_loss': 0.6830953,\n",
            " 'learning_rate': 0.030157303}\n",
            "I1118 20:34:15.976907 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05164772,\n",
            " 'Loss/localization_loss': 0.016312417,\n",
            " 'Loss/regularization_loss': 0.61513513,\n",
            " 'Loss/total_loss': 0.6830953,\n",
            " 'learning_rate': 0.030157303}\n",
            "INFO:tensorflow:Step 9700 per-step time 1.083s\n",
            "I1118 20:36:04.302669 136149638571136 model_lib_v2.py:705] Step 9700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051392112,\n",
            " 'Loss/localization_loss': 0.01973872,\n",
            " 'Loss/regularization_loss': 0.6137373,\n",
            " 'Loss/total_loss': 0.68486816,\n",
            " 'learning_rate': 0.029921034}\n",
            "I1118 20:36:04.302965 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.051392112,\n",
            " 'Loss/localization_loss': 0.01973872,\n",
            " 'Loss/regularization_loss': 0.6137373,\n",
            " 'Loss/total_loss': 0.68486816,\n",
            " 'learning_rate': 0.029921034}\n",
            "INFO:tensorflow:Step 9800 per-step time 1.083s\n",
            "I1118 20:37:52.626293 136149638571136 model_lib_v2.py:705] Step 9800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051445562,\n",
            " 'Loss/localization_loss': 0.01853958,\n",
            " 'Loss/regularization_loss': 0.61235493,\n",
            " 'Loss/total_loss': 0.6823401,\n",
            " 'learning_rate': 0.029682912}\n",
            "I1118 20:37:52.626583 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.051445562,\n",
            " 'Loss/localization_loss': 0.01853958,\n",
            " 'Loss/regularization_loss': 0.61235493,\n",
            " 'Loss/total_loss': 0.6823401,\n",
            " 'learning_rate': 0.029682912}\n",
            "INFO:tensorflow:Step 9900 per-step time 1.083s\n",
            "I1118 20:39:40.956036 136149638571136 model_lib_v2.py:705] Step 9900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046429962,\n",
            " 'Loss/localization_loss': 0.013823864,\n",
            " 'Loss/regularization_loss': 0.610988,\n",
            " 'Loss/total_loss': 0.6712419,\n",
            " 'learning_rate': 0.029442988}\n",
            "I1118 20:39:40.956332 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.046429962,\n",
            " 'Loss/localization_loss': 0.013823864,\n",
            " 'Loss/regularization_loss': 0.610988,\n",
            " 'Loss/total_loss': 0.6712419,\n",
            " 'learning_rate': 0.029442988}\n",
            "INFO:tensorflow:Step 10000 per-step time 1.083s\n",
            "I1118 20:41:29.300451 136149638571136 model_lib_v2.py:705] Step 10000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05843095,\n",
            " 'Loss/localization_loss': 0.013704186,\n",
            " 'Loss/regularization_loss': 0.6096277,\n",
            " 'Loss/total_loss': 0.6817629,\n",
            " 'learning_rate': 0.029201299}\n",
            "I1118 20:41:29.300718 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05843095,\n",
            " 'Loss/localization_loss': 0.013704186,\n",
            " 'Loss/regularization_loss': 0.6096277,\n",
            " 'Loss/total_loss': 0.6817629,\n",
            " 'learning_rate': 0.029201299}\n",
            "INFO:tensorflow:Step 10100 per-step time 1.094s\n",
            "I1118 20:43:18.675563 136149638571136 model_lib_v2.py:705] Step 10100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06245486,\n",
            " 'Loss/localization_loss': 0.018695414,\n",
            " 'Loss/regularization_loss': 0.6082865,\n",
            " 'Loss/total_loss': 0.6894368,\n",
            " 'learning_rate': 0.028957896}\n",
            "I1118 20:43:18.675833 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06245486,\n",
            " 'Loss/localization_loss': 0.018695414,\n",
            " 'Loss/regularization_loss': 0.6082865,\n",
            " 'Loss/total_loss': 0.6894368,\n",
            " 'learning_rate': 0.028957896}\n",
            "INFO:tensorflow:Step 10200 per-step time 1.083s\n",
            "I1118 20:45:06.997921 136149638571136 model_lib_v2.py:705] Step 10200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060136646,\n",
            " 'Loss/localization_loss': 0.01412056,\n",
            " 'Loss/regularization_loss': 0.6069567,\n",
            " 'Loss/total_loss': 0.681214,\n",
            " 'learning_rate': 0.028712818}\n",
            "I1118 20:45:06.998186 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.060136646,\n",
            " 'Loss/localization_loss': 0.01412056,\n",
            " 'Loss/regularization_loss': 0.6069567,\n",
            " 'Loss/total_loss': 0.681214,\n",
            " 'learning_rate': 0.028712818}\n",
            "INFO:tensorflow:Step 10300 per-step time 1.083s\n",
            "I1118 20:46:55.324441 136149638571136 model_lib_v2.py:705] Step 10300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059384737,\n",
            " 'Loss/localization_loss': 0.02141141,\n",
            " 'Loss/regularization_loss': 0.6056414,\n",
            " 'Loss/total_loss': 0.6864376,\n",
            " 'learning_rate': 0.028466115}\n",
            "I1118 20:46:55.324708 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.059384737,\n",
            " 'Loss/localization_loss': 0.02141141,\n",
            " 'Loss/regularization_loss': 0.6056414,\n",
            " 'Loss/total_loss': 0.6864376,\n",
            " 'learning_rate': 0.028466115}\n",
            "INFO:tensorflow:Step 10400 per-step time 1.083s\n",
            "I1118 20:48:43.643094 136149638571136 model_lib_v2.py:705] Step 10400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07100804,\n",
            " 'Loss/localization_loss': 0.030761953,\n",
            " 'Loss/regularization_loss': 0.60433584,\n",
            " 'Loss/total_loss': 0.7061058,\n",
            " 'learning_rate': 0.028217835}\n",
            "I1118 20:48:43.643361 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.07100804,\n",
            " 'Loss/localization_loss': 0.030761953,\n",
            " 'Loss/regularization_loss': 0.60433584,\n",
            " 'Loss/total_loss': 0.7061058,\n",
            " 'learning_rate': 0.028217835}\n",
            "INFO:tensorflow:Step 10500 per-step time 1.083s\n",
            "I1118 20:50:31.969480 136149638571136 model_lib_v2.py:705] Step 10500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06253949,\n",
            " 'Loss/localization_loss': 0.027946053,\n",
            " 'Loss/regularization_loss': 0.60305244,\n",
            " 'Loss/total_loss': 0.693538,\n",
            " 'learning_rate': 0.027968023}\n",
            "I1118 20:50:31.969747 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06253949,\n",
            " 'Loss/localization_loss': 0.027946053,\n",
            " 'Loss/regularization_loss': 0.60305244,\n",
            " 'Loss/total_loss': 0.693538,\n",
            " 'learning_rate': 0.027968023}\n",
            "INFO:tensorflow:Step 10600 per-step time 1.083s\n",
            "I1118 20:52:20.306177 136149638571136 model_lib_v2.py:705] Step 10600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.057440456,\n",
            " 'Loss/localization_loss': 0.0136804795,\n",
            " 'Loss/regularization_loss': 0.60177374,\n",
            " 'Loss/total_loss': 0.67289466,\n",
            " 'learning_rate': 0.027716719}\n",
            "I1118 20:52:20.306493 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.057440456,\n",
            " 'Loss/localization_loss': 0.0136804795,\n",
            " 'Loss/regularization_loss': 0.60177374,\n",
            " 'Loss/total_loss': 0.67289466,\n",
            " 'learning_rate': 0.027716719}\n",
            "INFO:tensorflow:Step 10700 per-step time 1.083s\n",
            "I1118 20:54:08.620327 136149638571136 model_lib_v2.py:705] Step 10700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0637957,\n",
            " 'Loss/localization_loss': 0.015446847,\n",
            " 'Loss/regularization_loss': 0.6005131,\n",
            " 'Loss/total_loss': 0.6797556,\n",
            " 'learning_rate': 0.02746398}\n",
            "I1118 20:54:08.620594 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0637957,\n",
            " 'Loss/localization_loss': 0.015446847,\n",
            " 'Loss/regularization_loss': 0.6005131,\n",
            " 'Loss/total_loss': 0.6797556,\n",
            " 'learning_rate': 0.02746398}\n",
            "INFO:tensorflow:Step 10800 per-step time 1.083s\n",
            "I1118 20:55:56.943146 136149638571136 model_lib_v2.py:705] Step 10800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05329346,\n",
            " 'Loss/localization_loss': 0.011706717,\n",
            " 'Loss/regularization_loss': 0.599265,\n",
            " 'Loss/total_loss': 0.66426516,\n",
            " 'learning_rate': 0.027209844}\n",
            "I1118 20:55:56.943453 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05329346,\n",
            " 'Loss/localization_loss': 0.011706717,\n",
            " 'Loss/regularization_loss': 0.599265,\n",
            " 'Loss/total_loss': 0.66426516,\n",
            " 'learning_rate': 0.027209844}\n",
            "INFO:tensorflow:Step 10900 per-step time 1.083s\n",
            "I1118 20:57:45.259697 136149638571136 model_lib_v2.py:705] Step 10900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05087527,\n",
            " 'Loss/localization_loss': 0.015849398,\n",
            " 'Loss/regularization_loss': 0.598033,\n",
            " 'Loss/total_loss': 0.66475767,\n",
            " 'learning_rate': 0.026954366}\n",
            "I1118 20:57:45.259967 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05087527,\n",
            " 'Loss/localization_loss': 0.015849398,\n",
            " 'Loss/regularization_loss': 0.598033,\n",
            " 'Loss/total_loss': 0.66475767,\n",
            " 'learning_rate': 0.026954366}\n",
            "INFO:tensorflow:Step 11000 per-step time 1.083s\n",
            "I1118 20:59:33.590212 136149638571136 model_lib_v2.py:705] Step 11000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047627997,\n",
            " 'Loss/localization_loss': 0.015226782,\n",
            " 'Loss/regularization_loss': 0.59681344,\n",
            " 'Loss/total_loss': 0.6596682,\n",
            " 'learning_rate': 0.026697593}\n",
            "I1118 20:59:33.590487 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047627997,\n",
            " 'Loss/localization_loss': 0.015226782,\n",
            " 'Loss/regularization_loss': 0.59681344,\n",
            " 'Loss/total_loss': 0.6596682,\n",
            " 'learning_rate': 0.026697593}\n",
            "INFO:tensorflow:Step 11100 per-step time 1.093s\n",
            "I1118 21:01:22.939480 136149638571136 model_lib_v2.py:705] Step 11100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05760251,\n",
            " 'Loss/localization_loss': 0.022782745,\n",
            " 'Loss/regularization_loss': 0.5956025,\n",
            " 'Loss/total_loss': 0.6759878,\n",
            " 'learning_rate': 0.026439566}\n",
            "I1118 21:01:22.939765 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05760251,\n",
            " 'Loss/localization_loss': 0.022782745,\n",
            " 'Loss/regularization_loss': 0.5956025,\n",
            " 'Loss/total_loss': 0.6759878,\n",
            " 'learning_rate': 0.026439566}\n",
            "INFO:tensorflow:Step 11200 per-step time 1.083s\n",
            "I1118 21:03:11.269743 136149638571136 model_lib_v2.py:705] Step 11200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045110717,\n",
            " 'Loss/localization_loss': 0.011384686,\n",
            " 'Loss/regularization_loss': 0.59440935,\n",
            " 'Loss/total_loss': 0.6509047,\n",
            " 'learning_rate': 0.026180338}\n",
            "I1118 21:03:11.270011 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.045110717,\n",
            " 'Loss/localization_loss': 0.011384686,\n",
            " 'Loss/regularization_loss': 0.59440935,\n",
            " 'Loss/total_loss': 0.6509047,\n",
            " 'learning_rate': 0.026180338}\n",
            "INFO:tensorflow:Step 11300 per-step time 1.083s\n",
            "I1118 21:04:59.599766 136149638571136 model_lib_v2.py:705] Step 11300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05561543,\n",
            " 'Loss/localization_loss': 0.019618932,\n",
            " 'Loss/regularization_loss': 0.59322625,\n",
            " 'Loss/total_loss': 0.6684606,\n",
            " 'learning_rate': 0.025919959}\n",
            "I1118 21:04:59.600030 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05561543,\n",
            " 'Loss/localization_loss': 0.019618932,\n",
            " 'Loss/regularization_loss': 0.59322625,\n",
            " 'Loss/total_loss': 0.6684606,\n",
            " 'learning_rate': 0.025919959}\n",
            "INFO:tensorflow:Step 11400 per-step time 1.083s\n",
            "I1118 21:06:47.925562 136149638571136 model_lib_v2.py:705] Step 11400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05479917,\n",
            " 'Loss/localization_loss': 0.012516482,\n",
            " 'Loss/regularization_loss': 0.59205943,\n",
            " 'Loss/total_loss': 0.6593751,\n",
            " 'learning_rate': 0.025658473}\n",
            "I1118 21:06:47.925829 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05479917,\n",
            " 'Loss/localization_loss': 0.012516482,\n",
            " 'Loss/regularization_loss': 0.59205943,\n",
            " 'Loss/total_loss': 0.6593751,\n",
            " 'learning_rate': 0.025658473}\n",
            "INFO:tensorflow:Step 11500 per-step time 1.083s\n",
            "I1118 21:08:36.254153 136149638571136 model_lib_v2.py:705] Step 11500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051709663,\n",
            " 'Loss/localization_loss': 0.019810982,\n",
            " 'Loss/regularization_loss': 0.5909093,\n",
            " 'Loss/total_loss': 0.6624299,\n",
            " 'learning_rate': 0.025395937}\n",
            "I1118 21:08:36.254467 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.051709663,\n",
            " 'Loss/localization_loss': 0.019810982,\n",
            " 'Loss/regularization_loss': 0.5909093,\n",
            " 'Loss/total_loss': 0.6624299,\n",
            " 'learning_rate': 0.025395937}\n",
            "INFO:tensorflow:Step 11600 per-step time 1.083s\n",
            "I1118 21:10:24.569901 136149638571136 model_lib_v2.py:705] Step 11600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062402427,\n",
            " 'Loss/localization_loss': 0.032169394,\n",
            " 'Loss/regularization_loss': 0.58976907,\n",
            " 'Loss/total_loss': 0.6843409,\n",
            " 'learning_rate': 0.025132386}\n",
            "I1118 21:10:24.570175 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.062402427,\n",
            " 'Loss/localization_loss': 0.032169394,\n",
            " 'Loss/regularization_loss': 0.58976907,\n",
            " 'Loss/total_loss': 0.6843409,\n",
            " 'learning_rate': 0.025132386}\n",
            "INFO:tensorflow:Step 11700 per-step time 1.083s\n",
            "I1118 21:12:12.909222 136149638571136 model_lib_v2.py:705] Step 11700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052610707,\n",
            " 'Loss/localization_loss': 0.0129448725,\n",
            " 'Loss/regularization_loss': 0.5886467,\n",
            " 'Loss/total_loss': 0.6542023,\n",
            " 'learning_rate': 0.024867883}\n",
            "I1118 21:12:12.909506 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.052610707,\n",
            " 'Loss/localization_loss': 0.0129448725,\n",
            " 'Loss/regularization_loss': 0.5886467,\n",
            " 'Loss/total_loss': 0.6542023,\n",
            " 'learning_rate': 0.024867883}\n",
            "INFO:tensorflow:Step 11800 per-step time 1.083s\n",
            "I1118 21:14:01.248075 136149638571136 model_lib_v2.py:705] Step 11800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045786284,\n",
            " 'Loss/localization_loss': 0.012885479,\n",
            " 'Loss/regularization_loss': 0.5875311,\n",
            " 'Loss/total_loss': 0.6462028,\n",
            " 'learning_rate': 0.024602469}\n",
            "I1118 21:14:01.248344 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.045786284,\n",
            " 'Loss/localization_loss': 0.012885479,\n",
            " 'Loss/regularization_loss': 0.5875311,\n",
            " 'Loss/total_loss': 0.6462028,\n",
            " 'learning_rate': 0.024602469}\n",
            "INFO:tensorflow:Step 11900 per-step time 1.083s\n",
            "I1118 21:15:49.591441 136149638571136 model_lib_v2.py:705] Step 11900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049348377,\n",
            " 'Loss/localization_loss': 0.01641206,\n",
            " 'Loss/regularization_loss': 0.58643055,\n",
            " 'Loss/total_loss': 0.652191,\n",
            " 'learning_rate': 0.024336198}\n",
            "I1118 21:15:49.591740 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.049348377,\n",
            " 'Loss/localization_loss': 0.01641206,\n",
            " 'Loss/regularization_loss': 0.58643055,\n",
            " 'Loss/total_loss': 0.652191,\n",
            " 'learning_rate': 0.024336198}\n",
            "INFO:tensorflow:Step 12000 per-step time 1.084s\n",
            "I1118 21:17:37.941927 136149638571136 model_lib_v2.py:705] Step 12000 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06247603,\n",
            " 'Loss/localization_loss': 0.014330358,\n",
            " 'Loss/regularization_loss': 0.5853449,\n",
            " 'Loss/total_loss': 0.66215134,\n",
            " 'learning_rate': 0.024069117}\n",
            "I1118 21:17:37.942199 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06247603,\n",
            " 'Loss/localization_loss': 0.014330358,\n",
            " 'Loss/regularization_loss': 0.5853449,\n",
            " 'Loss/total_loss': 0.66215134,\n",
            " 'learning_rate': 0.024069117}\n",
            "INFO:tensorflow:Step 12100 per-step time 1.094s\n",
            "I1118 21:19:27.329593 136149638571136 model_lib_v2.py:705] Step 12100 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06061481,\n",
            " 'Loss/localization_loss': 0.012678749,\n",
            " 'Loss/regularization_loss': 0.5842745,\n",
            " 'Loss/total_loss': 0.65756804,\n",
            " 'learning_rate': 0.02380128}\n",
            "I1118 21:19:27.329858 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.06061481,\n",
            " 'Loss/localization_loss': 0.012678749,\n",
            " 'Loss/regularization_loss': 0.5842745,\n",
            " 'Loss/total_loss': 0.65756804,\n",
            " 'learning_rate': 0.02380128}\n",
            "INFO:tensorflow:Step 12200 per-step time 1.083s\n",
            "I1118 21:21:15.630728 136149638571136 model_lib_v2.py:705] Step 12200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049355824,\n",
            " 'Loss/localization_loss': 0.014449687,\n",
            " 'Loss/regularization_loss': 0.58321893,\n",
            " 'Loss/total_loss': 0.64702445,\n",
            " 'learning_rate': 0.023532731}\n",
            "I1118 21:21:15.631003 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.049355824,\n",
            " 'Loss/localization_loss': 0.014449687,\n",
            " 'Loss/regularization_loss': 0.58321893,\n",
            " 'Loss/total_loss': 0.64702445,\n",
            " 'learning_rate': 0.023532731}\n",
            "INFO:tensorflow:Step 12300 per-step time 1.083s\n",
            "I1118 21:23:03.898672 136149638571136 model_lib_v2.py:705] Step 12300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.040147163,\n",
            " 'Loss/localization_loss': 0.009455158,\n",
            " 'Loss/regularization_loss': 0.58217293,\n",
            " 'Loss/total_loss': 0.63177526,\n",
            " 'learning_rate': 0.023263523}\n",
            "I1118 21:23:03.898941 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.040147163,\n",
            " 'Loss/localization_loss': 0.009455158,\n",
            " 'Loss/regularization_loss': 0.58217293,\n",
            " 'Loss/total_loss': 0.63177526,\n",
            " 'learning_rate': 0.023263523}\n",
            "INFO:tensorflow:Step 12400 per-step time 1.083s\n",
            "I1118 21:24:52.156644 136149638571136 model_lib_v2.py:705] Step 12400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04446315,\n",
            " 'Loss/localization_loss': 0.008908852,\n",
            " 'Loss/regularization_loss': 0.58113945,\n",
            " 'Loss/total_loss': 0.6345115,\n",
            " 'learning_rate': 0.022993708}\n",
            "I1118 21:24:52.156912 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04446315,\n",
            " 'Loss/localization_loss': 0.008908852,\n",
            " 'Loss/regularization_loss': 0.58113945,\n",
            " 'Loss/total_loss': 0.6345115,\n",
            " 'learning_rate': 0.022993708}\n",
            "INFO:tensorflow:Step 12500 per-step time 1.082s\n",
            "I1118 21:26:40.388589 136149638571136 model_lib_v2.py:705] Step 12500 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04489989,\n",
            " 'Loss/localization_loss': 0.01361483,\n",
            " 'Loss/regularization_loss': 0.58012193,\n",
            " 'Loss/total_loss': 0.63863665,\n",
            " 'learning_rate': 0.022723334}\n",
            "I1118 21:26:40.388854 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04489989,\n",
            " 'Loss/localization_loss': 0.01361483,\n",
            " 'Loss/regularization_loss': 0.58012193,\n",
            " 'Loss/total_loss': 0.63863665,\n",
            " 'learning_rate': 0.022723334}\n",
            "INFO:tensorflow:Step 12600 per-step time 1.082s\n",
            "I1118 21:28:28.624435 136149638571136 model_lib_v2.py:705] Step 12600 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044524338,\n",
            " 'Loss/localization_loss': 0.009174429,\n",
            " 'Loss/regularization_loss': 0.5791146,\n",
            " 'Loss/total_loss': 0.63281333,\n",
            " 'learning_rate': 0.02245245}\n",
            "I1118 21:28:28.624703 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.044524338,\n",
            " 'Loss/localization_loss': 0.009174429,\n",
            " 'Loss/regularization_loss': 0.5791146,\n",
            " 'Loss/total_loss': 0.63281333,\n",
            " 'learning_rate': 0.02245245}\n",
            "INFO:tensorflow:Step 12700 per-step time 1.082s\n",
            "I1118 21:30:16.869010 136149638571136 model_lib_v2.py:705] Step 12700 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047670953,\n",
            " 'Loss/localization_loss': 0.015195603,\n",
            " 'Loss/regularization_loss': 0.5781222,\n",
            " 'Loss/total_loss': 0.64098877,\n",
            " 'learning_rate': 0.022181105}\n",
            "I1118 21:30:16.869291 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047670953,\n",
            " 'Loss/localization_loss': 0.015195603,\n",
            " 'Loss/regularization_loss': 0.5781222,\n",
            " 'Loss/total_loss': 0.64098877,\n",
            " 'learning_rate': 0.022181105}\n",
            "INFO:tensorflow:Step 12800 per-step time 1.082s\n",
            "I1118 21:32:05.108975 136149638571136 model_lib_v2.py:705] Step 12800 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048088934,\n",
            " 'Loss/localization_loss': 0.010854552,\n",
            " 'Loss/regularization_loss': 0.5771429,\n",
            " 'Loss/total_loss': 0.63608634,\n",
            " 'learning_rate': 0.021909358}\n",
            "I1118 21:32:05.109264 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.048088934,\n",
            " 'Loss/localization_loss': 0.010854552,\n",
            " 'Loss/regularization_loss': 0.5771429,\n",
            " 'Loss/total_loss': 0.63608634,\n",
            " 'learning_rate': 0.021909358}\n",
            "INFO:tensorflow:Step 12900 per-step time 1.082s\n",
            "I1118 21:33:53.350051 136149638571136 model_lib_v2.py:705] Step 12900 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05055439,\n",
            " 'Loss/localization_loss': 0.010642205,\n",
            " 'Loss/regularization_loss': 0.57617456,\n",
            " 'Loss/total_loss': 0.6373712,\n",
            " 'learning_rate': 0.021637257}\n",
            "I1118 21:33:53.350316 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.05055439,\n",
            " 'Loss/localization_loss': 0.010642205,\n",
            " 'Loss/regularization_loss': 0.57617456,\n",
            " 'Loss/total_loss': 0.6373712,\n",
            " 'learning_rate': 0.021637257}\n",
            "INFO:tensorflow:Step 13000 per-step time 1.083s\n",
            "I1118 21:35:41.611373 136149638571136 model_lib_v2.py:705] Step 13000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041272007,\n",
            " 'Loss/localization_loss': 0.011035004,\n",
            " 'Loss/regularization_loss': 0.57522094,\n",
            " 'Loss/total_loss': 0.62752795,\n",
            " 'learning_rate': 0.021364845}\n",
            "I1118 21:35:41.611651 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.041272007,\n",
            " 'Loss/localization_loss': 0.011035004,\n",
            " 'Loss/regularization_loss': 0.57522094,\n",
            " 'Loss/total_loss': 0.62752795,\n",
            " 'learning_rate': 0.021364845}\n",
            "INFO:tensorflow:Step 13100 per-step time 1.093s\n",
            "I1118 21:37:30.893554 136149638571136 model_lib_v2.py:705] Step 13100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04631097,\n",
            " 'Loss/localization_loss': 0.00963166,\n",
            " 'Loss/regularization_loss': 0.57427907,\n",
            " 'Loss/total_loss': 0.63022166,\n",
            " 'learning_rate': 0.021092184}\n",
            "I1118 21:37:30.893828 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04631097,\n",
            " 'Loss/localization_loss': 0.00963166,\n",
            " 'Loss/regularization_loss': 0.57427907,\n",
            " 'Loss/total_loss': 0.63022166,\n",
            " 'learning_rate': 0.021092184}\n",
            "INFO:tensorflow:Step 13200 per-step time 1.083s\n",
            "I1118 21:39:19.149444 136149638571136 model_lib_v2.py:705] Step 13200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04501775,\n",
            " 'Loss/localization_loss': 0.02064006,\n",
            " 'Loss/regularization_loss': 0.5733515,\n",
            " 'Loss/total_loss': 0.6390093,\n",
            " 'learning_rate': 0.020819314}\n",
            "I1118 21:39:19.149703 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04501775,\n",
            " 'Loss/localization_loss': 0.02064006,\n",
            " 'Loss/regularization_loss': 0.5733515,\n",
            " 'Loss/total_loss': 0.6390093,\n",
            " 'learning_rate': 0.020819314}\n",
            "INFO:tensorflow:Step 13300 per-step time 1.082s\n",
            "I1118 21:41:07.399361 136149638571136 model_lib_v2.py:705] Step 13300 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.042039093,\n",
            " 'Loss/localization_loss': 0.011524455,\n",
            " 'Loss/regularization_loss': 0.57243806,\n",
            " 'Loss/total_loss': 0.6260016,\n",
            " 'learning_rate': 0.020546295}\n",
            "I1118 21:41:07.399654 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.042039093,\n",
            " 'Loss/localization_loss': 0.011524455,\n",
            " 'Loss/regularization_loss': 0.57243806,\n",
            " 'Loss/total_loss': 0.6260016,\n",
            " 'learning_rate': 0.020546295}\n",
            "INFO:tensorflow:Step 13400 per-step time 1.082s\n",
            "I1118 21:42:55.643857 136149638571136 model_lib_v2.py:705] Step 13400 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052208323,\n",
            " 'Loss/localization_loss': 0.012032129,\n",
            " 'Loss/regularization_loss': 0.57153827,\n",
            " 'Loss/total_loss': 0.6357787,\n",
            " 'learning_rate': 0.020273173}\n",
            "I1118 21:42:55.644123 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.052208323,\n",
            " 'Loss/localization_loss': 0.012032129,\n",
            " 'Loss/regularization_loss': 0.57153827,\n",
            " 'Loss/total_loss': 0.6357787,\n",
            " 'learning_rate': 0.020273173}\n",
            "INFO:tensorflow:Step 13500 per-step time 1.082s\n",
            "I1118 21:44:43.879158 136149638571136 model_lib_v2.py:705] Step 13500 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04509209,\n",
            " 'Loss/localization_loss': 0.022581518,\n",
            " 'Loss/regularization_loss': 0.57065004,\n",
            " 'Loss/total_loss': 0.63832366,\n",
            " 'learning_rate': 0.019999998}\n",
            "I1118 21:44:43.879449 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04509209,\n",
            " 'Loss/localization_loss': 0.022581518,\n",
            " 'Loss/regularization_loss': 0.57065004,\n",
            " 'Loss/total_loss': 0.63832366,\n",
            " 'learning_rate': 0.019999998}\n",
            "INFO:tensorflow:Step 13600 per-step time 1.082s\n",
            "I1118 21:46:32.108715 136149638571136 model_lib_v2.py:705] Step 13600 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04868838,\n",
            " 'Loss/localization_loss': 0.017612288,\n",
            " 'Loss/regularization_loss': 0.56977624,\n",
            " 'Loss/total_loss': 0.63607687,\n",
            " 'learning_rate': 0.019726824}\n",
            "I1118 21:46:32.108990 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04868838,\n",
            " 'Loss/localization_loss': 0.017612288,\n",
            " 'Loss/regularization_loss': 0.56977624,\n",
            " 'Loss/total_loss': 0.63607687,\n",
            " 'learning_rate': 0.019726824}\n",
            "INFO:tensorflow:Step 13700 per-step time 1.083s\n",
            "I1118 21:48:20.360256 136149638571136 model_lib_v2.py:705] Step 13700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044774175,\n",
            " 'Loss/localization_loss': 0.011977016,\n",
            " 'Loss/regularization_loss': 0.5689151,\n",
            " 'Loss/total_loss': 0.6256663,\n",
            " 'learning_rate': 0.0194537}\n",
            "I1118 21:48:20.360542 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.044774175,\n",
            " 'Loss/localization_loss': 0.011977016,\n",
            " 'Loss/regularization_loss': 0.5689151,\n",
            " 'Loss/total_loss': 0.6256663,\n",
            " 'learning_rate': 0.0194537}\n",
            "INFO:tensorflow:Step 13800 per-step time 1.082s\n",
            "I1118 21:50:08.604364 136149638571136 model_lib_v2.py:705] Step 13800 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04114797,\n",
            " 'Loss/localization_loss': 0.011773213,\n",
            " 'Loss/regularization_loss': 0.5680644,\n",
            " 'Loss/total_loss': 0.62098557,\n",
            " 'learning_rate': 0.019180683}\n",
            "I1118 21:50:08.604648 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04114797,\n",
            " 'Loss/localization_loss': 0.011773213,\n",
            " 'Loss/regularization_loss': 0.5680644,\n",
            " 'Loss/total_loss': 0.62098557,\n",
            " 'learning_rate': 0.019180683}\n",
            "INFO:tensorflow:Step 13900 per-step time 1.083s\n",
            "I1118 21:51:56.858141 136149638571136 model_lib_v2.py:705] Step 13900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055125497,\n",
            " 'Loss/localization_loss': 0.013588785,\n",
            " 'Loss/regularization_loss': 0.5672283,\n",
            " 'Loss/total_loss': 0.6359426,\n",
            " 'learning_rate': 0.018907815}\n",
            "I1118 21:51:56.858417 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.055125497,\n",
            " 'Loss/localization_loss': 0.013588785,\n",
            " 'Loss/regularization_loss': 0.5672283,\n",
            " 'Loss/total_loss': 0.6359426,\n",
            " 'learning_rate': 0.018907815}\n",
            "INFO:tensorflow:Step 14000 per-step time 1.083s\n",
            "I1118 21:53:45.123734 136149638571136 model_lib_v2.py:705] Step 14000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04171746,\n",
            " 'Loss/localization_loss': 0.0138190845,\n",
            " 'Loss/regularization_loss': 0.56640583,\n",
            " 'Loss/total_loss': 0.6219424,\n",
            " 'learning_rate': 0.01863515}\n",
            "I1118 21:53:45.123997 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04171746,\n",
            " 'Loss/localization_loss': 0.0138190845,\n",
            " 'Loss/regularization_loss': 0.56640583,\n",
            " 'Loss/total_loss': 0.6219424,\n",
            " 'learning_rate': 0.01863515}\n",
            "INFO:tensorflow:Step 14100 per-step time 1.093s\n",
            "I1118 21:55:34.453952 136149638571136 model_lib_v2.py:705] Step 14100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.067469366,\n",
            " 'Loss/localization_loss': 0.020292332,\n",
            " 'Loss/regularization_loss': 0.5655962,\n",
            " 'Loss/total_loss': 0.6533579,\n",
            " 'learning_rate': 0.018362742}\n",
            "I1118 21:55:34.454253 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.067469366,\n",
            " 'Loss/localization_loss': 0.020292332,\n",
            " 'Loss/regularization_loss': 0.5655962,\n",
            " 'Loss/total_loss': 0.6533579,\n",
            " 'learning_rate': 0.018362742}\n",
            "INFO:tensorflow:Step 14200 per-step time 1.083s\n",
            "I1118 21:57:22.783681 136149638571136 model_lib_v2.py:705] Step 14200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043741744,\n",
            " 'Loss/localization_loss': 0.009864752,\n",
            " 'Loss/regularization_loss': 0.5648011,\n",
            " 'Loss/total_loss': 0.6184076,\n",
            " 'learning_rate': 0.01809064}\n",
            "I1118 21:57:22.783959 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.043741744,\n",
            " 'Loss/localization_loss': 0.009864752,\n",
            " 'Loss/regularization_loss': 0.5648011,\n",
            " 'Loss/total_loss': 0.6184076,\n",
            " 'learning_rate': 0.01809064}\n",
            "INFO:tensorflow:Step 14300 per-step time 1.083s\n",
            "I1118 21:59:11.125947 136149638571136 model_lib_v2.py:705] Step 14300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059433717,\n",
            " 'Loss/localization_loss': 0.011914854,\n",
            " 'Loss/regularization_loss': 0.56401646,\n",
            " 'Loss/total_loss': 0.635365,\n",
            " 'learning_rate': 0.017818892}\n",
            "I1118 21:59:11.126320 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.059433717,\n",
            " 'Loss/localization_loss': 0.011914854,\n",
            " 'Loss/regularization_loss': 0.56401646,\n",
            " 'Loss/total_loss': 0.635365,\n",
            " 'learning_rate': 0.017818892}\n",
            "INFO:tensorflow:Step 14400 per-step time 1.083s\n",
            "I1118 22:00:59.453464 136149638571136 model_lib_v2.py:705] Step 14400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055926435,\n",
            " 'Loss/localization_loss': 0.0144108515,\n",
            " 'Loss/regularization_loss': 0.56324613,\n",
            " 'Loss/total_loss': 0.6335834,\n",
            " 'learning_rate': 0.01754755}\n",
            "I1118 22:00:59.453765 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.055926435,\n",
            " 'Loss/localization_loss': 0.0144108515,\n",
            " 'Loss/regularization_loss': 0.56324613,\n",
            " 'Loss/total_loss': 0.6335834,\n",
            " 'learning_rate': 0.01754755}\n",
            "INFO:tensorflow:Step 14500 per-step time 1.083s\n",
            "I1118 22:02:47.789422 136149638571136 model_lib_v2.py:705] Step 14500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0425603,\n",
            " 'Loss/localization_loss': 0.007999059,\n",
            " 'Loss/regularization_loss': 0.5624863,\n",
            " 'Loss/total_loss': 0.61304563,\n",
            " 'learning_rate': 0.017276663}\n",
            "I1118 22:02:47.789693 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0425603,\n",
            " 'Loss/localization_loss': 0.007999059,\n",
            " 'Loss/regularization_loss': 0.5624863,\n",
            " 'Loss/total_loss': 0.61304563,\n",
            " 'learning_rate': 0.017276663}\n",
            "INFO:tensorflow:Step 14600 per-step time 1.083s\n",
            "I1118 22:04:36.121254 136149638571136 model_lib_v2.py:705] Step 14600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047070157,\n",
            " 'Loss/localization_loss': 0.009747407,\n",
            " 'Loss/regularization_loss': 0.5617404,\n",
            " 'Loss/total_loss': 0.61855793,\n",
            " 'learning_rate': 0.01700629}\n",
            "I1118 22:04:36.121546 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047070157,\n",
            " 'Loss/localization_loss': 0.009747407,\n",
            " 'Loss/regularization_loss': 0.5617404,\n",
            " 'Loss/total_loss': 0.61855793,\n",
            " 'learning_rate': 0.01700629}\n",
            "INFO:tensorflow:Step 14700 per-step time 1.083s\n",
            "I1118 22:06:24.463506 136149638571136 model_lib_v2.py:705] Step 14700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0401651,\n",
            " 'Loss/localization_loss': 0.005727223,\n",
            " 'Loss/regularization_loss': 0.56100667,\n",
            " 'Loss/total_loss': 0.606899,\n",
            " 'learning_rate': 0.016736476}\n",
            "I1118 22:06:24.463778 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0401651,\n",
            " 'Loss/localization_loss': 0.005727223,\n",
            " 'Loss/regularization_loss': 0.56100667,\n",
            " 'Loss/total_loss': 0.606899,\n",
            " 'learning_rate': 0.016736476}\n",
            "INFO:tensorflow:Step 14800 per-step time 1.083s\n",
            "I1118 22:08:12.779903 136149638571136 model_lib_v2.py:705] Step 14800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034520473,\n",
            " 'Loss/localization_loss': 0.006572398,\n",
            " 'Loss/regularization_loss': 0.56028336,\n",
            " 'Loss/total_loss': 0.60137624,\n",
            " 'learning_rate': 0.016467266}\n",
            "I1118 22:08:12.780175 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.034520473,\n",
            " 'Loss/localization_loss': 0.006572398,\n",
            " 'Loss/regularization_loss': 0.56028336,\n",
            " 'Loss/total_loss': 0.60137624,\n",
            " 'learning_rate': 0.016467266}\n",
            "INFO:tensorflow:Step 14900 per-step time 1.083s\n",
            "I1118 22:10:01.112165 136149638571136 model_lib_v2.py:705] Step 14900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04687346,\n",
            " 'Loss/localization_loss': 0.013096122,\n",
            " 'Loss/regularization_loss': 0.55957186,\n",
            " 'Loss/total_loss': 0.6195414,\n",
            " 'learning_rate': 0.016198717}\n",
            "I1118 22:10:01.112446 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04687346,\n",
            " 'Loss/localization_loss': 0.013096122,\n",
            " 'Loss/regularization_loss': 0.55957186,\n",
            " 'Loss/total_loss': 0.6195414,\n",
            " 'learning_rate': 0.016198717}\n",
            "INFO:tensorflow:Step 15000 per-step time 1.083s\n",
            "I1118 22:11:49.388630 136149638571136 model_lib_v2.py:705] Step 15000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055935048,\n",
            " 'Loss/localization_loss': 0.009954084,\n",
            " 'Loss/regularization_loss': 0.5588737,\n",
            " 'Loss/total_loss': 0.62476283,\n",
            " 'learning_rate': 0.015930876}\n",
            "I1118 22:11:49.388904 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.055935048,\n",
            " 'Loss/localization_loss': 0.009954084,\n",
            " 'Loss/regularization_loss': 0.5588737,\n",
            " 'Loss/total_loss': 0.62476283,\n",
            " 'learning_rate': 0.015930876}\n",
            "INFO:tensorflow:Step 15100 per-step time 1.093s\n",
            "I1118 22:13:38.656522 136149638571136 model_lib_v2.py:705] Step 15100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047232587,\n",
            " 'Loss/localization_loss': 0.011477915,\n",
            " 'Loss/regularization_loss': 0.5581867,\n",
            " 'Loss/total_loss': 0.61689717,\n",
            " 'learning_rate': 0.015663799}\n",
            "I1118 22:13:38.656808 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047232587,\n",
            " 'Loss/localization_loss': 0.011477915,\n",
            " 'Loss/regularization_loss': 0.5581867,\n",
            " 'Loss/total_loss': 0.61689717,\n",
            " 'learning_rate': 0.015663799}\n",
            "INFO:tensorflow:Step 15200 per-step time 1.083s\n",
            "I1118 22:15:26.926137 136149638571136 model_lib_v2.py:705] Step 15200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.038304858,\n",
            " 'Loss/localization_loss': 0.010681678,\n",
            " 'Loss/regularization_loss': 0.55751234,\n",
            " 'Loss/total_loss': 0.6064989,\n",
            " 'learning_rate': 0.015397527}\n",
            "I1118 22:15:26.926450 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.038304858,\n",
            " 'Loss/localization_loss': 0.010681678,\n",
            " 'Loss/regularization_loss': 0.55751234,\n",
            " 'Loss/total_loss': 0.6064989,\n",
            " 'learning_rate': 0.015397527}\n",
            "INFO:tensorflow:Step 15300 per-step time 1.083s\n",
            "I1118 22:17:15.186244 136149638571136 model_lib_v2.py:705] Step 15300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032659546,\n",
            " 'Loss/localization_loss': 0.008575222,\n",
            " 'Loss/regularization_loss': 0.55684954,\n",
            " 'Loss/total_loss': 0.5980843,\n",
            " 'learning_rate': 0.015132114}\n",
            "I1118 22:17:15.186525 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.032659546,\n",
            " 'Loss/localization_loss': 0.008575222,\n",
            " 'Loss/regularization_loss': 0.55684954,\n",
            " 'Loss/total_loss': 0.5980843,\n",
            " 'learning_rate': 0.015132114}\n",
            "INFO:tensorflow:Step 15400 per-step time 1.082s\n",
            "I1118 22:19:03.431312 136149638571136 model_lib_v2.py:705] Step 15400 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046663135,\n",
            " 'Loss/localization_loss': 0.0082462905,\n",
            " 'Loss/regularization_loss': 0.5562011,\n",
            " 'Loss/total_loss': 0.61111057,\n",
            " 'learning_rate': 0.014867609}\n",
            "I1118 22:19:03.431595 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.046663135,\n",
            " 'Loss/localization_loss': 0.0082462905,\n",
            " 'Loss/regularization_loss': 0.5562011,\n",
            " 'Loss/total_loss': 0.61111057,\n",
            " 'learning_rate': 0.014867609}\n",
            "INFO:tensorflow:Step 15500 per-step time 1.082s\n",
            "I1118 22:20:51.674720 136149638571136 model_lib_v2.py:705] Step 15500 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046508104,\n",
            " 'Loss/localization_loss': 0.013685194,\n",
            " 'Loss/regularization_loss': 0.5555632,\n",
            " 'Loss/total_loss': 0.61575645,\n",
            " 'learning_rate': 0.014604063}\n",
            "I1118 22:20:51.675023 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.046508104,\n",
            " 'Loss/localization_loss': 0.013685194,\n",
            " 'Loss/regularization_loss': 0.5555632,\n",
            " 'Loss/total_loss': 0.61575645,\n",
            " 'learning_rate': 0.014604063}\n",
            "INFO:tensorflow:Step 15600 per-step time 1.082s\n",
            "I1118 22:22:39.921870 136149638571136 model_lib_v2.py:705] Step 15600 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03705497,\n",
            " 'Loss/localization_loss': 0.0063405964,\n",
            " 'Loss/regularization_loss': 0.5549373,\n",
            " 'Loss/total_loss': 0.5983329,\n",
            " 'learning_rate': 0.014341523}\n",
            "I1118 22:22:39.922152 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03705497,\n",
            " 'Loss/localization_loss': 0.0063405964,\n",
            " 'Loss/regularization_loss': 0.5549373,\n",
            " 'Loss/total_loss': 0.5983329,\n",
            " 'learning_rate': 0.014341523}\n",
            "INFO:tensorflow:Step 15700 per-step time 1.083s\n",
            "I1118 22:24:28.250077 136149638571136 model_lib_v2.py:705] Step 15700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041336697,\n",
            " 'Loss/localization_loss': 0.01030472,\n",
            " 'Loss/regularization_loss': 0.55432355,\n",
            " 'Loss/total_loss': 0.605965,\n",
            " 'learning_rate': 0.01408004}\n",
            "I1118 22:24:28.250344 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.041336697,\n",
            " 'Loss/localization_loss': 0.01030472,\n",
            " 'Loss/regularization_loss': 0.55432355,\n",
            " 'Loss/total_loss': 0.605965,\n",
            " 'learning_rate': 0.01408004}\n",
            "INFO:tensorflow:Step 15800 per-step time 1.082s\n",
            "I1118 22:26:16.481837 136149638571136 model_lib_v2.py:705] Step 15800 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04555086,\n",
            " 'Loss/localization_loss': 0.008301968,\n",
            " 'Loss/regularization_loss': 0.5537205,\n",
            " 'Loss/total_loss': 0.60757333,\n",
            " 'learning_rate': 0.013819658}\n",
            "I1118 22:26:16.482096 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04555086,\n",
            " 'Loss/localization_loss': 0.008301968,\n",
            " 'Loss/regularization_loss': 0.5537205,\n",
            " 'Loss/total_loss': 0.60757333,\n",
            " 'learning_rate': 0.013819658}\n",
            "INFO:tensorflow:Step 15900 per-step time 1.083s\n",
            "I1118 22:28:04.741572 136149638571136 model_lib_v2.py:705] Step 15900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037656102,\n",
            " 'Loss/localization_loss': 0.007081765,\n",
            " 'Loss/regularization_loss': 0.5531291,\n",
            " 'Loss/total_loss': 0.59786695,\n",
            " 'learning_rate': 0.013560432}\n",
            "I1118 22:28:04.741847 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.037656102,\n",
            " 'Loss/localization_loss': 0.007081765,\n",
            " 'Loss/regularization_loss': 0.5531291,\n",
            " 'Loss/total_loss': 0.59786695,\n",
            " 'learning_rate': 0.013560432}\n",
            "INFO:tensorflow:Step 16000 per-step time 1.083s\n",
            "I1118 22:29:53.004629 136149638571136 model_lib_v2.py:705] Step 16000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04164419,\n",
            " 'Loss/localization_loss': 0.010406852,\n",
            " 'Loss/regularization_loss': 0.5525495,\n",
            " 'Loss/total_loss': 0.60460055,\n",
            " 'learning_rate': 0.013302408}\n",
            "I1118 22:29:53.004897 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04164419,\n",
            " 'Loss/localization_loss': 0.010406852,\n",
            " 'Loss/regularization_loss': 0.5525495,\n",
            " 'Loss/total_loss': 0.60460055,\n",
            " 'learning_rate': 0.013302408}\n",
            "INFO:tensorflow:Step 16100 per-step time 1.093s\n",
            "I1118 22:31:42.292288 136149638571136 model_lib_v2.py:705] Step 16100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053993016,\n",
            " 'Loss/localization_loss': 0.013561824,\n",
            " 'Loss/regularization_loss': 0.55198026,\n",
            " 'Loss/total_loss': 0.6195351,\n",
            " 'learning_rate': 0.013045632}\n",
            "I1118 22:31:42.292578 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.053993016,\n",
            " 'Loss/localization_loss': 0.013561824,\n",
            " 'Loss/regularization_loss': 0.55198026,\n",
            " 'Loss/total_loss': 0.6195351,\n",
            " 'learning_rate': 0.013045632}\n",
            "INFO:tensorflow:Step 16200 per-step time 1.082s\n",
            "I1118 22:33:30.541790 136149638571136 model_lib_v2.py:705] Step 16200 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047831763,\n",
            " 'Loss/localization_loss': 0.008636707,\n",
            " 'Loss/regularization_loss': 0.5514228,\n",
            " 'Loss/total_loss': 0.60789126,\n",
            " 'learning_rate': 0.012790153}\n",
            "I1118 22:33:30.542163 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047831763,\n",
            " 'Loss/localization_loss': 0.008636707,\n",
            " 'Loss/regularization_loss': 0.5514228,\n",
            " 'Loss/total_loss': 0.60789126,\n",
            " 'learning_rate': 0.012790153}\n",
            "INFO:tensorflow:Step 16300 per-step time 1.083s\n",
            "I1118 22:35:18.798337 136149638571136 model_lib_v2.py:705] Step 16300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.042106055,\n",
            " 'Loss/localization_loss': 0.010732183,\n",
            " 'Loss/regularization_loss': 0.55087656,\n",
            " 'Loss/total_loss': 0.60371476,\n",
            " 'learning_rate': 0.012536017}\n",
            "I1118 22:35:18.798635 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.042106055,\n",
            " 'Loss/localization_loss': 0.010732183,\n",
            " 'Loss/regularization_loss': 0.55087656,\n",
            " 'Loss/total_loss': 0.60371476,\n",
            " 'learning_rate': 0.012536017}\n",
            "INFO:tensorflow:Step 16400 per-step time 1.083s\n",
            "I1118 22:37:07.065115 136149638571136 model_lib_v2.py:705] Step 16400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03222689,\n",
            " 'Loss/localization_loss': 0.0054610968,\n",
            " 'Loss/regularization_loss': 0.5503421,\n",
            " 'Loss/total_loss': 0.5880301,\n",
            " 'learning_rate': 0.01228328}\n",
            "I1118 22:37:07.065397 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03222689,\n",
            " 'Loss/localization_loss': 0.0054610968,\n",
            " 'Loss/regularization_loss': 0.5503421,\n",
            " 'Loss/total_loss': 0.5880301,\n",
            " 'learning_rate': 0.01228328}\n",
            "INFO:tensorflow:Step 16500 per-step time 1.082s\n",
            "I1118 22:38:55.309674 136149638571136 model_lib_v2.py:705] Step 16500 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039055753,\n",
            " 'Loss/localization_loss': 0.012506243,\n",
            " 'Loss/regularization_loss': 0.54981875,\n",
            " 'Loss/total_loss': 0.60138077,\n",
            " 'learning_rate': 0.012031979}\n",
            "I1118 22:38:55.309951 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.039055753,\n",
            " 'Loss/localization_loss': 0.012506243,\n",
            " 'Loss/regularization_loss': 0.54981875,\n",
            " 'Loss/total_loss': 0.60138077,\n",
            " 'learning_rate': 0.012031979}\n",
            "INFO:tensorflow:Step 16600 per-step time 1.082s\n",
            "I1118 22:40:43.552333 136149638571136 model_lib_v2.py:705] Step 16600 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039794818,\n",
            " 'Loss/localization_loss': 0.009238223,\n",
            " 'Loss/regularization_loss': 0.54930615,\n",
            " 'Loss/total_loss': 0.5983392,\n",
            " 'learning_rate': 0.011782162}\n",
            "I1118 22:40:43.552608 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.039794818,\n",
            " 'Loss/localization_loss': 0.009238223,\n",
            " 'Loss/regularization_loss': 0.54930615,\n",
            " 'Loss/total_loss': 0.5983392,\n",
            " 'learning_rate': 0.011782162}\n",
            "INFO:tensorflow:Step 16700 per-step time 1.082s\n",
            "I1118 22:42:31.799380 136149638571136 model_lib_v2.py:705] Step 16700 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047381043,\n",
            " 'Loss/localization_loss': 0.008521901,\n",
            " 'Loss/regularization_loss': 0.54880434,\n",
            " 'Loss/total_loss': 0.6047073,\n",
            " 'learning_rate': 0.01153388}\n",
            "I1118 22:42:31.799658 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047381043,\n",
            " 'Loss/localization_loss': 0.008521901,\n",
            " 'Loss/regularization_loss': 0.54880434,\n",
            " 'Loss/total_loss': 0.6047073,\n",
            " 'learning_rate': 0.01153388}\n",
            "INFO:tensorflow:Step 16800 per-step time 1.083s\n",
            "I1118 22:44:20.070047 136149638571136 model_lib_v2.py:705] Step 16800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0529992,\n",
            " 'Loss/localization_loss': 0.011911885,\n",
            " 'Loss/regularization_loss': 0.548314,\n",
            " 'Loss/total_loss': 0.61322504,\n",
            " 'learning_rate': 0.01128718}\n",
            "I1118 22:44:20.070309 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0529992,\n",
            " 'Loss/localization_loss': 0.011911885,\n",
            " 'Loss/regularization_loss': 0.548314,\n",
            " 'Loss/total_loss': 0.61322504,\n",
            " 'learning_rate': 0.01128718}\n",
            "INFO:tensorflow:Step 16900 per-step time 1.083s\n",
            "I1118 22:46:08.326030 136149638571136 model_lib_v2.py:705] Step 16900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036616877,\n",
            " 'Loss/localization_loss': 0.0062828823,\n",
            " 'Loss/regularization_loss': 0.54783374,\n",
            " 'Loss/total_loss': 0.59073347,\n",
            " 'learning_rate': 0.011042106}\n",
            "I1118 22:46:08.326319 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.036616877,\n",
            " 'Loss/localization_loss': 0.0062828823,\n",
            " 'Loss/regularization_loss': 0.54783374,\n",
            " 'Loss/total_loss': 0.59073347,\n",
            " 'learning_rate': 0.011042106}\n",
            "INFO:tensorflow:Step 17000 per-step time 1.082s\n",
            "I1118 22:47:56.574628 136149638571136 model_lib_v2.py:705] Step 17000 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03944362,\n",
            " 'Loss/localization_loss': 0.010068342,\n",
            " 'Loss/regularization_loss': 0.54736394,\n",
            " 'Loss/total_loss': 0.5968759,\n",
            " 'learning_rate': 0.010798697}\n",
            "I1118 22:47:56.574889 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03944362,\n",
            " 'Loss/localization_loss': 0.010068342,\n",
            " 'Loss/regularization_loss': 0.54736394,\n",
            " 'Loss/total_loss': 0.5968759,\n",
            " 'learning_rate': 0.010798697}\n",
            "INFO:tensorflow:Step 17100 per-step time 1.093s\n",
            "I1118 22:49:45.842580 136149638571136 model_lib_v2.py:705] Step 17100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.037569858,\n",
            " 'Loss/localization_loss': 0.008763905,\n",
            " 'Loss/regularization_loss': 0.546905,\n",
            " 'Loss/total_loss': 0.5932388,\n",
            " 'learning_rate': 0.010557013}\n",
            "I1118 22:49:45.842864 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.037569858,\n",
            " 'Loss/localization_loss': 0.008763905,\n",
            " 'Loss/regularization_loss': 0.546905,\n",
            " 'Loss/total_loss': 0.5932388,\n",
            " 'learning_rate': 0.010557013}\n",
            "INFO:tensorflow:Step 17200 per-step time 1.082s\n",
            "I1118 22:51:34.089356 136149638571136 model_lib_v2.py:705] Step 17200 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032392655,\n",
            " 'Loss/localization_loss': 0.0041769682,\n",
            " 'Loss/regularization_loss': 0.5464579,\n",
            " 'Loss/total_loss': 0.58302754,\n",
            " 'learning_rate': 0.0103170825}\n",
            "I1118 22:51:34.089650 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.032392655,\n",
            " 'Loss/localization_loss': 0.0041769682,\n",
            " 'Loss/regularization_loss': 0.5464579,\n",
            " 'Loss/total_loss': 0.58302754,\n",
            " 'learning_rate': 0.0103170825}\n",
            "INFO:tensorflow:Step 17300 per-step time 1.082s\n",
            "I1118 22:53:22.327642 136149638571136 model_lib_v2.py:705] Step 17300 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039351515,\n",
            " 'Loss/localization_loss': 0.0061572976,\n",
            " 'Loss/regularization_loss': 0.54602003,\n",
            " 'Loss/total_loss': 0.59152883,\n",
            " 'learning_rate': 0.010078964}\n",
            "I1118 22:53:22.327908 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.039351515,\n",
            " 'Loss/localization_loss': 0.0061572976,\n",
            " 'Loss/regularization_loss': 0.54602003,\n",
            " 'Loss/total_loss': 0.59152883,\n",
            " 'learning_rate': 0.010078964}\n",
            "INFO:tensorflow:Step 17400 per-step time 1.082s\n",
            "I1118 22:55:10.575576 136149638571136 model_lib_v2.py:705] Step 17400 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047463425,\n",
            " 'Loss/localization_loss': 0.009663896,\n",
            " 'Loss/regularization_loss': 0.5455925,\n",
            " 'Loss/total_loss': 0.6027198,\n",
            " 'learning_rate': 0.009842696}\n",
            "I1118 22:55:10.575844 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.047463425,\n",
            " 'Loss/localization_loss': 0.009663896,\n",
            " 'Loss/regularization_loss': 0.5455925,\n",
            " 'Loss/total_loss': 0.6027198,\n",
            " 'learning_rate': 0.009842696}\n",
            "INFO:tensorflow:Step 17500 per-step time 1.082s\n",
            "I1118 22:56:58.821087 136149638571136 model_lib_v2.py:705] Step 17500 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036787134,\n",
            " 'Loss/localization_loss': 0.0051808,\n",
            " 'Loss/regularization_loss': 0.54517496,\n",
            " 'Loss/total_loss': 0.5871429,\n",
            " 'learning_rate': 0.00960832}\n",
            "I1118 22:56:58.821362 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.036787134,\n",
            " 'Loss/localization_loss': 0.0051808,\n",
            " 'Loss/regularization_loss': 0.54517496,\n",
            " 'Loss/total_loss': 0.5871429,\n",
            " 'learning_rate': 0.00960832}\n",
            "INFO:tensorflow:Step 17600 per-step time 1.083s\n",
            "I1118 22:58:47.080378 136149638571136 model_lib_v2.py:705] Step 17600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032925963,\n",
            " 'Loss/localization_loss': 0.0056431885,\n",
            " 'Loss/regularization_loss': 0.5447678,\n",
            " 'Loss/total_loss': 0.58333695,\n",
            " 'learning_rate': 0.009375882}\n",
            "I1118 22:58:47.080657 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.032925963,\n",
            " 'Loss/localization_loss': 0.0056431885,\n",
            " 'Loss/regularization_loss': 0.5447678,\n",
            " 'Loss/total_loss': 0.58333695,\n",
            " 'learning_rate': 0.009375882}\n",
            "INFO:tensorflow:Step 17700 per-step time 1.083s\n",
            "I1118 23:00:35.334704 136149638571136 model_lib_v2.py:705] Step 17700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045393795,\n",
            " 'Loss/localization_loss': 0.012190275,\n",
            " 'Loss/regularization_loss': 0.5443707,\n",
            " 'Loss/total_loss': 0.60195476,\n",
            " 'learning_rate': 0.00914543}\n",
            "I1118 23:00:35.334978 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.045393795,\n",
            " 'Loss/localization_loss': 0.012190275,\n",
            " 'Loss/regularization_loss': 0.5443707,\n",
            " 'Loss/total_loss': 0.60195476,\n",
            " 'learning_rate': 0.00914543}\n",
            "INFO:tensorflow:Step 17800 per-step time 1.082s\n",
            "I1118 23:02:23.582513 136149638571136 model_lib_v2.py:705] Step 17800 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.031237673,\n",
            " 'Loss/localization_loss': 0.0040418236,\n",
            " 'Loss/regularization_loss': 0.5439839,\n",
            " 'Loss/total_loss': 0.5792634,\n",
            " 'learning_rate': 0.008917004}\n",
            "I1118 23:02:23.582789 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.031237673,\n",
            " 'Loss/localization_loss': 0.0040418236,\n",
            " 'Loss/regularization_loss': 0.5439839,\n",
            " 'Loss/total_loss': 0.5792634,\n",
            " 'learning_rate': 0.008917004}\n",
            "INFO:tensorflow:Step 17900 per-step time 1.083s\n",
            "I1118 23:04:11.852811 136149638571136 model_lib_v2.py:705] Step 17900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030646052,\n",
            " 'Loss/localization_loss': 0.008118437,\n",
            " 'Loss/regularization_loss': 0.5436072,\n",
            " 'Loss/total_loss': 0.58237165,\n",
            " 'learning_rate': 0.00869064}\n",
            "I1118 23:04:11.853085 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.030646052,\n",
            " 'Loss/localization_loss': 0.008118437,\n",
            " 'Loss/regularization_loss': 0.5436072,\n",
            " 'Loss/total_loss': 0.58237165,\n",
            " 'learning_rate': 0.00869064}\n",
            "INFO:tensorflow:Step 18000 per-step time 1.083s\n",
            "I1118 23:06:00.105849 136149638571136 model_lib_v2.py:705] Step 18000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026061766,\n",
            " 'Loss/localization_loss': 0.0066971895,\n",
            " 'Loss/regularization_loss': 0.5432393,\n",
            " 'Loss/total_loss': 0.57599825,\n",
            " 'learning_rate': 0.008466393}\n",
            "I1118 23:06:00.106127 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.026061766,\n",
            " 'Loss/localization_loss': 0.0066971895,\n",
            " 'Loss/regularization_loss': 0.5432393,\n",
            " 'Loss/total_loss': 0.57599825,\n",
            " 'learning_rate': 0.008466393}\n",
            "INFO:tensorflow:Step 18100 per-step time 1.093s\n",
            "I1118 23:07:49.374193 136149638571136 model_lib_v2.py:705] Step 18100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0447805,\n",
            " 'Loss/localization_loss': 0.005905912,\n",
            " 'Loss/regularization_loss': 0.54288137,\n",
            " 'Loss/total_loss': 0.5935678,\n",
            " 'learning_rate': 0.008244291}\n",
            "I1118 23:07:49.374472 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0447805,\n",
            " 'Loss/localization_loss': 0.005905912,\n",
            " 'Loss/regularization_loss': 0.54288137,\n",
            " 'Loss/total_loss': 0.5935678,\n",
            " 'learning_rate': 0.008244291}\n",
            "INFO:tensorflow:Step 18200 per-step time 1.083s\n",
            "I1118 23:09:37.648406 136149638571136 model_lib_v2.py:705] Step 18200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04343588,\n",
            " 'Loss/localization_loss': 0.0061490834,\n",
            " 'Loss/regularization_loss': 0.54253286,\n",
            " 'Loss/total_loss': 0.5921178,\n",
            " 'learning_rate': 0.008024387}\n",
            "I1118 23:09:37.648685 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04343588,\n",
            " 'Loss/localization_loss': 0.0061490834,\n",
            " 'Loss/regularization_loss': 0.54253286,\n",
            " 'Loss/total_loss': 0.5921178,\n",
            " 'learning_rate': 0.008024387}\n",
            "INFO:tensorflow:Step 18300 per-step time 1.083s\n",
            "I1118 23:11:25.919776 136149638571136 model_lib_v2.py:705] Step 18300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.025599657,\n",
            " 'Loss/localization_loss': 0.0061169574,\n",
            " 'Loss/regularization_loss': 0.5421941,\n",
            " 'Loss/total_loss': 0.5739108,\n",
            " 'learning_rate': 0.0078067183}\n",
            "I1118 23:11:25.920043 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.025599657,\n",
            " 'Loss/localization_loss': 0.0061169574,\n",
            " 'Loss/regularization_loss': 0.5421941,\n",
            " 'Loss/total_loss': 0.5739108,\n",
            " 'learning_rate': 0.0078067183}\n",
            "INFO:tensorflow:Step 18400 per-step time 1.083s\n",
            "I1118 23:13:14.187104 136149638571136 model_lib_v2.py:705] Step 18400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036349926,\n",
            " 'Loss/localization_loss': 0.0054293815,\n",
            " 'Loss/regularization_loss': 0.5418644,\n",
            " 'Loss/total_loss': 0.58364373,\n",
            " 'learning_rate': 0.00759132}\n",
            "I1118 23:13:14.187370 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.036349926,\n",
            " 'Loss/localization_loss': 0.0054293815,\n",
            " 'Loss/regularization_loss': 0.5418644,\n",
            " 'Loss/total_loss': 0.58364373,\n",
            " 'learning_rate': 0.00759132}\n",
            "INFO:tensorflow:Step 18500 per-step time 1.083s\n",
            "I1118 23:15:02.446625 136149638571136 model_lib_v2.py:705] Step 18500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041003164,\n",
            " 'Loss/localization_loss': 0.0110952845,\n",
            " 'Loss/regularization_loss': 0.5415437,\n",
            " 'Loss/total_loss': 0.5936422,\n",
            " 'learning_rate': 0.0073782397}\n",
            "I1118 23:15:02.446893 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.041003164,\n",
            " 'Loss/localization_loss': 0.0110952845,\n",
            " 'Loss/regularization_loss': 0.5415437,\n",
            " 'Loss/total_loss': 0.5936422,\n",
            " 'learning_rate': 0.0073782397}\n",
            "INFO:tensorflow:Step 18600 per-step time 1.083s\n",
            "I1118 23:16:50.706000 136149638571136 model_lib_v2.py:705] Step 18600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0330479,\n",
            " 'Loss/localization_loss': 0.006720462,\n",
            " 'Loss/regularization_loss': 0.5412328,\n",
            " 'Loss/total_loss': 0.5810012,\n",
            " 'learning_rate': 0.007167512}\n",
            "I1118 23:16:50.706264 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0330479,\n",
            " 'Loss/localization_loss': 0.006720462,\n",
            " 'Loss/regularization_loss': 0.5412328,\n",
            " 'Loss/total_loss': 0.5810012,\n",
            " 'learning_rate': 0.007167512}\n",
            "INFO:tensorflow:Step 18700 per-step time 1.083s\n",
            "I1118 23:18:38.975569 136149638571136 model_lib_v2.py:705] Step 18700 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039115593,\n",
            " 'Loss/localization_loss': 0.0076841214,\n",
            " 'Loss/regularization_loss': 0.5409309,\n",
            " 'Loss/total_loss': 0.58773065,\n",
            " 'learning_rate': 0.006959181}\n",
            "I1118 23:18:38.975872 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.039115593,\n",
            " 'Loss/localization_loss': 0.0076841214,\n",
            " 'Loss/regularization_loss': 0.5409309,\n",
            " 'Loss/total_loss': 0.58773065,\n",
            " 'learning_rate': 0.006959181}\n",
            "INFO:tensorflow:Step 18800 per-step time 1.083s\n",
            "I1118 23:20:27.231021 136149638571136 model_lib_v2.py:705] Step 18800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032166563,\n",
            " 'Loss/localization_loss': 0.0054745767,\n",
            " 'Loss/regularization_loss': 0.5406377,\n",
            " 'Loss/total_loss': 0.5782788,\n",
            " 'learning_rate': 0.0067532836}\n",
            "I1118 23:20:27.231314 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.032166563,\n",
            " 'Loss/localization_loss': 0.0054745767,\n",
            " 'Loss/regularization_loss': 0.5406377,\n",
            " 'Loss/total_loss': 0.5782788,\n",
            " 'learning_rate': 0.0067532836}\n",
            "INFO:tensorflow:Step 18900 per-step time 1.083s\n",
            "I1118 23:22:15.485145 136149638571136 model_lib_v2.py:705] Step 18900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03158311,\n",
            " 'Loss/localization_loss': 0.006299805,\n",
            " 'Loss/regularization_loss': 0.54035336,\n",
            " 'Loss/total_loss': 0.5782363,\n",
            " 'learning_rate': 0.006549853}\n",
            "I1118 23:22:15.485420 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03158311,\n",
            " 'Loss/localization_loss': 0.006299805,\n",
            " 'Loss/regularization_loss': 0.54035336,\n",
            " 'Loss/total_loss': 0.5782363,\n",
            " 'learning_rate': 0.006549853}\n",
            "INFO:tensorflow:Step 19000 per-step time 1.083s\n",
            "I1118 23:24:03.744115 136149638571136 model_lib_v2.py:705] Step 19000 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.042800453,\n",
            " 'Loss/localization_loss': 0.005457191,\n",
            " 'Loss/regularization_loss': 0.54007745,\n",
            " 'Loss/total_loss': 0.58833504,\n",
            " 'learning_rate': 0.0063489364}\n",
            "I1118 23:24:03.744405 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.042800453,\n",
            " 'Loss/localization_loss': 0.005457191,\n",
            " 'Loss/regularization_loss': 0.54007745,\n",
            " 'Loss/total_loss': 0.58833504,\n",
            " 'learning_rate': 0.0063489364}\n",
            "INFO:tensorflow:Step 19100 per-step time 1.093s\n",
            "I1118 23:25:53.045417 136149638571136 model_lib_v2.py:705] Step 19100 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035020296,\n",
            " 'Loss/localization_loss': 0.00717192,\n",
            " 'Loss/regularization_loss': 0.53981036,\n",
            " 'Loss/total_loss': 0.5820026,\n",
            " 'learning_rate': 0.006150566}\n",
            "I1118 23:25:53.045695 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.035020296,\n",
            " 'Loss/localization_loss': 0.00717192,\n",
            " 'Loss/regularization_loss': 0.53981036,\n",
            " 'Loss/total_loss': 0.5820026,\n",
            " 'learning_rate': 0.006150566}\n",
            "INFO:tensorflow:Step 19200 per-step time 1.083s\n",
            "I1118 23:27:41.299864 136149638571136 model_lib_v2.py:705] Step 19200 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03548815,\n",
            " 'Loss/localization_loss': 0.0076073743,\n",
            " 'Loss/regularization_loss': 0.53955156,\n",
            " 'Loss/total_loss': 0.5826471,\n",
            " 'learning_rate': 0.005954777}\n",
            "I1118 23:27:41.300138 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03548815,\n",
            " 'Loss/localization_loss': 0.0076073743,\n",
            " 'Loss/regularization_loss': 0.53955156,\n",
            " 'Loss/total_loss': 0.5826471,\n",
            " 'learning_rate': 0.005954777}\n",
            "INFO:tensorflow:Step 19300 per-step time 1.083s\n",
            "I1118 23:29:29.554816 136149638571136 model_lib_v2.py:705] Step 19300 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043726075,\n",
            " 'Loss/localization_loss': 0.008047169,\n",
            " 'Loss/regularization_loss': 0.53930134,\n",
            " 'Loss/total_loss': 0.5910746,\n",
            " 'learning_rate': 0.0057616076}\n",
            "I1118 23:29:29.555084 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.043726075,\n",
            " 'Loss/localization_loss': 0.008047169,\n",
            " 'Loss/regularization_loss': 0.53930134,\n",
            " 'Loss/total_loss': 0.5910746,\n",
            " 'learning_rate': 0.0057616076}\n",
            "INFO:tensorflow:Step 19400 per-step time 1.083s\n",
            "I1118 23:31:17.823735 136149638571136 model_lib_v2.py:705] Step 19400 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04191855,\n",
            " 'Loss/localization_loss': 0.006497762,\n",
            " 'Loss/regularization_loss': 0.539059,\n",
            " 'Loss/total_loss': 0.5874753,\n",
            " 'learning_rate': 0.005571098}\n",
            "I1118 23:31:17.824005 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.04191855,\n",
            " 'Loss/localization_loss': 0.006497762,\n",
            " 'Loss/regularization_loss': 0.539059,\n",
            " 'Loss/total_loss': 0.5874753,\n",
            " 'learning_rate': 0.005571098}\n",
            "INFO:tensorflow:Step 19500 per-step time 1.083s\n",
            "I1118 23:33:06.083130 136149638571136 model_lib_v2.py:705] Step 19500 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03314225,\n",
            " 'Loss/localization_loss': 0.010352708,\n",
            " 'Loss/regularization_loss': 0.53882486,\n",
            " 'Loss/total_loss': 0.58231986,\n",
            " 'learning_rate': 0.0053832806}\n",
            "I1118 23:33:06.083416 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03314225,\n",
            " 'Loss/localization_loss': 0.010352708,\n",
            " 'Loss/regularization_loss': 0.53882486,\n",
            " 'Loss/total_loss': 0.58231986,\n",
            " 'learning_rate': 0.0053832806}\n",
            "INFO:tensorflow:Step 19600 per-step time 1.083s\n",
            "I1118 23:34:54.339582 136149638571136 model_lib_v2.py:705] Step 19600 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043809332,\n",
            " 'Loss/localization_loss': 0.010307814,\n",
            " 'Loss/regularization_loss': 0.5385988,\n",
            " 'Loss/total_loss': 0.5927159,\n",
            " 'learning_rate': 0.0051981867}\n",
            "I1118 23:34:54.339859 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.043809332,\n",
            " 'Loss/localization_loss': 0.010307814,\n",
            " 'Loss/regularization_loss': 0.5385988,\n",
            " 'Loss/total_loss': 0.5927159,\n",
            " 'learning_rate': 0.0051981867}\n",
            "INFO:tensorflow:Step 19700 per-step time 1.082s\n",
            "I1118 23:36:42.578797 136149638571136 model_lib_v2.py:705] Step 19700 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03267506,\n",
            " 'Loss/localization_loss': 0.0059723863,\n",
            " 'Loss/regularization_loss': 0.53838044,\n",
            " 'Loss/total_loss': 0.5770279,\n",
            " 'learning_rate': 0.0050158584}\n",
            "I1118 23:36:42.579103 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03267506,\n",
            " 'Loss/localization_loss': 0.0059723863,\n",
            " 'Loss/regularization_loss': 0.53838044,\n",
            " 'Loss/total_loss': 0.5770279,\n",
            " 'learning_rate': 0.0050158584}\n",
            "INFO:tensorflow:Step 19800 per-step time 1.083s\n",
            "I1118 23:38:30.838529 136149638571136 model_lib_v2.py:705] Step 19800 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03490481,\n",
            " 'Loss/localization_loss': 0.0096657695,\n",
            " 'Loss/regularization_loss': 0.5381699,\n",
            " 'Loss/total_loss': 0.58274055,\n",
            " 'learning_rate': 0.004836321}\n",
            "I1118 23:38:30.838811 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.03490481,\n",
            " 'Loss/localization_loss': 0.0096657695,\n",
            " 'Loss/regularization_loss': 0.5381699,\n",
            " 'Loss/total_loss': 0.58274055,\n",
            " 'learning_rate': 0.004836321}\n",
            "INFO:tensorflow:Step 19900 per-step time 1.083s\n",
            "I1118 23:40:19.092810 136149638571136 model_lib_v2.py:705] Step 19900 per-step time 1.083s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035711225,\n",
            " 'Loss/localization_loss': 0.005549289,\n",
            " 'Loss/regularization_loss': 0.53796685,\n",
            " 'Loss/total_loss': 0.5792274,\n",
            " 'learning_rate': 0.004659617}\n",
            "I1118 23:40:19.093080 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.035711225,\n",
            " 'Loss/localization_loss': 0.005549289,\n",
            " 'Loss/regularization_loss': 0.53796685,\n",
            " 'Loss/total_loss': 0.5792274,\n",
            " 'learning_rate': 0.004659617}\n",
            "INFO:tensorflow:Step 20000 per-step time 1.084s\n",
            "I1118 23:42:07.475248 136149638571136 model_lib_v2.py:705] Step 20000 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02984613,\n",
            " 'Loss/localization_loss': 0.004706291,\n",
            " 'Loss/regularization_loss': 0.5377713,\n",
            " 'Loss/total_loss': 0.5723237,\n",
            " 'learning_rate': 0.004485774}\n",
            "I1118 23:42:07.475530 136149638571136 model_lib_v2.py:708] {'Loss/classification_loss': 0.02984613,\n",
            " 'Loss/localization_loss': 0.004706291,\n",
            " 'Loss/regularization_loss': 0.5377713,\n",
            " 'Loss/total_loss': 0.5723237,\n",
            " 'learning_rate': 0.004485774}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the file path\n",
        "file_path = f'/content//Tensorflow/workspace/models/{CUSTOM_MODEL_NAME}/hyperparameters_and_variables.txt'\n",
        "\n",
        "# Open the file in write mode ('w')\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(\"Hyperparameters and variables used to train/test this model\\n\")\n",
        "    file.write(\" Training variables and Hyperparameters:\\n\")\n",
        "    file.write(f\"  Batch size: {batch_size}\\n\")\n",
        "    file.write(f\"  Model Architecture: {PRETRAINED_MODEL_NAME}\\n\")\n",
        "    file.write(f\"  Training Steps: {training_steps}\\n\")\n",
        "\n",
        "print(f'File \"{file_path}\" has been created and written to.')"
      ],
      "metadata": {
        "id": "OEq3Uik3Oy_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UZpzAAd_pAEK",
        "outputId": "7eb92c3e-4cb2-4609-a078-a934c8e15a8c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/aircraftimage/temp/ssd_mobilenet_1'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Replace these paths with your source and destination folder paths\n",
        "source_folder = f\"/content/Tensorflow/workspace/models/{CUSTOM_MODEL_NAME}\"\n",
        "destination_folder = f\"/content/drive/MyDrive/aircraftimage/trained_models/{CUSTOM_MODEL_NAME}\"\n",
        "\n",
        "# Check if the destination folder already exists\n",
        "counter = 1\n",
        "while os.path.exists(destination_folder):\n",
        "    # If it exists, increment the counter and update the destination folder name\n",
        "    destination_folder = f\"{base_destination_folder}{CUSTOM_MODEL_NAME}_{counter}\"\n",
        "    counter += 1\n",
        "\n",
        "# Create the destination folder\n",
        "#os.makedirs(destination_folder)\n",
        "\n",
        "# Copy the entire folder\n",
        "shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "print(f\"Trained Model, testing records, checkpoints etc were copied to {destination_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now open up the Inferencing Notebook and load the model you've just built - located at destination_folder"
      ],
      "metadata": {
        "id": "_vPPsqe2SZIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "destination_folder"
      ],
      "metadata": {
        "id": "OYSSxyhNShcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}